{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"projecte-aina/catalan_general_crawling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Reduïu els costos dels processos administratius al vostre organisme públic\\nEviteu els desplaçaments i pèrdua de temps als ciutadans en les seves gestions\\nOferiu una administració més transparent a ciutadans i empreses\\nEns grans i petits experimenten aquesta transformació amb èxit, gràcies al suport de l\\'AOC\\nDepartament de Sistemes d\\'Informació i Processos\\n\" Via Oberta ens ha permès fer efectiu el dret dels ciutadans a no aportar documents, eliminant paper i simplificant procediments\"\\n\" e.FACT proporciona informació indispensable per a la realització de les auditories del registre comptable de factures de les Administracions Públiques Catalanes\"\\nCoordinador del departament d\\'Informàtica\\n\"El servei VIA OBERTA és el que ha aportat majors avantatges per als ciutadans\"\\n\"Amb l\\' e-NOTUM hem escurçat els procediments en 12 dies, quasi un 40% menys!\"\\nCoordinadora d\\'organització de persones i e-administració\\n\" Via Oberta ofereix millores per als ciutadans al no haver d\\'aportar cap document\"\\nResponsable d\\'Informàtica i Administració Electrònica\\n\" e-TRAM ens ha permès implantar un servei de tramitació electrònica per als ciutadans de forma ràpida, senzilla i amb un cost reduït\"\\n\"Els municipis amb pocs habitants trobem en els serveis de l\\'AOC la gratuïtat i la comoditat necessàries per dur a terme el nostre dia a dia\"\\n\"Les T-CAT han permès incorporar de forma segura la signatura electrònica dins dels nostres procediments afavorint la transformació digital de la nostra activitat\"\\nCap de Departament de Sistemes i Tecnologies de la Informació\\n\"Amb el desplegament de l\\' idCAT hem apropat l\\'Ajuntament a la ciutadania\"\\n\"Mitjançant els serveis de Govern Obert de l\\'AOC hem pogut fer fàcil el que sembla difícil\"\\n\"Al tauler electrònic pots penjar fins i tot el projecte sencer i al final et permet fer també la diligència\"\\nÀrea de Promoció Econòmica, Administració i Hisenda\\n\"El Sobre Digital i la PSCP han aconseguit una comunió senzilla entre empreses i administració per universalitzar la compra pública electrònica\"\\n\"L\\' e-SET és la implantació d\\'un nou sistema de treball que facilita la feina del dia a dia\"\\nCap del servei de contractació i compres\\n\"El Sobre Digital, una experiència imprescindible per a la bona administració amb estalvi de recursos i millora de la seguretat jurídica i la transparència\"\\nÀrea d\\'Organització i Administració Electrònica\\n\"El desplegament de la valisa electrònica ha estat clau en el procés de transformació digital dels nostres procediments interns\"\\n\"L\\' Hèstia permet el treball en temps real i des de qualsevol lloc, així com sistematitzar la pràctica professional, recollir la informació ordenadament i amb el mateix llenguatge\"\\nConsulta els materials del Congrés de Govern Digital 2019\\nGoverns transparents, fluids, dinàmics, líquids... un bon lema pel principal objectiu de la governança del segle XXI: democratitzar-ho tot.\\nConfluències, rius, cooperació.\\nCatalunya, Mediterrània, mar de drets.\\nA favor: totes les Administracions movent-se per posar-se al dia i millorar, tot aprofitant la revolució digital.\\nEn contra: quants cops estem reinventant la roda i quantes quantes oportunitats perdudes de fer-ho una única vegada i de forma coordinada i col·laborativa?\\n\"La transparència és una oportunitat.\\nHem de perdre tota por a explicar què fem\": la conclusió de la taula d\\'alcaldies de la Jornada de Govern Obert pic.twitter.com/ERbgLSIXZM\\nEl director general de Participació Ciutadana ens convida a transformar les administracions públiques a partir de la participació ciutadana\\nEns cal que allò que preocupa i ocupa els governants formi part d\\'allò en què participa la ciutadania pic.twitter.com/NwQr4EZSCS: \"A moltes institucions encara els sona xinés això de les dades obertes i la transparència.\\nDe que serveix que hi hagi un portal, si llavors no hi ha dades?\\nLlavors l\\'accés a la informació pels periodistes és molt parcial\".\\nOferim eines que, conjuntament amb la metodologia i el suport necessari, fan possible l\\'assoliment d\\'un govern digital\\nPosem al vostre abast tot el coneixement: formació, guies, normatives, etc.\\nTenim eines per gestionar àgilment part del procés administratiu del vostre ens\\nEl nostre equip farà tot el possible per resoldre les vostres incidències\\nSabem que es tracta d\\'una decisió molt important per al vostre ens i és per això que us ho volem posar fàcil.\\nLa selecció de l\\'actualitat d\\'Administració Oberta a la vostra safata.'}\n",
      "\n",
      "{'text': 'En compliment de la Directiva 2009/136/CE, desenvolupada en el nostre ordenament per l\\'article 22.2 de la Llei de Serveis de Societat de la Informació (LSSI) i seguint les instruccions de l\\'Agència Espanyola de Protecció de Dades, procedim a informar-li detalladament de l\\'ús que es realitza a la nostra pàgina web.\\nAquesta informació no revela la seva identitat, però sí que permet la seva identificació com a un usuari concret i pot guardar informació relativa a la freqüència amb la que visita la pàgina web, les seves preferències de navegació o aquella informació que més l\\'interessa.\\nEl que ens permet, cada vegada que accedeix a www.aoc.cat, millorar la qualitat i la usabilitat de la nostra pàgina web.\\nNo obstant, si les desactiva, pot ser que la seva navegació per www.aoc.cat no sigui òptima i algunes de les seves utilitats no funcionin correctament.\\nCookies analítiques: galetes de Google Analytics\\nAquesta pàgina web utilitza Google Analytics, un servei analític del web prestat per Google.\\nInc, una companyia de Delaware l\\'oficina principal de la qual es troba a 1600 Amphitheatre Parkway, Mountain View (Califòrnia), CA 94043, Estats Units (\" Google\").\\nLa informació que genera la cookie sobre l\\'ús del lloc web (incloent l\\'adreça IP) serà directament transmesa i arxivada per Google en els seus servidors d\\'Estats Units.\\nGoogle utilitzarà aquesta informació per compte nostre amb el propòsit de seguir la pista del seu ús del lloc web.\\nGoogle podrà transmetre aquesta informació a tercers quan així ho requereixi la legislació, o quan aquests tercers processin la informació per compte de Google.\\nEn aquests casos, Google no associarà la seva adreça IP amb cap altra dada de què disposi.\\nEn utilitzar aquesta pàgina web consent el tractament de la seva informació per Google en la forma i per als fins anteriorment indicats.\\nL\\'exercici de qualsevol dret s\\'haurà de realitzar mitjançant comunicació directa amb Google.\\nPer optar per no ser rastrejats per Google Analytics a través de tots els llocs web podeu consultar http://tools.google.com/dlpage/gaoptout\\nAixí mateix, també registra quan va ser la primera i l\\'última vegada que l\\'usuari va visitar el web www.aoc.cat.\\nGaletes en altres llocs web del Consorci AOC\\nLes seves finalitats són descrites a la pàgina de privacitat de Twitter.\\nConfiguració de l\\'usuari per evitar Cookies\\nÉs cas de dubte pot dirigir-se al webmaster del domini creador de la cookie.\\nLa selecció de l\\'actualitat d\\'Administració Oberta a la vostra safata.'}\n",
      "\n",
      "{'text': 'L\\'ús de la informació continguda en aquest lloc web implica l\\'acceptació i el consentiment en els termes i les condicions que es detallen en aquest avís legal.\\nTitularitat i règim de responsabilitat de la pàgina web\\nEl responsable d\\'aquesta pàgina web és el Consorci Administració Oberta de Catalunya, (Consorci AOC), amb NIF Q0801175A, i ubicat al Carrer de Tànger, núm. 98, (planta baixa) 08018 (tel. 93 272 25 00 i fax.\\nTota persona que accedeixi a aquest lloc web assumeix el paper d\\'usuari, comprometent-se a l\\'observança i compliment rigorós de les disposicions aquí disposades, així com a qualsevol altre disposició legal que li sigui d\\'aplicació.\\nEl Consorci AOC té el dret a modificar la informació que apareix en aquesta pàgina web, sense que existeixi la obligació de preavís o posada en coneixement dels usuaris de les noves obligacions -a excepció dels compromisos assumits en virtut de convenis específics – entenent-se com a suficient la seva publicació en el lloc web.\\nLes informacions i els continguts relacionats amb l\\'actuació i les funcions del Consorci AOC, que s\\'inclouen en aquest web, estan subjectes a les previsions següents:\\nResponsabilitat amb relació als continguts\\nEl Consorci AOC treballa perquè les informacions, els continguts i els serveis oferts o difosos en aquest web acompleixin de manera suficient la necessària integritat, veracitat, actualització, accessibilitat i usabilitat.\\nA aquest efecte, cal tenir en compte la data d\\'actualització de cadascun dels continguts que en cada cas s\\'indiqui.\\nLa pàgina web ofereix informació, consells, guies i d\\'altres continguts preparats pel Consorci AOC amb finalitats de difusió, informació, conscienciació i en determinats casos la prestació de serveis específics d\\'administració electrònica.\\nS\\'informa a l\\'usuari que tots aquests continguts, malgrat estar preparats amb el màxim nivell de qualitat possibles, no poden suposar en cap moment assessorament específic en matèria tecnològica i/o jurídica o ser considerats com a actuacions dirigides a la resolució de problemàtiques específiques.\\nEn qualsevol cas, el Consorci AOC es reserva el dret a modificar-los, suprimir-los, desenvolupar-los o actualitzar-los unilateralment sense notificació prèvia i sense assumir cap responsabilitat.\\nEl Consorci AOC ofereix la traducció automàtica en altres llengües diferents del català dels continguts del seu web per tal de facilitar als ciutadans la comprensió del text en el seu propi idioma.\\nMalgrat tot, els articles traduïts automàticament poden contenir errors materials dels quals el Consorci AOC no se\\'n fa responsable.\\nEn l\\'actualitat, el Consorci AOC només garanteix la veracitat dels continguts en llengua catalana.\\nReferències i enllaços a webs d\\'altres organitzacions\\nEl web del Consorci AOC conté referències o enllaços a webs de tercers (\"links\"), la major part d\\'elles són a pàgines d\\'Internet d\\'altres administracions públiques, que s\\'han considerat d\\'interès pels usuaris.\\nEn el cas que s\\'abandoni el web, el Consorci AOC no assumeix cap responsabilitat derivada de la connexió o dels contingut dels enllaços de tercers.\\nTot i això, es revisen periòdicament els enllaços a altres pàgines per tal d\\'evitar la inclusió d\\'enllaços que no compleixen la normativa de protecció de dades, així com la resta de normativa vigent.\\nEn aquest sentit, el Consorci manifesta que si es detecta qualsevol contingut que pugui contravenir la legislació nacional o internacional, o l\\'ordre públic, es procedirà a la retirada immediata de l\\'enllaç, posant-ho en coneixement de les autoritat competents.\\nEl Consorci AOC no es fa responsable de la informació i continguts emmagatzemats, a títol enunciatiu però no limitatiu, en els fòrums, blocs, comentaris en xarxes socials, o qualsevol altre mitjà del Consorci AOC que permeti a tercers publicar continguts de forma independent.\\nNo obstant, en compliment de l\\'article 11 i 16 de la LSSICE, es posa a disposició de tots els usuaris, autoritats i forces de seguretat, per col·laborar de forma activa en la retirada o, en el seu cas, bloqueig de tots aquells continguts que poguessin afectar o contravenir la legislació nacional, o internacional, drets de tercers o la moral i l\\'ordre públic.\\nEn el cas que qualsevol usuari consideri que existeix en el lloc web algun contingut que pugui ser susceptible de l\\'anterior classificació, es sol·licita que ho comuniqui de forma immediata a l\\'administrador del la pàgina web per mitjà del correu electrònic [EMAIL]\\nReproducció de continguts propis\\nEl Consorci AOC facilita la consulta lliure i gratuïta de la informació continguda en el web i autoritza la reproducció total o parcial dels seus continguts, sempre i quan els continguts esmentats es conservin íntegres, es citi la font i la data en la que s\\'ha realitzat la còpia, no es manipulin, ni alterin els continguts i no s\\'utilitzi directament amb finalitats comercials (Llei 37/2007, de 16 de novembre, sobre la reutilització de la informació del sector públic).\\nEl Consorci AOC autoritza la descarrega gratuïta dels manuals, impresos, programes i publicacions informatives que s\\'inclouen en el seu web, a efectes de la seva reproducció i distribució, llevat que s\\'indiqui el contrari de forma expressa.\\nNo obstant això, en determinats supòsits el Consorci AOC pot indicar de manera explícita que és necessari sol·licitar una autorització expressa.\\nAixí mateix, la reutilització es pot limitar per la tutela d\\'altres béns jurídics prioritaris, com ara la protecció de les dades personals, la intimitat o els drets de protecció intel·lectual de tercers.\\nEl domini d\\'aquest web és titularitat del Consorci AOC, així com els drets de propietat intel·lectual, el seu disseny i els codis que conté, llevat que s\\'indiqui una titularitat diferent.\\nNo s\\'autoritza en cap cas, l\\'ús de marques o signes distintius, logotips i en general símbols distintius de qualsevol naturalesa propietat del Consorci AOC, en publicacions i webs que no siguin d\\'ens participats o patrocinats per aquest Consorci, sense el coneixement i l\\'autorització corresponent del Consorci AOC.\\nEl Consorci AOC no assumirà cap responsabilitat derivada de l\\'ús per part de tercers del contingut d\\'aquesta pàgina Web i podrà exercitar totes les accions civils o penals que li corresponguin en cas d\\'infracció d\\'aquests drets per part de l\\'usuari.\\nAquesta informació es troba continguda a la Política de Cookies del Consorci AOC.\\nDret aplicable i jurisdicció competent\\nLa llei aplicable en cas de disputa o conflicte d\\'interpretació dels termes que conforme aquest Avís legal, així com qualsevol aspecte relacionat amb els serveis d\\'aquest web, serà la legislació espanyola.\\nEls possibles conflictes relatius a aquest web es regiran exclusivament pel dret espanyol, essent els jutjats de Barcelona els únics competents.\\nTota persona usuària del web, independentment de la jurisdicció territorial des de la qual es produeixi el seu accés, accepta el compliment i respecte d\\'aquesta clàusula amb renúncia expressa a qualsevol altre fur que li pogués correspondre.\\nSi alguna part o clàusula d\\'aquestes Condicions fos declarada nul·la o deixada sense efecte per una resolució judicial, les restants estipulacions conservaran la seva validesa.\\nLa selecció de l\\'actualitat d\\'Administració Oberta a la vostra safata.'}\n",
      "\n",
      "{'text': \"Els Reconeixements Administració Oberta als ajuntaments i consells comarcals que atorga anualment l'AOC han esdevingut el reconeixement públic de tots aquells ens que destaquen en la transformació digital de la seva relació amb la ciutadania i en la seva gestió interna.\\nEls guardons s'atorguen en base a uns indicadors objectius, l'anàlisi dels webs dels ens i l'ús de determinats serveis del Consorci AOC.\\nEl seu objectiu és valorar i reconèixer la implantació i l'ús dels serveis d'administració electrònica i, tal i com s'ha indicat anteriorment, la seva conseqüent transformació digital en seva relació amb la ciutadania i en la seva gestió interna.\\nEls Reconeixements Administració Oberta tenen set categories d'acord amb el nombre d'habitants dels ens i la seva naturalesa:\\nDescripció del mètode d'avaluació dels Reconeixements Administració Oberta\\nLlistat de guardonats a l'edició del 2018: ajuntaments i consells comarcals capdavanters en administració digital\\nSegells Reconeixements Administració Oberta 2018\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n",
      "{'text': \"En el marc del desenvolupament de l'Administració electrònica, des de l'AOC copsem l'estat de l'administració pel que fa als instruments municipals d'Administració electrònica i, més específicament, al reconeixement efectiu dels drets dels ciutadans arrel de la normativa que regula l'ús dels mitjans electrònics, la transparència, l'accés a la informació pública i el bon govern.\\nAmb aquest objectiu, periòdicament duem a terme una revisió de l'estat de l'e-Administració als 947 ajuntaments de Catalunya 1 i publiquem les dades en un informe.\\nAixí mateix, els resultats de l'anàlisi es plasmen en un mapa de Catalunya interactiu.\\nAl mapa municipal català podeu accedir a la informació relacionada amb els 947 municipis catalans:\\nLa informació que mostren els mapes és la més recent.\\nSi voleu conèixer les dades dels estudis anteriors podeu accedir als informes sobre administració.\\nTambé podeu consultar les dades dels 42 consells comarcals al mapa d'e-administració per comarques.\\nEls informes sobre e-Administració són el resultat d'un estudi dut a terme pel personal del Gabinet Tècnic de l'AOC en un període de temps concret i en base a:\\nA continuació detallem els paràmetres analitzats a l'estudi, agrupats en sis blocs\\nSi l'ajuntament ha aprovat normativa en matèria d'administració electrònica\\nSi l'ajuntament ha aprovat alguna norma específica per regular l'ús dels mitjans electrònics en la seva administració (ordenança reguladora d'administració electrònica, registre electrònic i seu electrònica).\\nEl resultat d'aquesta anàlisi es contrasta amb el personal tècnic dels consells comarcals, d'acord amb el conveni de col·laboració que hi ha entre els consells i el Consorci AOC.\\n1 En els tres primers informes de 2010, es van recollir dades de 946 ajuntaments, ja que La Canonja encara no era legalment municipi independent.\\nTambé es va analitzar en el seu moment el municipi de Medinyà fins a la seva forçosa desaparició el febrer de 2018.\\nEvolució de les dades dels informes sobre l'e-Administració (desembre 2017) (977 kB)\\nNOTA: les dades recollides en aquests informes es publiquen ara en format de dades obertes a indicadors públics d'activitat\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n",
      "{'text': \"Cursos de lliure accès per a que els comenceu quan vulgueu i els feu al vostre ritme.\\nCursos amb data d'inici planificada i seguiment per part del tutor\\nUna pinzellada de les principals característiques de cada servei.\\nEs pot completar en uns minuts i us permetrà començar amb bon peu.\\nCreació del preu públic del servei de formació (aprovada a la Comissió Executiva del Consorci AOC de 17 de desembre de 2014):\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n",
      "{'text': 'En aquest document trobareu la darrera versió de les condicions generals de prestació dels Serveis AOC amb la seva data d\\'aprovació per part de la Comissió Executiva del Consorci AOC.\\nTambé trobareu el document immediatament anterior a aquesta versió:\\nCondicions de prestació específiques\\nHi ha serveis que, donades les seves particularitats, disposen addicionalment d\\'unes condicions específiques de prestació.\\nEn cas de dubte o discrepàncies entre l\\'acord específic i el general, les condicions específiques són les que prevalen sobre les genèriques.\\nEn aquests documents trobareu la darrera versió de les condicions específiques amb la seva data d\\'aprovació per part de la Comissió Executiva del Consorci AOC.\\nEn cas d\\'haver-se modificat, també trobareu la versió del document immediatament anterior a l\\'actual:\\nSignatura electrònica i seguretat\\nSi sou usuaris d\\'un dels serveis del Consorci AOC i voleu comunicar-nos la vostra sol·licitud de baixa, feu-ho a través del tràmit de \"Sol·licitud de baixa de servei\" del servei \"Baixa de servei\" que trobareu a l\\'apartat \"Tràmits\", prestador \"Consorci AOC\"\\nAdreceu-vos al Centre d\\'Atenció a l\\'Usuari (CAU) del Consorci AOC.\\nPreus públics del servei de certificació (SCD):\\nLa selecció de l\\'actualitat d\\'Administració Oberta a la vostra safata.'}\n",
      "\n",
      "{'text': \"A continuació podeu accedir als convenis de col·laboració vigents subscrits pel Consorci Administració Oberta de Catalunya:\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n",
      "{'text': \"La informació sobre els processos de selecció de l'AOC es troba a la seu electrònica.\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n",
      "{'text': \"El Consorci Administració Oberta de Catalunya (Consorci AOC) té la seva gènesi en el Pacte per a la promoció i el desenvolupament de la Societat de la Informació a les administracions públiques catalanes (42,56 kB), signat al Parlament de Catalunya el 23 de juliol de 2001, entre els presidents de tots els grups parlamentaris, el Govern de la Generalitat de Catalunya i els governs locals representats per Localret.\\nLa missió de l'AOC és impulsar la transformació digital de les administracions catalanes, per promoure governs àgils, lògics i col·laboratius.\\nI la nostra visió es aconseguir que les persones gaudeixen de serveis públics de qualitat i visquin en una societat oberta.\\nSegons la Llei 29/2010, de 3 d'agost, de l'ús dels mitjans electrònics al sector públic de Catalunya, els objectius estratègics del Consorci AOC són, fonamentalment, col·laborar amb l'Administració de la Generalitat, els ens locals i, si s'escau, altres organismes públics, per:\\na) Promoure la interoperabilitat dels sistemes d'informació catalans amb la resta d'administracions.\\nb) Crear i prestar serveis comuns d'administració electrònica.\\nc) Reutilitzar les aplicacions i els serveis d'administració electrònica que es desenvolupin.\\nd) Garantir la identitat i acreditar la voluntat en les actuacions dels ciutadans i el personal del sector públic, així\\xad com la confidencialitat i el no-rebuig en les comunicacions electròniques.\\nMitjançant el Consorci AOC, també es desenvolupen i executen mesures de cooperació i foment de l'Administració de la Generalitat amb els ens locals en matèria d'ús dels mitjans electrònics.\\nEl Consorci AOC treballa amb una clara vocació de servei a les administracions públiques i la voluntat d'anticipar-se de les necessitats futures que ja es preveuen en l'actual marc normatiu o que demanda la ciutadania.\\nConcretament treballem en les següents línies d'actuació estratègiques:\\n1.- Serveis de col·laboració administrativa, amb l'objectiu de potenciar l'intercanvi d'informació per mitjans telemàtics entre les administracions públiques per millorar la seva eficiència i eficàcia, és a dir, de promoure la interoperabilitat dels sistemes d'informació de les administracions públiques catalanes.\\nI això es fa desenvolupant i prestant:\\n2.- Serveis comuns d'Administració electrònica, per tal de proporcionar suport als projectes d'ús intensiu de les tecnologies de la informació i les comunicacions que impulsin les institucions catalanes, potenciant la reusabilitat i la reutilització de les solucions d'Administració electrònica.\\nAmb aquests serveis el Consorci contribueix a:\\nEls serveis comuns d'Administració electrònica en els que treballa el Consorci es classifiquen en:\\n3.- Serveis d'identitat i signatura electrònica, adreçats als empleats públics i carrecs electes, i també a la ciutadania de Catalunya.\\nEl Consorci exerceix també funcions de divulgació, formació i assessorament, això com quan correspon, suport financer a les entitats locals en el desenvolupament dels seus projectes i iniciatives d'Administració electrònica.\\nEstatuts Consorci Administració Oberta de Catalunya\\nLa selecció de l'actualitat d'Administració Oberta a la vostra safata.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset['train']\n",
    "\n",
    "# i want to see the first 10 examples\n",
    "for i in range(10):\n",
    "    print(dataset[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenim diferents mides de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57333\n",
      "369003\n",
      "738007\n"
     ]
    }
   ],
   "source": [
    "# i want to get the first 100 MB of the dataset\n",
    "size = 0\n",
    "for i in range(len(dataset)):\n",
    "    size += len(dataset[i]['text'])\n",
    "    if size > 100000000:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "dataset_100MB = dataset.select(list(range(i)))\n",
    "\n",
    "\n",
    "# i want to get the first 500 MB of the dataset\n",
    "size = 0\n",
    "for j in range(len(dataset)):\n",
    "    size += len(dataset[i]['text'])\n",
    "    if size > 500000000:\n",
    "        print(j)\n",
    "        break\n",
    "\n",
    "dataset_500MB = dataset.select(list(range(j)))\n",
    "\n",
    "\n",
    "# i want to get the first 1 GB of the dataset\n",
    "size = 0\n",
    "for g in range(len(dataset)):\n",
    "    size += len(dataset[i]['text'])\n",
    "    if size > 1000000000:\n",
    "        print(g)\n",
    "        break\n",
    "\n",
    "dataset_1GB = dataset.select(list(range(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['reduïu', 'els', 'costos', 'dels', 'processos', 'administratius', 'al', 'vostre', 'organisme', 'públic', 'eviteu', 'els', 'desplaçaments', 'i', 'pèrdua', 'de', 'temps', 'als', 'ciutadans', 'en', 'les', 'seves', 'gestions', 'oferiu', 'una', 'administració', 'més', 'transparent', 'a', 'ciutadans', 'i', 'empreses', 'ens', 'grans', 'i', 'petits', 'experimenten', 'aquesta', 'transformació', 'amb', 'èxit', 'gràcies', 'al', 'suport', 'de', 'l', 'aoc', 'departament', 'de', 'sistemes', 'd', 'informació', 'i', 'processos', 'via', 'oberta', 'ens', 'ha', 'permès', 'fer', 'efectiu', 'el', 'dret', 'dels', 'ciutadans', 'a', 'no', 'aportar', 'documents', 'eliminant', 'paper', 'i', 'simplificant', 'procediments', 'e', 'fact', 'proporciona', 'informació', 'indispensable', 'per', 'a', 'la', 'realització', 'de', 'les', 'auditories', 'del', 'registre', 'comptable', 'de', 'factures', 'de', 'les', 'administracions', 'públiques', 'catalanes', 'coordinador', 'del', 'departament', 'd', 'informàtica', 'el', 'servei', 'via', 'oberta', 'és', 'el', 'que', 'ha', 'aportat', 'majors', 'avantatges', 'per', 'als', 'ciutadans', 'amb', 'l', 'e', 'notum', 'hem', 'escurçat', 'els', 'procediments', 'en', '12', 'dies', 'quasi', 'un', '40', 'menys', 'coordinadora', 'd', 'organització', 'de', 'persones', 'i', 'e', 'administració', 'via', 'oberta', 'ofereix', 'millores', 'per', 'als', 'ciutadans', 'al', 'no', 'haver', 'd', 'aportar', 'cap', 'document', 'responsable', 'd', 'informàtica', 'i', 'administració', 'electrònica', 'e', 'tram', 'ens', 'ha', 'permès', 'implantar', 'un', 'servei', 'de', 'tramitació', 'electrònica', 'per', 'als', 'ciutadans', 'de', 'forma', 'ràpida', 'senzilla', 'i', 'amb', 'un', 'cost', 'reduït', 'els', 'municipis', 'amb', 'pocs', 'habitants', 'trobem', 'en', 'els', 'serveis', 'de', 'l', 'aoc', 'la', 'gratuïtat', 'i', 'la', 'comoditat', 'necessàries', 'per', 'dur', 'a', 'terme', 'el', 'nostre', 'dia', 'a', 'dia', 'les', 't', 'cat', 'han', 'permès', 'incorporar', 'de', 'forma', 'segura', 'la', 'signatura', 'electrònica', 'dins', 'dels', 'nostres', 'procediments', 'afavorint', 'la', 'transformació', 'digital', 'de', 'la', 'nostra', 'activitat', 'cap', 'de', 'departament', 'de', 'sistemes', 'i', 'tecnologies', 'de', 'la', 'informació', 'amb', 'el', 'desplegament', 'de', 'l', 'idcat', 'hem', 'apropat', 'l', 'ajuntament', 'a', 'la', 'ciutadania', 'mitjançant', 'els', 'serveis', 'de', 'govern', 'obert', 'de', 'l', 'aoc', 'hem', 'pogut', 'fer', 'fàcil', 'el', 'que', 'sembla', 'difícil', 'al', 'tauler', 'electrònic', 'pots', 'penjar', 'fins', 'i', 'tot', 'el', 'projecte', 'sencer', 'i', 'al', 'final', 'et', 'permet', 'fer', 'també', 'la', 'diligència', 'àrea', 'de', 'promoció', 'econòmica', 'administració', 'i', 'hisenda', 'el', 'sobre', 'digital', 'i', 'la', 'pscp', 'han', 'aconseguit', 'una', 'comunió', 'senzilla', 'entre', 'empreses', 'i', 'administració', 'per', 'universalitzar', 'la', 'compra', 'pública', 'electrònica', 'l', 'e', 'set', 'és', 'la', 'implantació', 'd', 'un', 'nou', 'sistema', 'de', 'treball', 'que', 'facilita', 'la', 'feina', 'del', 'dia', 'a', 'dia', 'cap', 'del', 'servei', 'de', 'contractació', 'i', 'compres', 'el', 'sobre', 'digital', 'una', 'experiència', 'imprescindible', 'per', 'a', 'la', 'bona', 'administració', 'amb', 'estalvi', 'de', 'recursos', 'i', 'millora', 'de', 'la', 'seguretat', 'jurídica', 'i', 'la', 'transparència', 'àrea', 'd', 'organització', 'i', 'administració', 'electrònica', 'el', 'desplegament', 'de', 'la', 'valisa', 'electrònica', 'ha', 'estat', 'clau', 'en', 'el', 'procés', 'de', 'transformació', 'digital', 'dels', 'nostres', 'procediments', 'interns', 'l', 'hèstia', 'permet', 'el', 'treball', 'en', 'temps', 'real', 'i', 'des', 'de', 'qualsevol', 'lloc', 'així', 'com', 'sistematitzar', 'la', 'pràctica', 'professional', 'recollir', 'la', 'informació', 'ordenadament', 'i', 'amb', 'el', 'mateix', 'llenguatge', 'consulta', 'els', 'materials', 'del', 'congrés', 'de', 'govern', 'digital', '2019', 'governs', 'transparents', 'fluids', 'dinàmics', 'líquids', 'un', 'bon', 'lema', 'pel', 'principal', 'objectiu', 'de', 'la', 'governança', 'del', 'segle', 'xxi', 'democratitzar', 'ho', 'tot', 'confluències', 'rius', 'cooperació', 'catalunya', 'mediterrània', 'mar', 'de', 'drets', 'a', 'favor', 'totes', 'les', 'administracions', 'movent', 'se', 'per', 'posar', 'se', 'al', 'dia', 'i', 'millorar', 'tot', 'aprofitant', 'la', 'revolució', 'digital', 'en', 'contra', 'quants', 'cops', 'estem', 'reinventant', 'la', 'roda', 'i', 'quantes', 'quantes', 'oportunitats', 'perdudes', 'de', 'fer', 'ho', 'una', 'única', 'vegada', 'i', 'de', 'forma', 'coordinada', 'i', 'col', 'laborativa', 'la', 'transparència', 'és', 'una', 'oportunitat', 'hem', 'de', 'perdre', 'tota', 'por', 'a', 'explicar', 'què', 'fem', 'la', 'conclusió', 'de', 'la', 'taula', 'd', 'alcaldies', 'de', 'la', 'jornada', 'de', 'govern', 'obert', 'pic', 'twitter', 'com', 'erbglsixzm', 'el', 'director', 'general', 'de', 'participació', 'ciutadana', 'ens', 'convida', 'a', 'transformar', 'les', 'administracions', 'públiques', 'a', 'partir', 'de', 'la', 'participació', 'ciutadana', 'ens', 'cal', 'que', 'allò', 'que', 'preocupa', 'i', 'ocupa', 'els', 'governants', 'formi', 'part', 'd', 'allò', 'en', 'què', 'participa', 'la', 'ciutadania', 'pic', 'twitter', 'com', 'nwqr4ezscs', 'a', 'moltes', 'institucions', 'encara', 'els', 'sona', 'xinés', 'això', 'de', 'les', 'dades', 'obertes', 'i', 'la', 'transparència', 'de', 'que', 'serveix', 'que', 'hi', 'hagi', 'un', 'portal', 'si', 'llavors', 'no', 'hi', 'ha', 'dades', 'llavors', 'l', 'accés', 'a', 'la', 'informació', 'pels', 'periodistes', 'és', 'molt', 'parcial', 'oferim', 'eines', 'que', 'conjuntament', 'amb', 'la', 'metodologia', 'i', 'el', 'suport', 'necessari', 'fan', 'possible', 'l', 'assoliment', 'd', 'un', 'govern', 'digital', 'posem', 'al', 'vostre', 'abast', 'tot', 'el', 'coneixement', 'formació', 'guies', 'normatives', 'etc', 'tenim', 'eines', 'per', 'gestionar', 'àgilment', 'part', 'del', 'procés', 'administratiu', 'del', 'vostre', 'ens', 'el', 'nostre', 'equip', 'farà', 'tot', 'el', 'possible', 'per', 'resoldre', 'les', 'vostres', 'incidències', 'sabem', 'que', 'es', 'tracta', 'd', 'una', 'decisió', 'molt', 'important', 'per', 'al', 'vostre', 'ens', 'i', 'és', 'per', 'això', 'que', 'us', 'ho', 'volem', 'posar', 'fàcil', 'la', 'selecció', 'de', 'l', 'actualitat', 'd', 'administració', 'oberta', 'a', 'la', 'vostra', 'safata'], ['en', 'compliment', 'de', 'la', 'directiva', '2009', '136', 'ce', 'desenvolupada', 'en', 'el', 'nostre', 'ordenament', 'per', 'l', 'article', '22', '2', 'de', 'la', 'llei', 'de', 'serveis', 'de', 'societat', 'de', 'la', 'informació', 'lssi', 'i', 'seguint', 'les', 'instruccions', 'de', 'l', 'agència', 'espanyola', 'de', 'protecció', 'de', 'dades', 'procedim', 'a', 'informar', 'li', 'detalladament', 'de', 'l', 'ús', 'que', 'es', 'realitza', 'a', 'la', 'nostra', 'pàgina', 'web', 'aquesta', 'informació', 'no', 'revela', 'la', 'seva', 'identitat', 'però', 'sí', 'que', 'permet', 'la', 'seva', 'identificació', 'com', 'a', 'un', 'usuari', 'concret', 'i', 'pot', 'guardar', 'informació', 'relativa', 'a', 'la', 'freqüència', 'amb', 'la', 'que', 'visita', 'la', 'pàgina', 'web', 'les', 'seves', 'preferències', 'de', 'navegació', 'o', 'aquella', 'informació', 'que', 'més', 'l', 'interessa', 'el', 'que', 'ens', 'permet', 'cada', 'vegada', 'que', 'accedeix', 'a', 'www', 'aoc', 'cat', 'millorar', 'la', 'qualitat', 'i', 'la', 'usabilitat', 'de', 'la', 'nostra', 'pàgina', 'web', 'no', 'obstant', 'si', 'les', 'desactiva', 'pot', 'ser', 'que', 'la', 'seva', 'navegació', 'per', 'www', 'aoc', 'cat', 'no', 'sigui', 'òptima', 'i', 'algunes', 'de', 'les', 'seves', 'utilitats', 'no', 'funcionin', 'correctament', 'cookies', 'analítiques', 'galetes', 'de', 'google', 'analytics', 'aquesta', 'pàgina', 'web', 'utilitza', 'google', 'analytics', 'un', 'servei', 'analític', 'del', 'web', 'prestat', 'per', 'google', 'inc', 'una', 'companyia', 'de', 'delaware', 'l', 'oficina', 'principal', 'de', 'la', 'qual', 'es', 'troba', 'a', '1600', 'amphitheatre', 'parkway', 'mountain', 'view', 'califòrnia', 'ca', '94043', 'estats', 'units', 'google', 'la', 'informació', 'que', 'genera', 'la', 'cookie', 'sobre', 'l', 'ús', 'del', 'lloc', 'web', 'incloent', 'l', 'adreça', 'ip', 'serà', 'directament', 'transmesa', 'i', 'arxivada', 'per', 'google', 'en', 'els', 'seus', 'servidors', 'd', 'estats', 'units', 'google', 'utilitzarà', 'aquesta', 'informació', 'per', 'compte', 'nostre', 'amb', 'el', 'propòsit', 'de', 'seguir', 'la', 'pista', 'del', 'seu', 'ús', 'del', 'lloc', 'web', 'google', 'podrà', 'transmetre', 'aquesta', 'informació', 'a', 'tercers', 'quan', 'així', 'ho', 'requereixi', 'la', 'legislació', 'o', 'quan', 'aquests', 'tercers', 'processin', 'la', 'informació', 'per', 'compte', 'de', 'google', 'en', 'aquests', 'casos', 'google', 'no', 'associarà', 'la', 'seva', 'adreça', 'ip', 'amb', 'cap', 'altra', 'dada', 'de', 'què', 'disposi', 'en', 'utilitzar', 'aquesta', 'pàgina', 'web', 'consent', 'el', 'tractament', 'de', 'la', 'seva', 'informació', 'per', 'google', 'en', 'la', 'forma', 'i', 'per', 'als', 'fins', 'anteriorment', 'indicats', 'l', 'exercici', 'de', 'qualsevol', 'dret', 's', 'haurà', 'de', 'realitzar', 'mitjançant', 'comunicació', 'directa', 'amb', 'google', 'per', 'optar', 'per', 'no', 'ser', 'rastrejats', 'per', 'google', 'analytics', 'a', 'través', 'de', 'tots', 'els', 'llocs', 'web', 'podeu', 'consultar', 'http', 'tools', 'google', 'com', 'dlpage', 'gaoptout', 'així', 'mateix', 'també', 'registra', 'quan', 'va', 'ser', 'la', 'primera', 'i', 'l', 'última', 'vegada', 'que', 'l', 'usuari', 'va', 'visitar', 'el', 'web', 'www', 'aoc', 'cat', 'galetes', 'en', 'altres', 'llocs', 'web', 'del', 'consorci', 'aoc', 'les', 'seves', 'finalitats', 'són', 'descrites', 'a', 'la', 'pàgina', 'de', 'privacitat', 'de', 'twitter', 'configuració', 'de', 'l', 'usuari', 'per', 'evitar', 'cookies', 'és', 'cas', 'de', 'dubte', 'pot', 'dirigir', 'se', 'al', 'webmaster', 'del', 'domini', 'creador', 'de', 'la', 'cookie', 'la', 'selecció', 'de', 'l', 'actualitat', 'd', 'administració', 'oberta', 'a', 'la', 'vostra', 'safata']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "# Funció per netejar i tokenitzar el text\n",
    "def preprocess_text(text):\n",
    "    # Neteja el text: treu caràcters no desitjats, converteix a minúscules, etc.\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Substitueix caràcters no alfanumèrics per espais\n",
    "    text = text.lower()  # Converteix a minúscules\n",
    "    words = text.split()  # Tokenitza\n",
    "    return words\n",
    "\n",
    "# Carrega el fitxer de text i processa'l\n",
    "corpus_100MB = []\n",
    "for line in dataset_100MB:\n",
    "    words = preprocess_text(line['text'])\n",
    "    if words:  # Assegura't que la línia no està buida\n",
    "        corpus_100MB.append(words)\n",
    "\n",
    "# Comprova algunes línies per assegurar-te que tot està bé\n",
    "print(corpus_100MB[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament model de similitud de Text Semàntic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "text_semantic = load_dataset(\"projecte-aina/sts-ca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model_100MB = word2vec.Word2Vec(corpus_100MB, vector_size=100, window=5, min_count=10, workers=4, epochs=25)\n",
    "model_100MB.save(\"model_100MB\")\n",
    "# Obtenir un word-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100MB = Word2Vec.load(\"model_100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('frase', 0.7188398241996765), ('grafia', 0.6529539227485657), ('lletra', 0.6300726532936096), ('locució', 0.5698095560073853), ('conjunció', 0.5688847303390503), ('recomanació', 0.5602758526802063), ('mania', 0.5528755187988281), ('mot', 0.5462677478790283), ('idea', 0.535517156124115), ('afirmació', 0.534785807132721)]\n"
     ]
    }
   ],
   "source": [
    "# Exemple: trobar paraules similars\n",
    "similar_words = model_100MB.wv.most_similar('paraula')\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_semantic_train = text_semantic['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Atorga per primer cop les mencions Encarna Sanahuja a la inclusió de la perspectiva de gènere en docència Universitària',\n",
       " 'sentence2': 'Creen la menció M. Encarna Sanahuja a la inclusió de la perspectiva de gènere en docència universitària',\n",
       " 'label': 3.5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_semantic_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprcessament del text_semantic\n",
    "corpus_semantic = []\n",
    "semantic_score = []\n",
    "for line in text_semantic_train:\n",
    "    frase1 = preprocess_text(line['sentence1'])\n",
    "    frase2 = preprocess_text(line['sentence2'])\n",
    "\n",
    "    corpus_semantic.append((frase1, frase2))\n",
    "    semantic_score.append(line['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulari = {}\n",
    "\n",
    "for frases in corpus_semantic:\n",
    "    for frase in frases:\n",
    "        for paraula in frase:\n",
    "            if paraula in vocabulari:\n",
    "                vocabulari[paraula] += 1\n",
    "            else:\n",
    "                vocabulari[paraula] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulari_reduit = {palabra for palabra, frecuencia in vocabulari.items() if frecuencia >= 10}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │     \u001b[38;5;34m16,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m20,736\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_and_compile_model(input_length: int = 100, hidden_size: int = 64, dictionary_size: int = 1000, embedding_size: int = 16) -> tf.keras.Model:\n",
    "    \n",
    "    input_1, input_2 = tf.keras.Input((input_length, ), dtype=tf.int32), tf.keras.Input((input_length, ), dtype=tf.int32)\n",
    "    \n",
    "    # Define Layers\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        dictionary_size, embedding_size, input_length=input_length, mask_zero=True)\n",
    "    \n",
    "    lstm = tf.keras.layers.LSTM(hidden_size)\n",
    "    \n",
    "    concatenate = tf.keras.layers.Concatenate(axis=-1)\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "    output = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    # Pass through the layers\n",
    "    _embedded_1, _embedded_2 = embedding(input_1), embedding(input_2)\n",
    "    _lstm_1, _lstm_2 = lstm(_embedded_1), lstm(_embedded_2)\n",
    "    \n",
    "    _concatenated = concatenate([_lstm_1, _lstm_2])\n",
    "    _hidden_output = hidden(_concatenated)\n",
    "    _output = output(_hidden_output)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=(input_1, input_2), outputs=_output)\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "\n",
    "# Exemple d'ús del model\n",
    "baseline_model = build_and_compile_model()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">764</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │     \u001b[38;5;34m16,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m764\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m20,736\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_and_compile_model(input_length: int = 764, hidden_size: int = 64, dictionary_size: int = 1000, embedding_size: int = 16) -> tf.keras.Model:\n",
    "    \n",
    "    input_1, input_2 = tf.keras.Input((input_length, ), dtype=tf.int32), tf.keras.Input((input_length, ), dtype=tf.int32)\n",
    "    \n",
    "    # Define Layers\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        dictionary_size, embedding_size, input_length=input_length, mask_zero=True)\n",
    "    \n",
    "    lstm = tf.keras.layers.LSTM(hidden_size)\n",
    "    \n",
    "    concatenate = tf.keras.layers.Concatenate(axis=-1)\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "    output = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    # Pass through the layers\n",
    "    _embedded_1, _embedded_2 = embedding(input_1), embedding(input_2)\n",
    "    _lstm_1, _lstm_2 = lstm(_embedded_1), lstm(_embedded_2)\n",
    "    \n",
    "    _concatenated = concatenate([_lstm_1, _lstm_2])\n",
    "    _hidden_output = hidden(_concatenated)\n",
    "    _output = output(_hidden_output)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=(input_1, input_2), outputs=_output)\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "\n",
    "# Exemple d'ús del model\n",
    "baseline_model = build_and_compile_model()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def build_and_compile_model(hidden_size: int = 64) -> tf.keras.Model:\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Concatenate(axis=-1, ),\n",
    "      tf.keras.layers.Dense(hidden_size, activation='relu'),\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model\n",
    "\n",
    "# Exemple d'ús del model\n",
    "baseline_model = build_and_compile_model()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para calcular la representación one-hot de un texto\n",
    "def compute_one_hot_encoding(text, vocabulari):\n",
    "    \"\"\"\n",
    "    Genera la representación one-hot de un texto utilizando un vocabulario predefinido.\n",
    "    \"\"\"\n",
    "    one_hot_vector = np.zeros(len(vocabulari))\n",
    "    vocabulario_list = list(vocabulari)\n",
    "    for palabra in text:\n",
    "        if palabra in vocabulari:\n",
    "            index = vocabulario_list.index(palabra)\n",
    "            one_hot_vector[index] = 1\n",
    "        \n",
    "    return one_hot_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar les frases de corpus_semantic a vectors\n",
    "one_hot_corpus_semantic = corpus_semantic.copy()\n",
    "for i, (frase1, frase2) in enumerate(one_hot_corpus_semantic):\n",
    "    one_hot_corpus_semantic[i] = (compute_one_hot_encoding(frase1, vocabulari_reduit), \n",
    "                                    compute_one_hot_encoding(frase2, vocabulari_reduit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 1.8048 - val_loss: 0.8186\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.8176 - val_loss: 0.7666\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.6937 - val_loss: 0.7566\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.6056 - val_loss: 0.7558\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5516 - val_loss: 0.7536\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4925 - val_loss: 0.7498\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4901 - val_loss: 0.7520\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4624 - val_loss: 0.7587\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4160 - val_loss: 0.7496\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3992 - val_loss: 0.7598\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3765 - val_loss: 0.7684\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3482 - val_loss: 0.7657\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3187 - val_loss: 0.7701\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3080 - val_loss: 0.7703\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3094 - val_loss: 0.7773\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2767 - val_loss: 0.7697\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2596 - val_loss: 0.7929\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2459 - val_loss: 0.7862\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2343 - val_loss: 0.7867\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2233 - val_loss: 0.7877\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2177 - val_loss: 0.7989\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1907 - val_loss: 0.8012\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1979 - val_loss: 0.8115\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1769 - val_loss: 0.8042\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1763 - val_loss: 0.8143\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1827 - val_loss: 0.8085\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1893 - val_loss: 0.8194\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1624 - val_loss: 0.8189\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1600 - val_loss: 0.8194\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1593 - val_loss: 0.8225\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1655 - val_loss: 0.8112\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1513 - val_loss: 0.8294\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1523 - val_loss: 0.8069\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1392 - val_loss: 0.8198\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1336 - val_loss: 0.8168\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1360 - val_loss: 0.8264\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1312 - val_loss: 0.8156\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1350 - val_loss: 0.8313\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1350 - val_loss: 0.8207\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1378 - val_loss: 0.8189\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1349 - val_loss: 0.8278\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1274 - val_loss: 0.8298\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1246 - val_loss: 0.8220\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1158 - val_loss: 0.8296\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1227 - val_loss: 0.8293\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1115 - val_loss: 0.8374\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1164 - val_loss: 0.8208\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1242 - val_loss: 0.8333\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1108 - val_loss: 0.8255\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1134 - val_loss: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24ac40d5ad0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Entrenament de la xarxa amb els vectors de les frases ####\n",
    "\n",
    "# Convertir les llistes de tuples a arrays de NumPy\n",
    "vectors_1 = np.array([pair[0] for pair in one_hot_corpus_semantic])\n",
    "vectors_2 = np.array([pair[1] for pair in one_hot_corpus_semantic])\n",
    "\n",
    "# Comprovar si hi ha valors fora de rang i substituir-los\n",
    "vectors_1 = np.clip(vectors_1, 0, 1)\n",
    "vectors_2 = np.clip(vectors_2, 0, 1)\n",
    "\n",
    "# Convertir les llistes de similituds a un array de NumPy\n",
    "semantic_score = np.array(semantic_score)\n",
    "\n",
    "baseline_model.fit(\n",
    "    [vectors_1, vectors_2], \n",
    "    semantic_score, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de dos nuevas frases a predecir\n",
    "new_sentence1 = \"Hola \"\n",
    "new_sentence2 = \"This is another new sentence\"\n",
    "\n",
    "# Convertir las frases a representaciones one-hot\n",
    "new_vector1 = compute_one_hot_encoding(new_sentence1, vocabulari_reduit)\n",
    "new_vector2 = compute_one_hot_encoding(new_sentence2, vocabulari_reduit)\n",
    "\n",
    "# Hacer la predicción de similitud\n",
    "similarity_prediction = baseline_model.predict([[new_vector1], [new_vector2]])\n",
    "\n",
    "print(\"Similitud predicha entre las dos frases:\", similarity_prediction[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Models Word2Vec pre-entrenats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │     \u001b[38;5;34m16,000\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m20,736\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,057</span> (176.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,057\u001b[0m (176.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_and_compile_model(input_length: int = 100, hidden_size: int = 64, dictionary_size: int = 1000, embedding_size: int = 16) -> tf.keras.Model:\n",
    "    \n",
    "    input_1, input_2 = tf.keras.Input((input_length, ), dtype=tf.int32), tf.keras.Input((input_length, ), dtype=tf.int32)\n",
    "    \n",
    "    # Define Layers\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        dictionary_size, embedding_size, input_length=input_length, mask_zero=True)\n",
    "    \n",
    "    lstm = tf.keras.layers.LSTM(hidden_size)\n",
    "    \n",
    "    concatenate = tf.keras.layers.Concatenate(axis=-1)\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "    output = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    # Pass through the layers\n",
    "    _embedded_1, _embedded_2 = embedding(input_1), embedding(input_2)\n",
    "    _lstm_1, _lstm_2 = lstm(_embedded_1), lstm(_embedded_2)\n",
    "    \n",
    "    _concatenated = concatenate([_lstm_1, _lstm_2])\n",
    "    _hidden_output = hidden(_concatenated)\n",
    "    _output = output(_hidden_output)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=(input_1, input_2), outputs=_output)\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "\n",
    "# Exemple d'ús del model\n",
    "baseline_model = build_and_compile_model()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Word2Vec + Mean \n",
    "def compute_mean_embedding(text, model, embedding_dim):\n",
    "    \"\"\"\n",
    "    Agafa els vectors d'embeddings de cada paraula en una frase o document i \n",
    "    calcula la mitjana dels vectors per obtenir una única representació vectorial \n",
    "    per a la frase o document.\n",
    "    \"\"\"\n",
    "    vectors = [model[word] for word in text if word in model]\n",
    "    if vectors:\n",
    "        mean_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        mean_vector = np.zeros(embedding_dim)\n",
    "    return mean_vector\n",
    "\n",
    "\n",
    "# Word2Vec + Mean Ponderada\n",
    "def compute_weighted_mean_embedding(text, model, word2tfidf, embedding_dim):\n",
    "    \"\"\"\n",
    "    Utilitza una ponderació per a cada vector de paraula, com ara la freqüència \n",
    "    inversa del document (TF-IDF), per calcular una mitjana ponderada dels vectors.\n",
    "    \"\"\"\n",
    "    vectors = [model[word] * word2tfidf[word] for word in text if word in model and word in word2tfidf]\n",
    "    if vectors:\n",
    "        weighted_mean_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        weighted_mean_vector = np.zeros(embedding_dim)\n",
    "    return weighted_mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar les frases de corpus_semantic a vectors\n",
    "mean_embbeding_corpus_semantic = corpus_semantic.copy()\n",
    "for i, (frase1, frase2) in enumerate(mean_embbeding_corpus_semantic):\n",
    "    mean_embbeding_corpus_semantic[i] = (compute_mean_embedding(frase1, model_100MB.wv, 100), \n",
    "                                        compute_mean_embedding(frase2, model_100MB.wv, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 100)\n",
      "(2073, 100)\n",
      "(2073,)\n",
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - loss: 0.9921 - val_loss: 0.6544\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.6827 - val_loss: 0.7196\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.7162 - val_loss: 0.6233\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.6877 - val_loss: 0.6375\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.6734 - val_loss: 0.6852\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.6844 - val_loss: 0.6304\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.6565 - val_loss: 0.6417\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.6670 - val_loss: 0.6827\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.6817 - val_loss: 0.6352\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.6733 - val_loss: 0.6240\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.6502 - val_loss: 0.6228\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.6610 - val_loss: 0.6312\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6662 - val_loss: 0.6469\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6792 - val_loss: 0.6205\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.6802 - val_loss: 0.6201\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6530 - val_loss: 0.6205\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.6582 - val_loss: 0.6246\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.6625 - val_loss: 0.6211\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.6638 - val_loss: 0.6204\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6700 - val_loss: 0.6205\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.6533 - val_loss: 0.6216\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6693 - val_loss: 0.6210\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6633 - val_loss: 0.6431\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.6832 - val_loss: 0.6243\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6720 - val_loss: 0.6301\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6726 - val_loss: 0.6207\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6769 - val_loss: 0.6212\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.6803 - val_loss: 0.6207\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6507 - val_loss: 0.6304\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 0.6614 - val_loss: 0.6216\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6753 - val_loss: 0.6207\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.6770 - val_loss: 0.6425\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.6662 - val_loss: 0.6542\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.6781 - val_loss: 0.6215\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6511 - val_loss: 0.6910\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6773 - val_loss: 0.6205\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6621 - val_loss: 0.6267\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.6538 - val_loss: 0.6564\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6705 - val_loss: 0.6215\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.6702 - val_loss: 0.6211\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6421 - val_loss: 0.6233\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6798 - val_loss: 0.6211\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.6502 - val_loss: 0.6205\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6551 - val_loss: 0.6213\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.6516 - val_loss: 0.6428\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.6697 - val_loss: 0.6218\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.6622 - val_loss: 0.6232\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.6390 - val_loss: 0.6214\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.6739 - val_loss: 0.6381\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.6535 - val_loss: 0.6213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24a85111010>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Entrenament de la xarxa amb els vectors de les frases ####\n",
    "\n",
    "# Convertir les llistes de tuples a arrays de NumPy\n",
    "vectors_1 = np.array([pair[0] for pair in mean_embbeding_corpus_semantic])\n",
    "vectors_2 = np.array([pair[1] for pair in mean_embbeding_corpus_semantic])\n",
    "\n",
    "# Comprovar si hi ha valors fora de rang i substituir-los\n",
    "vectors_1 = np.clip(vectors_1, 0, 999)\n",
    "vectors_2 = np.clip(vectors_2, 0, 999)\n",
    "\n",
    "# Convertir les llistes de similituds a un array de NumPy\n",
    "semantic_score = np.array(semantic_score)\n",
    "\n",
    "print(vectors_1.shape)\n",
    "print(vectors_2.shape)\n",
    "print(semantic_score.shape)\n",
    "\n",
    "baseline_model.fit(\n",
    "    [vectors_1, vectors_2], \n",
    "    semantic_score, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-md==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_md-3.7.0/ca_core_news_md-3.7.0-py3-none-any.whl (49.2 MB)\n",
      "     ---------------------------------------- 0.0/49.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/49.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/49.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/49.2 MB 217.9 kB/s eta 0:03:46\n",
      "     --------------------------------------- 0.0/49.2 MB 245.8 kB/s eta 0:03:21\n",
      "     --------------------------------------- 0.1/49.2 MB 599.1 kB/s eta 0:01:22\n",
      "     ---------------------------------------- 0.4/49.2 MB 1.8 MB/s eta 0:00:27\n",
      "      --------------------------------------- 0.9/49.2 MB 3.3 MB/s eta 0:00:15\n",
      "     - -------------------------------------- 2.0/49.2 MB 6.2 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 2.9/49.2 MB 8.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.8/49.2 MB 9.4 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 4.8/49.2 MB 10.6 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 4.9/49.2 MB 10.4 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 6.1/49.2 MB 11.2 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 7.0/49.2 MB 12.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 8.0/49.2 MB 12.8 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 8.6/49.2 MB 13.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 9.6/49.2 MB 13.3 MB/s eta 0:00:03\n",
      "     ------- ------------------------------- 10.0/49.2 MB 13.3 MB/s eta 0:00:03\n",
      "     -------- ------------------------------ 11.0/49.2 MB 19.3 MB/s eta 0:00:02\n",
      "     --------- ----------------------------- 11.8/49.2 MB 19.8 MB/s eta 0:00:02\n",
      "     ---------- ---------------------------- 12.8/49.2 MB 19.3 MB/s eta 0:00:02\n",
      "     ---------- ---------------------------- 13.8/49.2 MB 18.7 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 14.7/49.2 MB 19.3 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 15.5/49.2 MB 19.8 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 16.3/49.2 MB 19.3 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 17.2/49.2 MB 19.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 17.9/49.2 MB 20.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 18.4/49.2 MB 19.3 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 19.4/49.2 MB 21.1 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 21.0/49.2 MB 21.1 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 21.8/49.2 MB 21.1 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 21.9/49.2 MB 20.5 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 23.3/49.2 MB 21.1 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 24.0/49.2 MB 21.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 25.4/49.2 MB 22.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 26.4/49.2 MB 21.8 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 27.8/49.2 MB 23.4 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 28.0/49.2 MB 22.5 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 28.7/49.2 MB 23.4 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 29.7/49.2 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 30.5/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 31.7/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 32.0/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 33.2/49.2 MB 20.5 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 34.4/49.2 MB 21.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 35.7/49.2 MB 21.8 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 36.7/49.2 MB 22.6 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 37.2/49.2 MB 19.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 38.5/49.2 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 38.6/49.2 MB 19.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 39.9/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 41.1/49.2 MB 22.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 41.1/49.2 MB 22.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 42.4/49.2 MB 22.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 42.4/49.2 MB 22.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 42.9/49.2 MB 19.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 44.7/49.2 MB 19.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 45.4/49.2 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 45.9/49.2 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 46.8/49.2 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 47.9/49.2 MB 18.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  49.2/49.2 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 49.2/49.2 MB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ca-core-news-md==3.7.0) (3.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pathy>=0.10.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-md==3.7.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!py -m spacy download ca_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_md = spacy.load('ca_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_mean_embedding(text1, text2, model):\n",
    "    \"\"\"\n",
    "    Agafa els vectors d'embeddings de cada paraula en una frase o document i \n",
    "    calcula la mitjana dels vectors per obtenir una única representació vectorial \n",
    "    per a la frase o document.\n",
    "    \"\"\"\n",
    "    text1 = ' '.join(text1)\n",
    "    text2 = ' '.join(text2)\n",
    "    frase1 = model(text1).vector\n",
    "    frase2 = model(text2).vector\n",
    "    \n",
    "    return frase1, frase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar les frases de corpus_semantic a vectors\n",
    "spacy_mean_embbeding_corpus_semantic = corpus_semantic.copy()\n",
    "for i, (frase1, frase2) in enumerate(spacy_mean_embbeding_corpus_semantic):\n",
    "    \n",
    "    frase1, frase2 = spacy_mean_embedding(frase1, frase2, nlp_md)\n",
    "    spacy_mean_embbeding_corpus_semantic[i] = (frase1, frase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073, 300)\n",
      "(2073, 300)\n",
      "(2073,)\n",
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 348ms/step - loss: 0.9142 - val_loss: 0.6697\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - loss: 0.6794 - val_loss: 0.6241\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - loss: 0.6562 - val_loss: 0.6427\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 380ms/step - loss: 0.6672 - val_loss: 0.6415\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 266ms/step - loss: 0.6285 - val_loss: 0.6420\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 355ms/step - loss: 0.6285 - val_loss: 0.6506\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 375ms/step - loss: 0.6226 - val_loss: 0.6543\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 478ms/step - loss: 0.6036 - val_loss: 0.6429\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 378ms/step - loss: 0.6031 - val_loss: 0.6561\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 401ms/step - loss: 0.6169 - val_loss: 0.6420\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 374ms/step - loss: 0.5954 - val_loss: 0.6749\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.5890 - val_loss: 0.6493\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 257ms/step - loss: 0.5927 - val_loss: 0.6736\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.5852 - val_loss: 0.6599\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.5874 - val_loss: 0.6850\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 268ms/step - loss: 0.5604 - val_loss: 0.6589\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 265ms/step - loss: 0.5790 - val_loss: 0.6783\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: 0.5410 - val_loss: 0.6597\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: 0.5580 - val_loss: 0.6834\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.5554 - val_loss: 0.6742\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 0.5424 - val_loss: 0.6995\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 0.5413 - val_loss: 0.7009\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 258ms/step - loss: 0.5441 - val_loss: 0.7100\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - loss: 0.5531 - val_loss: 0.6584\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: 0.5406 - val_loss: 0.7038\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.5389 - val_loss: 0.7024\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 265ms/step - loss: 0.5109 - val_loss: 0.7008\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 265ms/step - loss: 0.5144 - val_loss: 0.6989\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - loss: 0.5129 - val_loss: 0.6846\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 257ms/step - loss: 0.5128 - val_loss: 0.6844\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 251ms/step - loss: 0.5081 - val_loss: 0.6974\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.4873 - val_loss: 0.7320\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: 0.4888 - val_loss: 0.7025\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.4799 - val_loss: 0.6964\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: 0.4626 - val_loss: 0.6958\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.4896 - val_loss: 0.7066\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.4605 - val_loss: 0.7077\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - loss: 0.4884 - val_loss: 0.7113\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - loss: 0.4808 - val_loss: 0.6891\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 0.4700 - val_loss: 0.7109\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: 0.4855 - val_loss: 0.6962\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: 0.5054 - val_loss: 0.7089\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 256ms/step - loss: 0.4664 - val_loss: 0.6958\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: 0.4733 - val_loss: 0.7146\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 269ms/step - loss: 0.4491 - val_loss: 0.7097\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: 0.4553 - val_loss: 0.7269\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: 0.4494 - val_loss: 0.7098\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: 0.4402 - val_loss: 0.7269\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - loss: 0.4262 - val_loss: 0.7346\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - loss: 0.4323 - val_loss: 0.7289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24ac1cc59d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Entrenament de la xarxa amb els vectors de les frases ####\n",
    "\n",
    "# Convertir les llistes de tuples a arrays de NumPy\n",
    "vectors_1 = np.array([pair[0] for pair in spacy_mean_embbeding_corpus_semantic])\n",
    "vectors_2 = np.array([pair[1] for pair in spacy_mean_embbeding_corpus_semantic])\n",
    "\n",
    "# Comprovar si hi ha valors fora de rang i substituir-los\n",
    "#vectors_1 = np.clip(vectors_1, 0, 999)\n",
    "#vectors_2 = np.clip(vectors_2, 0, 999)\n",
    "\n",
    "# Convertir les llistes de similituds a un array de NumPy\n",
    "semantic_score = np.array(semantic_score)\n",
    "\n",
    "print(vectors_1.shape)\n",
    "print(vectors_2.shape)\n",
    "print(semantic_score.shape)\n",
    "\n",
    "baseline_model.fit(\n",
    "    [vectors_1, vectors_2], \n",
    "    semantic_score, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-trf==3.7.2\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_trf-3.7.2/ca_core_news_trf-3.7.2-py3-none-any.whl (457.1 MB)\n",
      "     ---------------------------------------- 0.0/457.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/457.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/457.1 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/457.1 MB 262.6 kB/s eta 0:29:01\n",
      "     -------------------------------------- 0.1/457.1 MB 363.1 kB/s eta 0:20:59\n",
      "     ---------------------------------------- 0.2/457.1 MB 1.0 MB/s eta 0:07:22\n",
      "     ---------------------------------------- 0.5/457.1 MB 2.0 MB/s eta 0:03:48\n",
      "     ---------------------------------------- 1.0/457.1 MB 3.8 MB/s eta 0:02:01\n",
      "     ---------------------------------------- 1.9/457.1 MB 5.8 MB/s eta 0:01:18\n",
      "     ---------------------------------------- 2.8/457.1 MB 7.5 MB/s eta 0:01:01\n",
      "     ---------------------------------------- 3.6/457.1 MB 8.6 MB/s eta 0:00:53\n",
      "     ---------------------------------------- 4.6/457.1 MB 9.8 MB/s eta 0:00:47\n",
      "     --------------------------------------- 5.5/457.1 MB 10.7 MB/s eta 0:00:43\n",
      "      -------------------------------------- 6.5/457.1 MB 11.2 MB/s eta 0:00:41\n",
      "      -------------------------------------- 7.5/457.1 MB 12.2 MB/s eta 0:00:37\n",
      "      -------------------------------------- 8.3/457.1 MB 12.1 MB/s eta 0:00:38\n",
      "      -------------------------------------- 8.8/457.1 MB 12.5 MB/s eta 0:00:36\n",
      "      -------------------------------------- 9.6/457.1 MB 12.8 MB/s eta 0:00:36\n",
      "      ------------------------------------- 10.7/457.1 MB 17.7 MB/s eta 0:00:26\n",
      "      ------------------------------------- 11.6/457.1 MB 18.7 MB/s eta 0:00:24\n",
      "     - ------------------------------------ 12.2/457.1 MB 18.2 MB/s eta 0:00:25\n",
      "     - ------------------------------------ 12.5/457.1 MB 16.8 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 13.7/457.1 MB 17.2 MB/s eta 0:00:26\n",
      "     - ------------------------------------ 13.8/457.1 MB 16.8 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 15.3/457.1 MB 16.8 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 16.1/457.1 MB 16.8 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 16.7/457.1 MB 16.4 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 17.9/457.1 MB 16.8 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 18.1/457.1 MB 16.4 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 18.6/457.1 MB 16.4 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 19.9/457.1 MB 16.4 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 20.7/457.1 MB 15.6 MB/s eta 0:00:28\n",
      "     - ------------------------------------ 21.3/457.1 MB 16.0 MB/s eta 0:00:28\n",
      "     - ------------------------------------ 21.8/457.1 MB 16.0 MB/s eta 0:00:28\n",
      "     - ------------------------------------ 23.4/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 24.3/457.1 MB 18.2 MB/s eta 0:00:24\n",
      "     -- ----------------------------------- 25.0/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 25.5/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 26.1/457.1 MB 17.2 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 27.3/457.1 MB 17.7 MB/s eta 0:00:25\n",
      "     -- ----------------------------------- 28.2/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 28.8/457.1 MB 17.7 MB/s eta 0:00:25\n",
      "     -- ----------------------------------- 29.6/457.1 MB 17.2 MB/s eta 0:00:25\n",
      "     -- ----------------------------------- 29.9/457.1 MB 16.0 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 31.1/457.1 MB 16.4 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 31.7/457.1 MB 16.4 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 32.2/457.1 MB 17.2 MB/s eta 0:00:25\n",
      "     -- ----------------------------------- 33.1/457.1 MB 16.0 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 34.2/457.1 MB 16.0 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 34.5/457.1 MB 15.6 MB/s eta 0:00:28\n",
      "     --- ---------------------------------- 36.3/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 36.8/457.1 MB 16.8 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 37.3/457.1 MB 16.0 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 37.7/457.1 MB 15.6 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 38.3/457.1 MB 15.2 MB/s eta 0:00:28\n",
      "     --- ---------------------------------- 39.6/457.1 MB 16.0 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 40.6/457.1 MB 16.8 MB/s eta 0:00:25\n",
      "     --- ---------------------------------- 41.5/457.1 MB 17.7 MB/s eta 0:00:24\n",
      "     --- ---------------------------------- 41.9/457.1 MB 16.8 MB/s eta 0:00:25\n",
      "     --- ---------------------------------- 41.9/457.1 MB 16.8 MB/s eta 0:00:25\n",
      "     --- ---------------------------------- 44.2/457.1 MB 17.7 MB/s eta 0:00:24\n",
      "     --- ---------------------------------- 45.0/457.1 MB 18.7 MB/s eta 0:00:23\n",
      "     --- ---------------------------------- 45.7/457.1 MB 17.7 MB/s eta 0:00:24\n",
      "     --- ---------------------------------- 46.1/457.1 MB 16.0 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 47.0/457.1 MB 16.0 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 48.0/457.1 MB 18.2 MB/s eta 0:00:23\n",
      "     ---- --------------------------------- 48.2/457.1 MB 18.7 MB/s eta 0:00:22\n",
      "     ---- --------------------------------- 49.3/457.1 MB 16.8 MB/s eta 0:00:25\n",
      "     ---- --------------------------------- 51.4/457.1 MB 18.7 MB/s eta 0:00:22\n",
      "     ---- --------------------------------- 51.9/457.1 MB 19.2 MB/s eta 0:00:22\n",
      "     ---- --------------------------------- 53.0/457.1 MB 19.9 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 54.1/457.1 MB 19.3 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 55.3/457.1 MB 19.8 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 55.7/457.1 MB 19.2 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 56.2/457.1 MB 19.2 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 57.9/457.1 MB 21.1 MB/s eta 0:00:19\n",
      "     ---- --------------------------------- 59.0/457.1 MB 23.4 MB/s eta 0:00:18\n",
      "     ----- -------------------------------- 61.2/457.1 MB 22.6 MB/s eta 0:00:18\n",
      "     ----- -------------------------------- 61.7/457.1 MB 23.4 MB/s eta 0:00:17\n",
      "     ----- -------------------------------- 61.7/457.1 MB 23.4 MB/s eta 0:00:17\n",
      "     ----- -------------------------------- 61.8/457.1 MB 18.7 MB/s eta 0:00:22\n",
      "     ----- -------------------------------- 64.3/457.1 MB 21.1 MB/s eta 0:00:19\n",
      "     ----- -------------------------------- 65.5/457.1 MB 21.1 MB/s eta 0:00:19\n",
      "     ----- -------------------------------- 65.8/457.1 MB 19.3 MB/s eta 0:00:21\n",
      "     ----- -------------------------------- 66.6/457.1 MB 23.4 MB/s eta 0:00:17\n",
      "     ----- -------------------------------- 66.6/457.1 MB 23.4 MB/s eta 0:00:17\n",
      "     ----- -------------------------------- 68.0/457.1 MB 19.3 MB/s eta 0:00:21\n",
      "     ----- -------------------------------- 69.0/457.1 MB 19.8 MB/s eta 0:00:20\n",
      "     ----- -------------------------------- 69.9/457.1 MB 17.7 MB/s eta 0:00:22\n",
      "     ----- -------------------------------- 70.0/457.1 MB 17.2 MB/s eta 0:00:23\n",
      "     ----- -------------------------------- 71.1/457.1 MB 16.4 MB/s eta 0:00:24\n",
      "     ----- -------------------------------- 71.3/457.1 MB 16.0 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 73.1/457.1 MB 19.3 MB/s eta 0:00:20\n",
      "     ------ ------------------------------- 74.7/457.1 MB 17.7 MB/s eta 0:00:22\n",
      "     ------ ------------------------------- 75.6/457.1 MB 16.8 MB/s eta 0:00:23\n",
      "     ------ ------------------------------- 75.7/457.1 MB 16.8 MB/s eta 0:00:23\n",
      "     ------ ------------------------------- 75.7/457.1 MB 16.8 MB/s eta 0:00:23\n",
      "     ------ ------------------------------- 75.7/457.1 MB 16.8 MB/s eta 0:00:23\n",
      "     ------ ------------------------------- 76.0/457.1 MB 14.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 79.5/457.1 MB 18.2 MB/s eta 0:00:21\n",
      "     ------ ------------------------------- 80.3/457.1 MB 19.3 MB/s eta 0:00:20\n",
      "     ------ ------------------------------- 81.4/457.1 MB 19.3 MB/s eta 0:00:20\n",
      "     ------ ------------------------------- 82.2/457.1 MB 20.5 MB/s eta 0:00:19\n",
      "     ------ ------------------------------- 83.5/457.1 MB 19.3 MB/s eta 0:00:20\n",
      "     ------- ------------------------------ 84.6/457.1 MB 19.2 MB/s eta 0:00:20\n",
      "     ------- ------------------------------ 85.4/457.1 MB 19.9 MB/s eta 0:00:19\n",
      "     ------- ------------------------------ 86.3/457.1 MB 28.5 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 89.1/457.1 MB 26.2 MB/s eta 0:00:15\n",
      "     ------- ------------------------------ 89.5/457.1 MB 25.2 MB/s eta 0:00:15\n",
      "     ------- ------------------------------ 90.4/457.1 MB 23.4 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 92.4/457.1 MB 26.2 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 93.8/457.1 MB 26.2 MB/s eta 0:00:14\n",
      "     ------- ------------------------------ 94.0/457.1 MB 25.2 MB/s eta 0:00:15\n",
      "     ------- ------------------------------ 94.0/457.1 MB 25.2 MB/s eta 0:00:15\n",
      "     -------- ----------------------------- 96.5/457.1 MB 21.8 MB/s eta 0:00:17\n",
      "     -------- ----------------------------- 97.5/457.1 MB 23.4 MB/s eta 0:00:16\n",
      "     -------- ----------------------------- 98.2/457.1 MB 20.5 MB/s eta 0:00:18\n",
      "     -------- ----------------------------- 99.6/457.1 MB 20.5 MB/s eta 0:00:18\n",
      "     -------- ---------------------------- 100.6/457.1 MB 21.1 MB/s eta 0:00:17\n",
      "     -------- ---------------------------- 100.9/457.1 MB 21.8 MB/s eta 0:00:17\n",
      "     -------- ---------------------------- 102.6/457.1 MB 19.9 MB/s eta 0:00:18\n",
      "     -------- ---------------------------- 104.4/457.1 MB 29.7 MB/s eta 0:00:12\n",
      "     -------- ---------------------------- 105.4/457.1 MB 26.2 MB/s eta 0:00:14\n",
      "     -------- ---------------------------- 106.9/457.1 MB 24.2 MB/s eta 0:00:15\n",
      "     -------- ---------------------------- 107.7/457.1 MB 25.2 MB/s eta 0:00:14\n",
      "     -------- ---------------------------- 108.3/457.1 MB 25.2 MB/s eta 0:00:14\n",
      "     -------- ---------------------------- 109.5/457.1 MB 22.5 MB/s eta 0:00:16\n",
      "     -------- ---------------------------- 109.9/457.1 MB 21.8 MB/s eta 0:00:16\n",
      "     -------- ---------------------------- 110.7/457.1 MB 20.5 MB/s eta 0:00:17\n",
      "     --------- --------------------------- 111.7/457.1 MB 22.6 MB/s eta 0:00:16\n",
      "     --------- --------------------------- 112.9/457.1 MB 21.1 MB/s eta 0:00:17\n",
      "     --------- --------------------------- 114.0/457.1 MB 19.3 MB/s eta 0:00:18\n",
      "     --------- --------------------------- 115.5/457.1 MB 19.8 MB/s eta 0:00:18\n",
      "     --------- --------------------------- 117.3/457.1 MB 20.5 MB/s eta 0:00:17\n",
      "     --------- --------------------------- 117.3/457.1 MB 20.5 MB/s eta 0:00:17\n",
      "     --------- --------------------------- 118.9/457.1 MB 22.6 MB/s eta 0:00:15\n",
      "     --------- --------------------------- 120.7/457.1 MB 26.2 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 121.2/457.1 MB 26.2 MB/s eta 0:00:13\n",
      "     --------- --------------------------- 121.4/457.1 MB 21.9 MB/s eta 0:00:16\n",
      "     ---------- -------------------------- 124.0/457.1 MB 26.2 MB/s eta 0:00:13\n",
      "     ---------- -------------------------- 125.3/457.1 MB 26.2 MB/s eta 0:00:13\n",
      "     ---------- -------------------------- 125.9/457.1 MB 24.2 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 127.5/457.1 MB 24.2 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 128.7/457.1 MB 26.2 MB/s eta 0:00:13\n",
      "     ---------- -------------------------- 129.8/457.1 MB 25.1 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 130.5/457.1 MB 23.4 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 131.1/457.1 MB 24.2 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 131.5/457.1 MB 25.1 MB/s eta 0:00:13\n",
      "     ---------- -------------------------- 132.6/457.1 MB 23.4 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 135.1/457.1 MB 24.2 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 135.9/457.1 MB 22.6 MB/s eta 0:00:15\n",
      "     ----------- ------------------------- 136.7/457.1 MB 21.9 MB/s eta 0:00:15\n",
      "     ----------- ------------------------- 136.8/457.1 MB 20.5 MB/s eta 0:00:16\n",
      "     ----------- ------------------------- 137.2/457.1 MB 19.8 MB/s eta 0:00:17\n",
      "     ----------- ------------------------- 138.1/457.1 MB 19.2 MB/s eta 0:00:17\n",
      "     ----------- ------------------------- 139.1/457.1 MB 18.7 MB/s eta 0:00:18\n",
      "     ----------- ------------------------- 140.6/457.1 MB 19.8 MB/s eta 0:00:16\n",
      "     ----------- ------------------------- 142.4/457.1 MB 23.4 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 143.1/457.1 MB 21.1 MB/s eta 0:00:15\n",
      "     ----------- ------------------------- 143.2/457.1 MB 21.1 MB/s eta 0:00:15\n",
      "     ----------- ------------------------- 143.4/457.1 MB 18.2 MB/s eta 0:00:18\n",
      "     ----------- ------------------------- 145.5/457.1 MB 18.7 MB/s eta 0:00:17\n",
      "     ----------- ------------------------- 147.4/457.1 MB 22.6 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 147.9/457.1 MB 23.4 MB/s eta 0:00:14\n",
      "     ------------ ------------------------ 148.3/457.1 MB 21.9 MB/s eta 0:00:15\n",
      "     ------------ ------------------------ 149.5/457.1 MB 23.4 MB/s eta 0:00:14\n",
      "     ------------ ------------------------ 151.3/457.1 MB 22.6 MB/s eta 0:00:14\n",
      "     ------------ ------------------------ 153.3/457.1 MB 25.1 MB/s eta 0:00:13\n",
      "     ------------ ------------------------ 153.7/457.1 MB 28.4 MB/s eta 0:00:11\n",
      "     ------------ ------------------------ 153.7/457.1 MB 28.4 MB/s eta 0:00:11\n",
      "     ------------ ------------------------ 155.6/457.1 MB 23.4 MB/s eta 0:00:13\n",
      "     ------------ ------------------------ 156.4/457.1 MB 22.6 MB/s eta 0:00:14\n",
      "     ------------ ------------------------ 157.5/457.1 MB 21.1 MB/s eta 0:00:15\n",
      "     ------------ ------------------------ 160.0/457.1 MB 26.2 MB/s eta 0:00:12\n",
      "     ------------- ----------------------- 161.6/457.1 MB 25.2 MB/s eta 0:00:12\n",
      "     ------------- ----------------------- 162.9/457.1 MB 24.2 MB/s eta 0:00:13\n",
      "     ------------- ----------------------- 163.2/457.1 MB 21.8 MB/s eta 0:00:14\n",
      "     ------------- ----------------------- 163.5/457.1 MB 19.9 MB/s eta 0:00:15\n",
      "     ------------- ----------------------- 165.4/457.1 MB 24.2 MB/s eta 0:00:13\n",
      "     ------------- ----------------------- 167.0/457.1 MB 26.2 MB/s eta 0:00:12\n",
      "     ------------- ----------------------- 168.6/457.1 MB 27.3 MB/s eta 0:00:11\n",
      "     ------------- ----------------------- 169.0/457.1 MB 24.2 MB/s eta 0:00:12\n",
      "     ------------- ----------------------- 170.7/457.1 MB 23.4 MB/s eta 0:00:13\n",
      "     ------------- ----------------------- 172.6/457.1 MB 24.2 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 173.8/457.1 MB 31.2 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 174.6/457.1 MB 31.2 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 175.3/457.1 MB 26.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 176.9/457.1 MB 27.3 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 178.1/457.1 MB 26.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 179.3/457.1 MB 28.4 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 181.0/457.1 MB 28.4 MB/s eta 0:00:10\n",
      "     -------------- ---------------------- 182.1/457.1 MB 26.2 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 182.6/457.1 MB 24.3 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 182.6/457.1 MB 24.3 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 183.2/457.1 MB 19.3 MB/s eta 0:00:15\n",
      "     --------------- --------------------- 185.8/457.1 MB 24.2 MB/s eta 0:00:12\n",
      "     --------------- --------------------- 186.8/457.1 MB 23.4 MB/s eta 0:00:12\n",
      "     --------------- --------------------- 187.5/457.1 MB 22.6 MB/s eta 0:00:12\n",
      "     --------------- --------------------- 188.6/457.1 MB 20.5 MB/s eta 0:00:14\n",
      "     --------------- --------------------- 190.4/457.1 MB 21.1 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 191.1/457.1 MB 20.5 MB/s eta 0:00:14\n",
      "     --------------- --------------------- 191.8/457.1 MB 20.5 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 191.8/457.1 MB 20.5 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 193.2/457.1 MB 23.4 MB/s eta 0:00:12\n",
      "     --------------- --------------------- 194.1/457.1 MB 20.5 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 196.0/457.1 MB 20.5 MB/s eta 0:00:13\n",
      "     --------------- --------------------- 197.3/457.1 MB 21.8 MB/s eta 0:00:12\n",
      "     ---------------- -------------------- 198.0/457.1 MB 21.1 MB/s eta 0:00:13\n",
      "     ---------------- -------------------- 199.4/457.1 MB 21.1 MB/s eta 0:00:13\n",
      "     ---------------- -------------------- 200.6/457.1 MB 21.1 MB/s eta 0:00:13\n",
      "     ---------------- -------------------- 202.0/457.1 MB 21.8 MB/s eta 0:00:12\n",
      "     ---------------- -------------------- 203.6/457.1 MB 28.4 MB/s eta 0:00:09\n",
      "     ---------------- -------------------- 204.9/457.1 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 206.0/457.1 MB 26.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 206.3/457.1 MB 23.4 MB/s eta 0:00:11\n",
      "     ---------------- -------------------- 206.7/457.1 MB 21.1 MB/s eta 0:00:12\n",
      "     ---------------- -------------------- 207.8/457.1 MB 22.6 MB/s eta 0:00:12\n",
      "     ---------------- -------------------- 208.8/457.1 MB 22.6 MB/s eta 0:00:11\n",
      "     ----------------- ------------------- 211.5/457.1 MB 23.4 MB/s eta 0:00:11\n",
      "     ----------------- ------------------- 212.2/457.1 MB 25.1 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 213.3/457.1 MB 21.8 MB/s eta 0:00:12\n",
      "     ----------------- ------------------- 214.3/457.1 MB 21.8 MB/s eta 0:00:12\n",
      "     ----------------- ------------------- 215.3/457.1 MB 21.8 MB/s eta 0:00:12\n",
      "     ----------------- ------------------- 216.7/457.1 MB 27.3 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 217.5/457.1 MB 25.1 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 218.6/457.1 MB 26.2 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 220.4/457.1 MB 24.2 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 222.0/457.1 MB 24.2 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 223.0/457.1 MB 25.1 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 223.8/457.1 MB 27.3 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 224.2/457.1 MB 25.2 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 226.0/457.1 MB 24.2 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 226.8/457.1 MB 22.6 MB/s eta 0:00:11\n",
      "     ------------------ ------------------ 227.6/457.1 MB 24.3 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 227.8/457.1 MB 23.4 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 228.0/457.1 MB 22.5 MB/s eta 0:00:11\n",
      "     ------------------ ------------------ 229.3/457.1 MB 19.8 MB/s eta 0:00:12\n",
      "     ------------------ ------------------ 230.2/457.1 MB 19.2 MB/s eta 0:00:12\n",
      "     ------------------ ------------------ 232.3/457.1 MB 19.3 MB/s eta 0:00:12\n",
      "     ------------------ ------------------ 233.3/457.1 MB 20.5 MB/s eta 0:00:11\n",
      "     ------------------ ------------------ 233.6/457.1 MB 17.7 MB/s eta 0:00:13\n",
      "     ------------------- ----------------- 234.9/457.1 MB 21.1 MB/s eta 0:00:11\n",
      "     ------------------- ----------------- 236.0/457.1 MB 19.2 MB/s eta 0:00:12\n",
      "     ------------------- ----------------- 236.6/457.1 MB 19.9 MB/s eta 0:00:12\n",
      "     ------------------- ----------------- 237.8/457.1 MB 18.7 MB/s eta 0:00:12\n",
      "     ------------------- ----------------- 239.5/457.1 MB 24.2 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 240.9/457.1 MB 26.2 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 241.3/457.1 MB 25.1 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 242.4/457.1 MB 22.6 MB/s eta 0:00:10\n",
      "     ------------------- ----------------- 242.9/457.1 MB 20.5 MB/s eta 0:00:11\n",
      "     ------------------- ----------------- 245.6/457.1 MB 26.2 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 245.8/457.1 MB 24.2 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 246.1/457.1 MB 24.3 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 248.6/457.1 MB 24.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 250.7/457.1 MB 27.3 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 251.2/457.1 MB 25.2 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 252.7/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 254.1/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 255.7/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 256.9/457.1 MB 29.7 MB/s eta 0:00:07\n",
      "     -------------------- ---------------- 257.7/457.1 MB 29.8 MB/s eta 0:00:07\n",
      "     -------------------- ---------------- 258.1/457.1 MB 27.3 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 259.4/457.1 MB 24.2 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 262.2/457.1 MB 29.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 262.9/457.1 MB 27.3 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 262.9/457.1 MB 25.1 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 264.6/457.1 MB 23.4 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 267.3/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 267.8/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 268.1/457.1 MB 24.3 MB/s eta 0:00:08\n",
      "     --------------------- --------------- 269.5/457.1 MB 25.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 272.3/457.1 MB 26.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 272.9/457.1 MB 25.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 272.9/457.1 MB 25.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 273.3/457.1 MB 24.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 274.6/457.1 MB 23.4 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 277.4/457.1 MB 24.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 278.2/457.1 MB 25.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 278.9/457.1 MB 27.3 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 279.1/457.1 MB 24.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 280.6/457.1 MB 21.8 MB/s eta 0:00:09\n",
      "     ---------------------- -------------- 282.0/457.1 MB 19.9 MB/s eta 0:00:09\n",
      "     ---------------------- -------------- 283.2/457.1 MB 22.6 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 283.9/457.1 MB 23.4 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 285.3/457.1 MB 23.4 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 286.3/457.1 MB 21.1 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 287.1/457.1 MB 19.8 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 287.9/457.1 MB 19.3 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 289.6/457.1 MB 23.4 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 290.7/457.1 MB 22.6 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 291.2/457.1 MB 21.8 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 291.8/457.1 MB 21.1 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 292.3/457.1 MB 19.9 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 293.4/457.1 MB 18.7 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 294.4/457.1 MB 19.9 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 295.1/457.1 MB 18.2 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 295.8/457.1 MB 18.7 MB/s eta 0:00:09\n",
      "     ----------------------- ------------- 296.3/457.1 MB 18.2 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 297.9/457.1 MB 18.7 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 299.5/457.1 MB 19.3 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 300.4/457.1 MB 18.2 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 301.4/457.1 MB 19.9 MB/s eta 0:00:08\n",
      "     ------------------------ ------------ 301.8/457.1 MB 19.3 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 302.5/457.1 MB 19.2 MB/s eta 0:00:09\n",
      "     ------------------------ ------------ 303.7/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------ ------------ 306.0/457.1 MB 22.6 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 306.7/457.1 MB 24.2 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 308.0/457.1 MB 23.4 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 308.7/457.1 MB 21.8 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 308.7/457.1 MB 21.8 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 309.3/457.1 MB 18.7 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 311.3/457.1 MB 20.5 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 22.6 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 312.1/457.1 MB 22.6 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 312.1/457.1 MB 19.3 MB/s eta 0:00:08\n",
      "     ------------------------- ----------- 314.9/457.1 MB 13.6 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 318.3/457.1 MB 15.6 MB/s eta 0:00:09\n",
      "     ------------------------- ----------- 320.4/457.1 MB 18.2 MB/s eta 0:00:08\n",
      "     -------------------------- ---------- 323.3/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 323.9/457.1 MB 54.4 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 325.6/457.1 MB 43.7 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 325.6/457.1 MB 43.7 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 327.1/457.1 MB 32.7 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 327.5/457.1 MB 29.7 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 328.2/457.1 MB 28.5 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 328.2/457.1 MB 28.5 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 328.4/457.1 MB 21.1 MB/s eta 0:00:07\n",
      "     -------------------------- ---------- 330.6/457.1 MB 21.1 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 332.5/457.1 MB 21.1 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 333.0/457.1 MB 18.7 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 333.6/457.1 MB 18.2 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 335.0/457.1 MB 19.3 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 335.5/457.1 MB 18.7 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 336.6/457.1 MB 19.2 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 337.4/457.1 MB 19.8 MB/s eta 0:00:07\n",
      "     --------------------------- --------- 339.0/457.1 MB 26.2 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 339.4/457.1 MB 22.6 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 340.1/457.1 MB 21.1 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 340.7/457.1 MB 19.8 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 342.0/457.1 MB 19.3 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 344.6/457.1 MB 22.6 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 344.8/457.1 MB 21.1 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 344.8/457.1 MB 21.1 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 345.1/457.1 MB 16.8 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 346.3/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 348.0/457.1 MB 19.3 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 350.4/457.1 MB 22.6 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 350.8/457.1 MB 23.4 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 351.6/457.1 MB 21.8 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 351.9/457.1 MB 20.5 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 352.2/457.1 MB 18.2 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 353.6/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 353.6/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 355.1/457.1 MB 21.9 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 355.2/457.1 MB 20.5 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 356.4/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 358.2/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ----------------------------- ------- 358.9/457.1 MB 18.7 MB/s eta 0:00:06\n",
      "     ----------------------------- ------- 359.2/457.1 MB 17.7 MB/s eta 0:00:06\n",
      "     ----------------------------- ------- 360.9/457.1 MB 16.4 MB/s eta 0:00:06\n",
      "     ----------------------------- ------- 362.6/457.1 MB 21.1 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 363.3/457.1 MB 19.3 MB/s eta 0:00:05\n",
      "     ------------------------------ ------- 363.4/457.1 MB 7.6 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.5/457.1 MB 7.5 MB/s eta 0:00:13\n",
      "     ------------------------------ ------- 363.7/457.1 MB 5.0 MB/s eta 0:00:19\n",
      "     ------------------------------ ------- 364.2/457.1 MB 5.0 MB/s eta 0:00:19\n",
      "     ------------------------------ ------- 364.4/457.1 MB 5.0 MB/s eta 0:00:19\n",
      "     ------------------------------ ------- 364.6/457.1 MB 4.8 MB/s eta 0:00:20\n",
      "     ------------------------------ ------- 364.8/457.1 MB 4.7 MB/s eta 0:00:20\n",
      "     ------------------------------ ------- 365.1/457.1 MB 4.6 MB/s eta 0:00:20\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.3/457.1 MB 4.5 MB/s eta 0:00:21\n",
      "     ------------------------------ ------- 365.6/457.1 MB 2.8 MB/s eta 0:00:33\n",
      "     ------------------------------ ------- 365.7/457.1 MB 2.8 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 365.9/457.1 MB 2.7 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 366.0/457.1 MB 2.7 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 366.0/457.1 MB 2.7 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 366.0/457.1 MB 2.7 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 366.0/457.1 MB 2.7 MB/s eta 0:00:34\n",
      "     ------------------------------ ------- 366.1/457.1 MB 2.6 MB/s eta 0:00:36\n",
      "     ------------------------------ ------- 366.2/457.1 MB 2.6 MB/s eta 0:00:36\n",
      "     ------------------------------ ------- 366.2/457.1 MB 2.6 MB/s eta 0:00:36\n",
      "     ------------------------------ ------- 366.2/457.1 MB 2.6 MB/s eta 0:00:36\n",
      "     ------------------------------ ------- 366.2/457.1 MB 2.6 MB/s eta 0:00:36\n",
      "     ------------------------------ ------- 366.4/457.1 MB 2.4 MB/s eta 0:00:38\n",
      "     ------------------------------ ------- 366.7/457.1 MB 2.4 MB/s eta 0:00:38\n",
      "     ------------------------------ ------- 367.0/457.1 MB 2.4 MB/s eta 0:00:38\n",
      "     ------------------------------ ------- 367.0/457.1 MB 2.4 MB/s eta 0:00:38\n",
      "     ------------------------------ ------- 367.2/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 367.2/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 367.2/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 367.8/457.1 MB 2.3 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 368.4/457.1 MB 2.3 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 369.5/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 369.5/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 369.5/457.1 MB 2.3 MB/s eta 0:00:39\n",
      "     ------------------------------ ------- 369.7/457.1 MB 2.2 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 369.8/457.1 MB 2.2 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 370.6/457.1 MB 2.2 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 370.6/457.1 MB 2.2 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 370.6/457.1 MB 2.2 MB/s eta 0:00:40\n",
      "     ------------------------------ ------- 370.9/457.1 MB 2.1 MB/s eta 0:00:41\n",
      "     ------------------------------ ------- 371.0/457.1 MB 2.1 MB/s eta 0:00:41\n",
      "     ------------------------------ ------- 371.2/457.1 MB 2.1 MB/s eta 0:00:41\n",
      "     ------------------------------ ------- 371.2/457.1 MB 2.1 MB/s eta 0:00:41\n",
      "     ------------------------------ ------- 371.2/457.1 MB 2.1 MB/s eta 0:00:41\n",
      "     ------------------------------ ------- 371.4/457.1 MB 2.0 MB/s eta 0:00:42\n",
      "     ------------------------------ ------- 372.0/457.1 MB 2.0 MB/s eta 0:00:43\n",
      "     ------------------------------ ------- 372.3/457.1 MB 2.0 MB/s eta 0:00:43\n",
      "     ------------------------------- ------ 373.1/457.1 MB 2.0 MB/s eta 0:00:43\n",
      "     ------------------------------- ------ 373.3/457.1 MB 2.0 MB/s eta 0:00:43\n",
      "     ------------------------------- ------ 373.5/457.1 MB 2.0 MB/s eta 0:00:42\n",
      "     ------------------------------- ------ 373.5/457.1 MB 2.0 MB/s eta 0:00:42\n",
      "     ------------------------------- ------ 373.7/457.1 MB 2.3 MB/s eta 0:00:37\n",
      "     ------------------------------- ------ 374.0/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 374.7/457.1 MB 2.8 MB/s eta 0:00:30\n",
      "     ------------------------------- ------ 374.7/457.1 MB 2.8 MB/s eta 0:00:30\n",
      "     ------------------------------- ------ 374.7/457.1 MB 2.8 MB/s eta 0:00:30\n",
      "     ------------------------------- ------ 374.8/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 375.1/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 375.4/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 375.4/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 375.4/457.1 MB 2.7 MB/s eta 0:00:31\n",
      "     ------------------------------- ------ 375.6/457.1 MB 4.2 MB/s eta 0:00:20\n",
      "     ------------------------------- ------ 375.8/457.1 MB 4.1 MB/s eta 0:00:20\n",
      "     ------------------------------- ------ 376.1/457.1 MB 4.2 MB/s eta 0:00:20\n",
      "     ------------------------------- ------ 376.5/457.1 MB 5.0 MB/s eta 0:00:17\n",
      "     ------------------------------- ------ 376.7/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 376.7/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 376.7/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 376.9/457.1 MB 4.8 MB/s eta 0:00:17\n",
      "     ------------------------------- ------ 377.2/457.1 MB 4.7 MB/s eta 0:00:18\n",
      "     ------------------------------- ------ 377.5/457.1 MB 5.1 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 377.9/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 378.4/457.1 MB 5.1 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 378.6/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 378.8/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 379.1/457.1 MB 4.8 MB/s eta 0:00:17\n",
      "     ------------------------------- ------ 379.5/457.1 MB 4.7 MB/s eta 0:00:17\n",
      "     ------------------------------- ------ 380.0/457.1 MB 5.1 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 380.4/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 380.7/457.1 MB 5.0 MB/s eta 0:00:16\n",
      "     ------------------------------- ------ 381.2/457.1 MB 5.3 MB/s eta 0:00:15\n",
      "     ------------------------------- ------ 381.5/457.1 MB 5.3 MB/s eta 0:00:15\n",
      "     ------------------------------- ------ 381.9/457.1 MB 5.7 MB/s eta 0:00:14\n",
      "     ------------------------------- ------ 382.3/457.1 MB 5.7 MB/s eta 0:00:14\n",
      "     ------------------------------- ------ 382.9/457.1 MB 5.6 MB/s eta 0:00:14\n",
      "     ------------------------------- ------ 383.3/457.1 MB 5.7 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 383.7/457.1 MB 5.6 MB/s eta 0:00:14\n",
      "     ------------------------------- ------ 383.8/457.1 MB 5.8 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 384.4/457.1 MB 6.0 MB/s eta 0:00:13\n",
      "     ------------------------------- ------ 384.9/457.1 MB 6.3 MB/s eta 0:00:12\n",
      "     -------------------------------- ----- 385.5/457.1 MB 6.4 MB/s eta 0:00:12\n",
      "     -------------------------------- ----- 385.9/457.1 MB 7.2 MB/s eta 0:00:10\n",
      "     -------------------------------- ----- 386.5/457.1 MB 7.4 MB/s eta 0:00:10\n",
      "     -------------------------------- ----- 387.1/457.1 MB 8.4 MB/s eta 0:00:09\n",
      "     -------------------------------- ----- 387.4/457.1 MB 8.5 MB/s eta 0:00:09\n",
      "     -------------------------------- ----- 387.9/457.1 MB 8.6 MB/s eta 0:00:09\n",
      "     -------------------------------- ----- 388.4/457.1 MB 8.7 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 389.0/457.1 MB 9.0 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 389.3/457.1 MB 9.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 389.8/457.1 MB 9.1 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 390.2/457.1 MB 9.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 390.7/457.1 MB 9.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 391.1/457.1 MB 9.2 MB/s eta 0:00:08\n",
      "     -------------------------------- ----- 391.7/457.1 MB 9.4 MB/s eta 0:00:07\n",
      "     -------------------------------- ----- 392.1/457.1 MB 9.5 MB/s eta 0:00:07\n",
      "     -------------------------------- ----- 392.7/457.1 MB 9.8 MB/s eta 0:00:07\n",
      "     -------------------------------- ----- 393.2/457.1 MB 9.8 MB/s eta 0:00:07\n",
      "     -------------------------------- ----- 393.9/457.1 MB 9.9 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 394.3/457.1 MB 10.4 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 395.0/457.1 MB 10.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 395.4/457.1 MB 10.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 396.0/457.1 MB 10.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 396.7/457.1 MB 10.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 397.3/457.1 MB 10.1 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 398.1/457.1 MB 10.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 398.9/457.1 MB 10.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 399.5/457.1 MB 10.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 400.2/457.1 MB 10.9 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 400.9/457.1 MB 10.9 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 401.9/457.1 MB 11.3 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.9/457.1 MB 11.5 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 403.4/457.1 MB 11.5 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 403.9/457.1 MB 11.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 404.4/457.1 MB 11.3 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 405.2/457.1 MB 11.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 405.7/457.1 MB 10.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 406.6/457.1 MB 11.1 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 407.4/457.1 MB 11.5 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 407.8/457.1 MB 10.7 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 408.4/457.1 MB 10.7 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 408.8/457.1 MB 10.7 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 409.5/457.1 MB 10.2 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 409.9/457.1 MB 10.2 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 410.5/457.1 MB 10.1 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 411.1/457.1 MB 10.1 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 411.7/457.1 MB 9.9 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 412.3/457.1 MB 9.9 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 413.0/457.1 MB 9.6 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 413.6/457.1 MB 9.6 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 414.5/457.1 MB 9.9 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 415.3/457.1 MB 10.1 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 416.1/457.1 MB 10.6 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 416.7/457.1 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 417.5/457.1 MB 10.1 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 418.0/457.1 MB 10.4 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 418.9/457.1 MB 10.7 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 419.5/457.1 MB 11.3 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 420.0/457.1 MB 11.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 420.8/457.1 MB 11.3 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 421.2/457.1 MB 11.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 421.7/457.1 MB 10.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 422.7/457.1 MB 11.3 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 423.2/457.1 MB 11.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 423.5/457.1 MB 10.9 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 424.3/457.1 MB 10.9 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 424.9/457.1 MB 10.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 425.2/457.1 MB 10.2 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 425.7/457.1 MB 10.4 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 426.4/457.1 MB 10.4 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 427.1/457.1 MB 10.6 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 427.2/457.1 MB 9.9 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 428.1/457.1 MB 10.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 428.6/457.1 MB 10.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 429.3/457.1 MB 10.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 429.3/457.1 MB 10.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 429.9/457.1 MB 9.6 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 430.4/457.1 MB 9.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 431.2/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 431.4/457.1 MB 10.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 431.9/457.1 MB 9.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 432.5/457.1 MB 9.8 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 433.2/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 433.8/457.1 MB 10.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 434.1/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 434.5/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 434.9/457.1 MB 9.8 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 435.6/457.1 MB 10.2 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 435.9/457.1 MB 10.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 436.4/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 436.8/457.1 MB 9.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 437.5/457.1 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 437.8/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 438.1/457.1 MB 9.9 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 438.6/457.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 439.1/457.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 439.8/457.1 MB 10.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 440.4/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 440.9/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 441.4/457.1 MB 10.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 442.0/457.1 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 442.5/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 442.8/457.1 MB 10.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 443.4/457.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 443.9/457.1 MB 9.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 444.7/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------------------------  445.2/457.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------------------------  445.9/457.1 MB 10.4 MB/s eta 0:00:02\n",
      "     ------------------------------------  446.5/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.0/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.4/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.6/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  448.1/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  448.5/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  449.2/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  449.6/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.0/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.4/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.1/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.5/457.1 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  452.0/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  452.5/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  453.2/457.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  453.6/457.1 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.1/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.5/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.2/457.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  456.0/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  456.4/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  456.9/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 457.1/457.1 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ca-core-news-trf==3.7.2) (3.7.0)\n",
      "Requirement already satisfied: spacy-curated-transformers<0.3.0,>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ca-core-news-trf==3.7.2) (0.2.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.9.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.26.4)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2024.5.15)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.2.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pathy>=0.10.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (3.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.1.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.12.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (1.3.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_trf')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!py -m spacy download ca_core_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'curated_transformer' for language Catalan (ca). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, ca.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nlp_trf \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mca_core_news_trf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:50\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     27\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ca_core_news_trf\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:539\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    537\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config, for_overrides\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    538\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m--> 539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:587\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[0;32m    586\u001b[0m lang_cls \u001b[38;5;241m=\u001b[39m get_lang_class(nlp_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 587\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1864\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     factory \u001b[38;5;241m=\u001b[39m pipe_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;66;03m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;66;03m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[1;32m-> 1864\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1870\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipe_cfg\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:821\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    817\u001b[0m     pipe_component, factory_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    818\u001b[0m         factory_name, source, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m     pipe_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m pipe_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_meta[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:690\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_factory(factory_name):\n\u001b[0;32m    683\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE002\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    684\u001b[0m         name\u001b[38;5;241m=\u001b[39mfactory_name,\n\u001b[0;32m    685\u001b[0m         opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactory_names),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    688\u001b[0m         lang_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang,\n\u001b[0;32m    689\u001b[0m     )\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[0;32m    691\u001b[0m pipe_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: [E002] Can't find factory for 'curated_transformer' for language Catalan (ca). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, ca.lemmatizer"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_trf = spacy.load('ca_core_news_trf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RoBERTa fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "from scipy.special import logit\n",
    "\n",
    "model = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(sentence_pairs):\n",
    "    sentence_pairs_prep = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        sentence_pairs_prep.append(f\"{tokenizer.cls_token} {s1}{tokenizer.sep_token}{tokenizer.sep_token} {s2}{tokenizer.sep_token}\")\n",
    "    return sentence_pairs_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_runed_corpus_semantic = corpus_semantic.copy()\n",
    "for i, (frase1, frase2) in enumerate(fine_runed_corpus_semantic):\n",
    "    frase1 = ' '.join(frase1)\n",
    "    frase2 = ' '.join(frase2)\n",
    "    fine_runed_corpus_semantic[i] = (frase1, frase2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'SIMILARITY', 'score': 3.639443974101274}, {'label': 'SIMILARITY', 'score': 1.3343049254405437}, {'label': 'SIMILARITY', 'score': 3.6255003414699982}, {'label': 'SIMILARITY', 'score': 2.8571212701413073}, {'label': 'SIMILARITY', 'score': 1.7412681993979517}, {'label': 'SIMILARITY', 'score': 2.902458331608203}, {'label': 'SIMILARITY', 'score': 3.3925175786892536}, {'label': 'SIMILARITY', 'score': 2.7214751443641485}, {'label': 'SIMILARITY', 'score': 2.848001481281147}, {'label': 'SIMILARITY', 'score': 2.8075600107730767}, {'label': 'SIMILARITY', 'score': 2.9737861311233997}, {'label': 'SIMILARITY', 'score': 0.946479625573919}, {'label': 'SIMILARITY', 'score': 2.0864164114103474}, {'label': 'SIMILARITY', 'score': 3.390759591752991}, {'label': 'SIMILARITY', 'score': 3.119538929859854}, {'label': 'SIMILARITY', 'score': 2.835003453924068}, {'label': 'SIMILARITY', 'score': 1.6847840009938235}, {'label': 'SIMILARITY', 'score': 3.1470772247192316}, {'label': 'SIMILARITY', 'score': 2.6824705621661047}, {'label': 'SIMILARITY', 'score': 4.226412654742718}, {'label': 'SIMILARITY', 'score': 3.126528135836064}, {'label': 'SIMILARITY', 'score': 1.7081137790117091}, {'label': 'SIMILARITY', 'score': 4.230167032371548}, {'label': 'SIMILARITY', 'score': 1.8934870039501301}, {'label': 'SIMILARITY', 'score': 2.7132040190339723}, {'label': 'SIMILARITY', 'score': 2.6130709971824206}, {'label': 'SIMILARITY', 'score': 2.037800000515877}, {'label': 'SIMILARITY', 'score': 2.33263418193179}, {'label': 'SIMILARITY', 'score': 2.5973923458820583}, {'label': 'SIMILARITY', 'score': 0.8618329165908697}, {'label': 'SIMILARITY', 'score': 4.2248132103366265}, {'label': 'SIMILARITY', 'score': 2.7458963517477017}, {'label': 'SIMILARITY', 'score': 3.3074664974471806}, {'label': 'SIMILARITY', 'score': 3.7756875804485848}, {'label': 'SIMILARITY', 'score': 3.0761924276671877}, {'label': 'SIMILARITY', 'score': 2.4497194024832134}, {'label': 'SIMILARITY', 'score': 2.3104285309815897}, {'label': 'SIMILARITY', 'score': 2.055789338626736}, {'label': 'SIMILARITY', 'score': 3.5544121850107184}, {'label': 'SIMILARITY', 'score': 3.0630930880441944}, {'label': 'SIMILARITY', 'score': 1.9726317429036382}, {'label': 'SIMILARITY', 'score': 2.1199992941213046}, {'label': 'SIMILARITY', 'score': 2.503829783954064}, {'label': 'SIMILARITY', 'score': 4.207686592066606}, {'label': 'SIMILARITY', 'score': 3.0206260061968004}, {'label': 'SIMILARITY', 'score': 2.553386819701617}, {'label': 'SIMILARITY', 'score': 1.6169672689316072}, {'label': 'SIMILARITY', 'score': 2.5593145534221518}, {'label': 'SIMILARITY', 'score': 2.4372375847977272}, {'label': 'SIMILARITY', 'score': 2.0298332542640454}, {'label': 'SIMILARITY', 'score': 2.014581006361909}, {'label': 'SIMILARITY', 'score': 1.4988620081551278}, {'label': 'SIMILARITY', 'score': 4.21061992739215}, {'label': 'SIMILARITY', 'score': 2.096065271846751}, {'label': 'SIMILARITY', 'score': 2.902290375164996}, {'label': 'SIMILARITY', 'score': 3.1974557566228814}, {'label': 'SIMILARITY', 'score': 3.2517584576470235}, {'label': 'SIMILARITY', 'score': 1.4670121191708474}, {'label': 'SIMILARITY', 'score': 1.6989868085832516}, {'label': 'SIMILARITY', 'score': 1.456438533620495}, {'label': 'SIMILARITY', 'score': 2.5803544010880874}, {'label': 'SIMILARITY', 'score': 1.6024959773586511}, {'label': 'SIMILARITY', 'score': 1.2920962565510448}, {'label': 'SIMILARITY', 'score': 1.71866389412072}, {'label': 'SIMILARITY', 'score': 3.1044316994336874}, {'label': 'SIMILARITY', 'score': 3.0982684270197693}, {'label': 'SIMILARITY', 'score': 3.704224110226398}, {'label': 'SIMILARITY', 'score': 2.0405611365364362}, {'label': 'SIMILARITY', 'score': 1.9703906099460806}, {'label': 'SIMILARITY', 'score': 2.9243630147918447}, {'label': 'SIMILARITY', 'score': 2.353398937622096}, {'label': 'SIMILARITY', 'score': 1.5367582813635792}, {'label': 'SIMILARITY', 'score': 3.5366171942583695}, {'label': 'SIMILARITY', 'score': 1.55160417783913}, {'label': 'SIMILARITY', 'score': 1.6197496913091034}, {'label': 'SIMILARITY', 'score': 4.219516293539999}, {'label': 'SIMILARITY', 'score': 3.4760505156255235}, {'label': 'SIMILARITY', 'score': 3.200305403284124}, {'label': 'SIMILARITY', 'score': 0.46994832393887703}, {'label': 'SIMILARITY', 'score': 0.20668384803437304}, {'label': 'SIMILARITY', 'score': 3.5399204653194913}, {'label': 'SIMILARITY', 'score': 2.4224328154873165}, {'label': 'SIMILARITY', 'score': 2.961230503858237}, {'label': 'SIMILARITY', 'score': 2.777953287644126}, {'label': 'SIMILARITY', 'score': 3.571589811709348}, {'label': 'SIMILARITY', 'score': 1.4796314170156202}, {'label': 'SIMILARITY', 'score': 3.5147780437246907}, {'label': 'SIMILARITY', 'score': 3.024355901512201}, {'label': 'SIMILARITY', 'score': 2.8038727765075016}, {'label': 'SIMILARITY', 'score': 3.056932181334793}, {'label': 'SIMILARITY', 'score': 2.790148050464573}, {'label': 'SIMILARITY', 'score': 1.3172318304470148}, {'label': 'SIMILARITY', 'score': 2.6925369972500164}, {'label': 'SIMILARITY', 'score': 3.051272714582565}, {'label': 'SIMILARITY', 'score': 1.5833144259105116}, {'label': 'SIMILARITY', 'score': 4.227400428976332}, {'label': 'SIMILARITY', 'score': 1.9046106329307044}, {'label': 'SIMILARITY', 'score': 2.4374190338672723}, {'label': 'SIMILARITY', 'score': 4.229804466303161}, {'label': 'SIMILARITY', 'score': 1.743852826246043}, {'label': 'SIMILARITY', 'score': 2.7442518021171507}, {'label': 'SIMILARITY', 'score': 1.8025528931227843}, {'label': 'SIMILARITY', 'score': 2.6133538965626832}, {'label': 'SIMILARITY', 'score': 2.939813010704966}, {'label': 'SIMILARITY', 'score': 4.228612271574886}, {'label': 'SIMILARITY', 'score': 3.20009629087962}, {'label': 'SIMILARITY', 'score': 2.6888448654536274}, {'label': 'SIMILARITY', 'score': 2.9412785338206935}, {'label': 'SIMILARITY', 'score': 3.016453271243749}, {'label': 'SIMILARITY', 'score': 4.226463071325598}, {'label': 'SIMILARITY', 'score': 3.0369117963217027}, {'label': 'SIMILARITY', 'score': 2.746696893899641}, {'label': 'SIMILARITY', 'score': 3.2980775397822106}, {'label': 'SIMILARITY', 'score': 2.5416401420442147}, {'label': 'SIMILARITY', 'score': 4.218023357515997}, {'label': 'SIMILARITY', 'score': 2.705917995193654}, {'label': 'SIMILARITY', 'score': 2.8755191545986456}, {'label': 'SIMILARITY', 'score': 4.225971614913898}, {'label': 'SIMILARITY', 'score': 3.0028536739078375}, {'label': 'SIMILARITY', 'score': 2.9187071777655644}, {'label': 'SIMILARITY', 'score': 2.8499991583563253}, {'label': 'SIMILARITY', 'score': 1.2641152837976914}, {'label': 'SIMILARITY', 'score': 3.2181226744779114}, {'label': 'SIMILARITY', 'score': 2.8157523992899356}, {'label': 'SIMILARITY', 'score': 1.8078392116373434}, {'label': 'SIMILARITY', 'score': 3.016415774831342}, {'label': 'SIMILARITY', 'score': 3.0239877369556427}, {'label': 'SIMILARITY', 'score': 2.8940109510668064}, {'label': 'SIMILARITY', 'score': 2.92026179035961}, {'label': 'SIMILARITY', 'score': 2.965900465325177}, {'label': 'SIMILARITY', 'score': 1.6589238770747456}, {'label': 'SIMILARITY', 'score': 3.1170292617630935}, {'label': 'SIMILARITY', 'score': 1.7856236135356318}, {'label': 'SIMILARITY', 'score': 0.9128038532361863}, {'label': 'SIMILARITY', 'score': 1.8424520908191835}, {'label': 'SIMILARITY', 'score': 2.862966469302841}, {'label': 'SIMILARITY', 'score': 4.224804820854788}, {'label': 'SIMILARITY', 'score': 2.818794392297546}, {'label': 'SIMILARITY', 'score': 2.0296770289593535}, {'label': 'SIMILARITY', 'score': 2.9674777282964238}, {'label': 'SIMILARITY', 'score': 2.8211363562399567}, {'label': 'SIMILARITY', 'score': 1.4061379221917623}, {'label': 'SIMILARITY', 'score': 2.710597186200766}, {'label': 'SIMILARITY', 'score': 2.134538006652288}, {'label': 'SIMILARITY', 'score': 2.2909085852105817}, {'label': 'SIMILARITY', 'score': 1.134789361279017}, {'label': 'SIMILARITY', 'score': 4.228780695913693}, {'label': 'SIMILARITY', 'score': 4.159190106927247}, {'label': 'SIMILARITY', 'score': 3.1006963152521454}, {'label': 'SIMILARITY', 'score': 3.0203531557415038}, {'label': 'SIMILARITY', 'score': 2.840387895230038}, {'label': 'SIMILARITY', 'score': 1.2675995411442682}, {'label': 'SIMILARITY', 'score': 4.162833404558112}, {'label': 'SIMILARITY', 'score': 1.3560100688925327}, {'label': 'SIMILARITY', 'score': 2.813026515839836}, {'label': 'SIMILARITY', 'score': 3.017687346482905}, {'label': 'SIMILARITY', 'score': 2.780039680429342}, {'label': 'SIMILARITY', 'score': 2.720131691573945}, {'label': 'SIMILARITY', 'score': 2.7093184012717004}, {'label': 'SIMILARITY', 'score': 2.911358635471955}, {'label': 'SIMILARITY', 'score': 2.937407592407723}, {'label': 'SIMILARITY', 'score': 3.7306836791077}, {'label': 'SIMILARITY', 'score': 4.227875738868506}, {'label': 'SIMILARITY', 'score': 3.579928509461553}, {'label': 'SIMILARITY', 'score': 1.4368905254749262}, {'label': 'SIMILARITY', 'score': 4.12379352214613}, {'label': 'SIMILARITY', 'score': 3.372992670624899}, {'label': 'SIMILARITY', 'score': 2.7491124534783973}, {'label': 'SIMILARITY', 'score': 4.227156549795726}, {'label': 'SIMILARITY', 'score': 3.0359790263060322}, {'label': 'SIMILARITY', 'score': 2.92102700950639}, {'label': 'SIMILARITY', 'score': 3.0056628621089567}, {'label': 'SIMILARITY', 'score': 1.200823651899384}, {'label': 'SIMILARITY', 'score': 2.948393467660903}, {'label': 'SIMILARITY', 'score': 2.8618588484233443}, {'label': 'SIMILARITY', 'score': 3.118068869700141}, {'label': 'SIMILARITY', 'score': 2.91315920733368}, {'label': 'SIMILARITY', 'score': 3.1645571460735336}, {'label': 'SIMILARITY', 'score': 2.0219172518979365}, {'label': 'SIMILARITY', 'score': 4.2129394506399285}, {'label': 'SIMILARITY', 'score': 2.1081360281427433}, {'label': 'SIMILARITY', 'score': 1.467554322415775}, {'label': 'SIMILARITY', 'score': 1.4159468401856514}, {'label': 'SIMILARITY', 'score': 3.069211480982673}, {'label': 'SIMILARITY', 'score': 1.5595818937241979}, {'label': 'SIMILARITY', 'score': 2.9752946697799416}, {'label': 'SIMILARITY', 'score': 0.5193965554466606}, {'label': 'SIMILARITY', 'score': 3.0996037489678576}, {'label': 'SIMILARITY', 'score': 3.1757290051480753}, {'label': 'SIMILARITY', 'score': 2.9916760260942765}, {'label': 'SIMILARITY', 'score': 2.212808438342496}, {'label': 'SIMILARITY', 'score': 3.169885292001065}, {'label': 'SIMILARITY', 'score': 2.751802677665469}, {'label': 'SIMILARITY', 'score': 2.829011834007042}, {'label': 'SIMILARITY', 'score': 1.089342739933811}, {'label': 'SIMILARITY', 'score': 1.7078095333131873}, {'label': 'SIMILARITY', 'score': 3.0458884135586968}, {'label': 'SIMILARITY', 'score': 2.9698799370264077}, {'label': 'SIMILARITY', 'score': 3.9511607969277325}, {'label': 'SIMILARITY', 'score': 3.140984256099914}, {'label': 'SIMILARITY', 'score': 1.35784116560879}, {'label': 'SIMILARITY', 'score': 2.4284178622283226}, {'label': 'SIMILARITY', 'score': 2.6780969243768835}, {'label': 'SIMILARITY', 'score': 2.38691817636789}, {'label': 'SIMILARITY', 'score': 3.052426077523179}, {'label': 'SIMILARITY', 'score': 2.4681657409480815}, {'label': 'SIMILARITY', 'score': 2.1257151111651003}, {'label': 'SIMILARITY', 'score': 3.9096723416869654}, {'label': 'SIMILARITY', 'score': 1.4612729069468748}, {'label': 'SIMILARITY', 'score': 3.0711970851571184}, {'label': 'SIMILARITY', 'score': 2.186390860872444}, {'label': 'SIMILARITY', 'score': 3.009113587207771}, {'label': 'SIMILARITY', 'score': 1.2888792002721865}, {'label': 'SIMILARITY', 'score': 1.5713178624541315}, {'label': 'SIMILARITY', 'score': 2.813513116625873}, {'label': 'SIMILARITY', 'score': 2.992460676313603}, {'label': 'SIMILARITY', 'score': 3.03980650181559}, {'label': 'SIMILARITY', 'score': 3.18149373759479}, {'label': 'SIMILARITY', 'score': 2.9256244631885444}, {'label': 'SIMILARITY', 'score': 2.8360256659771808}, {'label': 'SIMILARITY', 'score': 3.7783166215523583}, {'label': 'SIMILARITY', 'score': 1.700310418721196}, {'label': 'SIMILARITY', 'score': 2.065903589576782}, {'label': 'SIMILARITY', 'score': 1.2895039753385458}, {'label': 'SIMILARITY', 'score': 3.4716539838011466}, {'label': 'SIMILARITY', 'score': 4.229353544843205}, {'label': 'SIMILARITY', 'score': 2.5031049546499413}, {'label': 'SIMILARITY', 'score': 3.3787713295742705}, {'label': 'SIMILARITY', 'score': 2.948452656785678}, {'label': 'SIMILARITY', 'score': 2.992358469954168}, {'label': 'SIMILARITY', 'score': 4.169244276535476}, {'label': 'SIMILARITY', 'score': 2.5174634936460625}, {'label': 'SIMILARITY', 'score': 2.745734418328459}, {'label': 'SIMILARITY', 'score': 2.6113797267034666}, {'label': 'SIMILARITY', 'score': 3.103897913148543}, {'label': 'SIMILARITY', 'score': 3.0289446637824105}, {'label': 'SIMILARITY', 'score': 2.9448867943929145}, {'label': 'SIMILARITY', 'score': 4.2278084250164705}, {'label': 'SIMILARITY', 'score': 3.984131509949227}, {'label': 'SIMILARITY', 'score': 1.3068973287949879}, {'label': 'SIMILARITY', 'score': 1.4124480194022744}, {'label': 'SIMILARITY', 'score': 1.7510200828232885}, {'label': 'SIMILARITY', 'score': 2.485364293442714}, {'label': 'SIMILARITY', 'score': 1.0983106324412342}, {'label': 'SIMILARITY', 'score': 2.820636343616339}, {'label': 'SIMILARITY', 'score': 2.855755117024779}, {'label': 'SIMILARITY', 'score': 0.35137223249830174}, {'label': 'SIMILARITY', 'score': 3.0348223441718796}, {'label': 'SIMILARITY', 'score': 2.2220823803984606}, {'label': 'SIMILARITY', 'score': 3.2017036897047384}, {'label': 'SIMILARITY', 'score': 2.61559423829568}, {'label': 'SIMILARITY', 'score': 1.0293488830716857}, {'label': 'SIMILARITY', 'score': 0.7828790246387515}, {'label': 'SIMILARITY', 'score': 3.2126075798148674}, {'label': 'SIMILARITY', 'score': 1.8668347701398926}, {'label': 'SIMILARITY', 'score': 3.248296571171331}, {'label': 'SIMILARITY', 'score': 2.899799372309607}, {'label': 'SIMILARITY', 'score': 2.8083442412354382}, {'label': 'SIMILARITY', 'score': 0.6485375282493143}, {'label': 'SIMILARITY', 'score': 3.0110202252283753}, {'label': 'SIMILARITY', 'score': 3.23897640364101}, {'label': 'SIMILARITY', 'score': 4.1438053621014035}, {'label': 'SIMILARITY', 'score': 2.5780710016600707}, {'label': 'SIMILARITY', 'score': 2.486840668806698}, {'label': 'SIMILARITY', 'score': 1.8580878809792731}, {'label': 'SIMILARITY', 'score': 2.3066425000770687}, {'label': 'SIMILARITY', 'score': 2.497385088706873}, {'label': 'SIMILARITY', 'score': 4.229749670911981}, {'label': 'SIMILARITY', 'score': 1.4824638751848673}, {'label': 'SIMILARITY', 'score': 1.9703079039813782}, {'label': 'SIMILARITY', 'score': 3.0260864382474075}, {'label': 'SIMILARITY', 'score': 3.8321135515605946}, {'label': 'SIMILARITY', 'score': 3.394109638380895}, {'label': 'SIMILARITY', 'score': 2.714427831314883}, {'label': 'SIMILARITY', 'score': 4.225623117068601}, {'label': 'SIMILARITY', 'score': 0.8934796135497209}, {'label': 'SIMILARITY', 'score': 2.963847753801709}, {'label': 'SIMILARITY', 'score': 1.5892025721688132}, {'label': 'SIMILARITY', 'score': 2.4632011969765046}, {'label': 'SIMILARITY', 'score': 0.9980283397580882}, {'label': 'SIMILARITY', 'score': 3.0770793217423704}, {'label': 'SIMILARITY', 'score': 2.515052317331713}, {'label': 'SIMILARITY', 'score': 2.856845122056044}, {'label': 'SIMILARITY', 'score': 1.8623467562244573}, {'label': 'SIMILARITY', 'score': 2.8842874423553786}, {'label': 'SIMILARITY', 'score': 2.8372346229500303}, {'label': 'SIMILARITY', 'score': 2.2104247369403187}, {'label': 'SIMILARITY', 'score': 2.699187747718144}, {'label': 'SIMILARITY', 'score': 4.195852510728515}, {'label': 'SIMILARITY', 'score': 2.8933407413200087}, {'label': 'SIMILARITY', 'score': 2.7510270540550974}, {'label': 'SIMILARITY', 'score': 1.6474001377688259}, {'label': 'SIMILARITY', 'score': 1.9173333737018692}, {'label': 'SIMILARITY', 'score': 0.034052324215461185}, {'label': 'SIMILARITY', 'score': 2.0433950588434104}, {'label': 'SIMILARITY', 'score': 0.7159323739709014}, {'label': 'SIMILARITY', 'score': 2.48592202383072}, {'label': 'SIMILARITY', 'score': 0.8541683205392421}, {'label': 'SIMILARITY', 'score': 2.866539292114396}, {'label': 'SIMILARITY', 'score': 3.2467260433932044}, {'label': 'SIMILARITY', 'score': 1.9688755237304902}, {'label': 'SIMILARITY', 'score': 3.097886175354952}, {'label': 'SIMILARITY', 'score': 3.098480526089397}, {'label': 'SIMILARITY', 'score': 4.230167032371548}, {'label': 'SIMILARITY', 'score': 3.1101061997782398}, {'label': 'SIMILARITY', 'score': 2.765823148158267}, {'label': 'SIMILARITY', 'score': 2.9877963359391626}, {'label': 'SIMILARITY', 'score': 1.3643189749948856}, {'label': 'SIMILARITY', 'score': 2.1209620972293406}, {'label': 'SIMILARITY', 'score': 3.2086568270099796}, {'label': 'SIMILARITY', 'score': 3.013043636227416}, {'label': 'SIMILARITY', 'score': 0.7457657547402406}, {'label': 'SIMILARITY', 'score': 1.5660171181849194}, {'label': 'SIMILARITY', 'score': 0.9738820866812639}, {'label': 'SIMILARITY', 'score': 3.1085118646409886}, {'label': 'SIMILARITY', 'score': 3.102806493008044}, {'label': 'SIMILARITY', 'score': 3.4300606256815946}, {'label': 'SIMILARITY', 'score': 2.3298859069852504}, {'label': 'SIMILARITY', 'score': 3.1218022763698436}, {'label': 'SIMILARITY', 'score': 1.5513877201122228}, {'label': 'SIMILARITY', 'score': 2.829264244965164}, {'label': 'SIMILARITY', 'score': 2.811416427275298}, {'label': 'SIMILARITY', 'score': 3.311793054509829}, {'label': 'SIMILARITY', 'score': 0.8590896535149101}, {'label': 'SIMILARITY', 'score': 2.4052958543760634}, {'label': 'SIMILARITY', 'score': 3.0398653217774854}, {'label': 'SIMILARITY', 'score': 1.9133161044507512}, {'label': 'SIMILARITY', 'score': 0.7133416484106022}, {'label': 'SIMILARITY', 'score': 2.248183004619509}, {'label': 'SIMILARITY', 'score': 2.9969118767397562}, {'label': 'SIMILARITY', 'score': 3.332055372678551}, {'label': 'SIMILARITY', 'score': 2.6205714885977587}, {'label': 'SIMILARITY', 'score': 1.774445288008859}, {'label': 'SIMILARITY', 'score': 1.5920464405826367}, {'label': 'SIMILARITY', 'score': 2.8744014173839467}, {'label': 'SIMILARITY', 'score': 0.9816306592670437}, {'label': 'SIMILARITY', 'score': 1.9793031310431384}, {'label': 'SIMILARITY', 'score': 1.953010200587775}, {'label': 'SIMILARITY', 'score': 1.541124038752437}, {'label': 'SIMILARITY', 'score': 3.169429373791626}, {'label': 'SIMILARITY', 'score': 1.90844617790744}, {'label': 'SIMILARITY', 'score': 3.1420694698280487}, {'label': 'SIMILARITY', 'score': 1.2640142965612113}, {'label': 'SIMILARITY', 'score': 3.1005459504047295}, {'label': 'SIMILARITY', 'score': 2.5661151096577695}, {'label': 'SIMILARITY', 'score': 2.1049073924039363}, {'label': 'SIMILARITY', 'score': 2.6056299335326463}, {'label': 'SIMILARITY', 'score': 3.0325003893976716}, {'label': 'SIMILARITY', 'score': 3.368248036406151}, {'label': 'SIMILARITY', 'score': 4.229960438380887}, {'label': 'SIMILARITY', 'score': 3.1989010051702502}, {'label': 'SIMILARITY', 'score': 3.152963248371442}, {'label': 'SIMILARITY', 'score': 1.4202876279520948}, {'label': 'SIMILARITY', 'score': 1.2184930929344007}, {'label': 'SIMILARITY', 'score': 2.054270984496596}, {'label': 'SIMILARITY', 'score': 4.155347853156986}, {'label': 'SIMILARITY', 'score': 3.2524465152866155}, {'label': 'SIMILARITY', 'score': 2.581495959758173}, {'label': 'SIMILARITY', 'score': 4.226698381359096}, {'label': 'SIMILARITY', 'score': 1.0818150867199323}, {'label': 'SIMILARITY', 'score': 2.6994350772841975}, {'label': 'SIMILARITY', 'score': 2.2326376133418586}, {'label': 'SIMILARITY', 'score': 2.656800011875543}, {'label': 'SIMILARITY', 'score': 1.4062023929447576}, {'label': 'SIMILARITY', 'score': 2.8663801539082456}, {'label': 'SIMILARITY', 'score': 2.9656305583752953}, {'label': 'SIMILARITY', 'score': 3.7292119794925833}, {'label': 'SIMILARITY', 'score': 2.6037255401127077}, {'label': 'SIMILARITY', 'score': 3.148629220845153}, {'label': 'SIMILARITY', 'score': 2.7923896314801295}, {'label': 'SIMILARITY', 'score': 2.542273687886832}, {'label': 'SIMILARITY', 'score': 1.720448154949384}, {'label': 'SIMILARITY', 'score': 1.8322806104864793}, {'label': 'SIMILARITY', 'score': 3.036433039299446}, {'label': 'SIMILARITY', 'score': 2.59583265782504}, {'label': 'SIMILARITY', 'score': 1.6213009440315818}, {'label': 'SIMILARITY', 'score': 3.017558648749842}, {'label': 'SIMILARITY', 'score': 2.283177847237938}, {'label': 'SIMILARITY', 'score': 1.9253536672823575}, {'label': 'SIMILARITY', 'score': 2.4115774669013468}, {'label': 'SIMILARITY', 'score': 4.086524097063126}, {'label': 'SIMILARITY', 'score': 2.29016229909194}, {'label': 'SIMILARITY', 'score': 4.231027583825688}, {'label': 'SIMILARITY', 'score': 3.2353227471191643}, {'label': 'SIMILARITY', 'score': 2.7267241982743515}, {'label': 'SIMILARITY', 'score': 2.8975918089897665}, {'label': 'SIMILARITY', 'score': 3.287468925487733}, {'label': 'SIMILARITY', 'score': 2.110124854872156}, {'label': 'SIMILARITY', 'score': 3.9238726834672772}, {'label': 'SIMILARITY', 'score': 2.512956364454831}, {'label': 'SIMILARITY', 'score': 2.185333579696101}, {'label': 'SIMILARITY', 'score': 3.0644687498957324}, {'label': 'SIMILARITY', 'score': 1.9422166461990815}, {'label': 'SIMILARITY', 'score': 1.9049668452910087}, {'label': 'SIMILARITY', 'score': 2.581028450395889}, {'label': 'SIMILARITY', 'score': 3.13324801459684}, {'label': 'SIMILARITY', 'score': 1.3236724694777469}, {'label': 'SIMILARITY', 'score': 2.731833409399457}, {'label': 'SIMILARITY', 'score': 0.6287364646973483}, {'label': 'SIMILARITY', 'score': 3.2451660508255973}, {'label': 'SIMILARITY', 'score': 2.8610317614182805}, {'label': 'SIMILARITY', 'score': 3.0752596291267427}, {'label': 'SIMILARITY', 'score': 2.7156939191884533}, {'label': 'SIMILARITY', 'score': 2.175382097936648}, {'label': 'SIMILARITY', 'score': 3.038857609550097}, {'label': 'SIMILARITY', 'score': 1.1734607026969053}, {'label': 'SIMILARITY', 'score': 1.2267997837415492}, {'label': 'SIMILARITY', 'score': 0.8718432105190944}, {'label': 'SIMILARITY', 'score': 2.078656095552567}, {'label': 'SIMILARITY', 'score': 2.229766873297817}, {'label': 'SIMILARITY', 'score': 2.856843961913359}, {'label': 'SIMILARITY', 'score': 2.831286707225621}, {'label': 'SIMILARITY', 'score': 2.829813406014644}, {'label': 'SIMILARITY', 'score': 2.896349641193539}, {'label': 'SIMILARITY', 'score': 1.2448291946162573}, {'label': 'SIMILARITY', 'score': 2.8406577382292646}, {'label': 'SIMILARITY', 'score': 1.2466831643369258}, {'label': 'SIMILARITY', 'score': 2.0773853286854314}, {'label': 'SIMILARITY', 'score': 2.726219702393298}, {'label': 'SIMILARITY', 'score': 1.9037590639442183}, {'label': 'SIMILARITY', 'score': 3.7963658713228634}, {'label': 'SIMILARITY', 'score': 2.9663982386028462}, {'label': 'SIMILARITY', 'score': 4.224611881635764}, {'label': 'SIMILARITY', 'score': 1.795178900092425}, {'label': 'SIMILARITY', 'score': 3.2482916027865123}, {'label': 'SIMILARITY', 'score': 2.951172459999267}, {'label': 'SIMILARITY', 'score': 1.4263001649085536}, {'label': 'SIMILARITY', 'score': 2.2877209433583725}, {'label': 'SIMILARITY', 'score': 0.6276269853898965}, {'label': 'SIMILARITY', 'score': 3.1478287911810323}, {'label': 'SIMILARITY', 'score': 3.4519580964312424}, {'label': 'SIMILARITY', 'score': 1.9241328204539592}, {'label': 'SIMILARITY', 'score': 2.645226657791094}, {'label': 'SIMILARITY', 'score': 3.065686473625363}, {'label': 'SIMILARITY', 'score': 4.1070058178102515}, {'label': 'SIMILARITY', 'score': 3.146531230453979}, {'label': 'SIMILARITY', 'score': 4.229100778083209}, {'label': 'SIMILARITY', 'score': 1.766716402053653}, {'label': 'SIMILARITY', 'score': 3.0609937749194973}, {'label': 'SIMILARITY', 'score': 2.0112402859495546}, {'label': 'SIMILARITY', 'score': 2.429273836091733}, {'label': 'SIMILARITY', 'score': 3.1401219588712226}, {'label': 'SIMILARITY', 'score': 2.9773583752526873}, {'label': 'SIMILARITY', 'score': 1.8925926506138588}, {'label': 'SIMILARITY', 'score': 2.8616456112957995}, {'label': 'SIMILARITY', 'score': 2.951534846555649}, {'label': 'SIMILARITY', 'score': 2.126406745944653}, {'label': 'SIMILARITY', 'score': 3.304829672079567}, {'label': 'SIMILARITY', 'score': 2.898595691141948}, {'label': 'SIMILARITY', 'score': 2.6529881110551083}, {'label': 'SIMILARITY', 'score': 2.8862663603964696}, {'label': 'SIMILARITY', 'score': 3.1521853967034037}, {'label': 'SIMILARITY', 'score': 1.5310821816166167}, {'label': 'SIMILARITY', 'score': 3.020359875385059}, {'label': 'SIMILARITY', 'score': 2.8169565664205627}, {'label': 'SIMILARITY', 'score': 2.7191883114701536}, {'label': 'SIMILARITY', 'score': 1.560078220427731}, {'label': 'SIMILARITY', 'score': 2.8607895753662484}, {'label': 'SIMILARITY', 'score': 1.4971357666566159}, {'label': 'SIMILARITY', 'score': 2.738227769517429}, {'label': 'SIMILARITY', 'score': 2.989543649114411}, {'label': 'SIMILARITY', 'score': 4.190134074804389}, {'label': 'SIMILARITY', 'score': 3.096578874343152}, {'label': 'SIMILARITY', 'score': 2.452049796547854}, {'label': 'SIMILARITY', 'score': 4.176539484930962}, {'label': 'SIMILARITY', 'score': 3.043220523384986}, {'label': 'SIMILARITY', 'score': 3.2459094105694937}, {'label': 'SIMILARITY', 'score': 3.1148446120579347}, {'label': 'SIMILARITY', 'score': 1.508364024414071}, {'label': 'SIMILARITY', 'score': 2.7887132771167074}, {'label': 'SIMILARITY', 'score': 3.4568450042219707}, {'label': 'SIMILARITY', 'score': 2.2747578301587374}, {'label': 'SIMILARITY', 'score': 2.470745823562973}, {'label': 'SIMILARITY', 'score': 3.305562931081749}, {'label': 'SIMILARITY', 'score': 2.6745546514431253}, {'label': 'SIMILARITY', 'score': 4.2245783306790425}, {'label': 'SIMILARITY', 'score': 1.2658801847968424}, {'label': 'SIMILARITY', 'score': 2.8796105242126964}, {'label': 'SIMILARITY', 'score': 2.4558328435380177}, {'label': 'SIMILARITY', 'score': 3.118099720638933}, {'label': 'SIMILARITY', 'score': 2.8829530853714846}, {'label': 'SIMILARITY', 'score': 2.8801410624499586}, {'label': 'SIMILARITY', 'score': 2.7724897418736245}, {'label': 'SIMILARITY', 'score': 1.651869615586584}, {'label': 'SIMILARITY', 'score': 2.8632091260689854}, {'label': 'SIMILARITY', 'score': 1.5085026416184253}, {'label': 'SIMILARITY', 'score': 3.118786011942754}, {'label': 'SIMILARITY', 'score': 3.1738812036974124}, {'label': 'SIMILARITY', 'score': 2.036070261758442}, {'label': 'SIMILARITY', 'score': 2.7528263810990383}, {'label': 'SIMILARITY', 'score': 4.1806625683754435}, {'label': 'SIMILARITY', 'score': 1.2320985441052705}, {'label': 'SIMILARITY', 'score': 1.2957484218034554}, {'label': 'SIMILARITY', 'score': 3.3478988054886796}, {'label': 'SIMILARITY', 'score': 2.264673684756741}, {'label': 'SIMILARITY', 'score': 2.5168742515180464}, {'label': 'SIMILARITY', 'score': 3.03755046308862}, {'label': 'SIMILARITY', 'score': 3.0524205429172473}, {'label': 'SIMILARITY', 'score': 2.9403379760568096}, {'label': 'SIMILARITY', 'score': 2.871683655514791}, {'label': 'SIMILARITY', 'score': 2.0827360931317638}, {'label': 'SIMILARITY', 'score': 1.8351070701707577}, {'label': 'SIMILARITY', 'score': 1.0263297873540853}, {'label': 'SIMILARITY', 'score': 4.129740008998624}, {'label': 'SIMILARITY', 'score': 1.8084622494830973}, {'label': 'SIMILARITY', 'score': 2.8217377889373774}, {'label': 'SIMILARITY', 'score': 4.146795569336921}, {'label': 'SIMILARITY', 'score': 2.8372733857675}, {'label': 'SIMILARITY', 'score': 4.059118799415456}, {'label': 'SIMILARITY', 'score': 3.0723758025459795}, {'label': 'SIMILARITY', 'score': 4.143778218092622}, {'label': 'SIMILARITY', 'score': 2.6453027428007974}, {'label': 'SIMILARITY', 'score': 4.229673805184637}, {'label': 'SIMILARITY', 'score': 4.228380733086852}, {'label': 'SIMILARITY', 'score': 1.640688083980907}, {'label': 'SIMILARITY', 'score': 2.1972157028983883}, {'label': 'SIMILARITY', 'score': 3.099826220316177}, {'label': 'SIMILARITY', 'score': 3.2209319608525147}, {'label': 'SIMILARITY', 'score': 0.7663876843057055}, {'label': 'SIMILARITY', 'score': 1.9594957809155105}, {'label': 'SIMILARITY', 'score': 3.132086715480112}, {'label': 'SIMILARITY', 'score': 1.572129910105391}, {'label': 'SIMILARITY', 'score': 2.635405792931488}, {'label': 'SIMILARITY', 'score': 2.7638791842344297}, {'label': 'SIMILARITY', 'score': 1.3088853470286295}, {'label': 'SIMILARITY', 'score': 2.3816104191587297}, {'label': 'SIMILARITY', 'score': 3.5452368287572056}, {'label': 'SIMILARITY', 'score': 3.313915353448332}, {'label': 'SIMILARITY', 'score': 2.2461106340221577}, {'label': 'SIMILARITY', 'score': 0.4022297195265531}, {'label': 'SIMILARITY', 'score': 2.80970516326548}, {'label': 'SIMILARITY', 'score': 2.9112490127689985}, {'label': 'SIMILARITY', 'score': 2.984432247604211}, {'label': 'SIMILARITY', 'score': 1.3321492823069252}, {'label': 'SIMILARITY', 'score': 1.2312225276076645}, {'label': 'SIMILARITY', 'score': 3.160572360243504}, {'label': 'SIMILARITY', 'score': 2.5560084401552845}, {'label': 'SIMILARITY', 'score': 2.81678862207351}, {'label': 'SIMILARITY', 'score': 1.0611997015151478}, {'label': 'SIMILARITY', 'score': 2.1393188085232318}, {'label': 'SIMILARITY', 'score': 2.942049584170683}, {'label': 'SIMILARITY', 'score': 2.9394406855822157}, {'label': 'SIMILARITY', 'score': 1.5315857292043482}, {'label': 'SIMILARITY', 'score': 2.570199026746082}, {'label': 'SIMILARITY', 'score': 2.7713072690742084}, {'label': 'SIMILARITY', 'score': 3.4346272811980345}, {'label': 'SIMILARITY', 'score': 2.0100698705269973}, {'label': 'SIMILARITY', 'score': 4.2013691069237264}, {'label': 'SIMILARITY', 'score': 1.8717140451123586}, {'label': 'SIMILARITY', 'score': 2.394114021017703}, {'label': 'SIMILARITY', 'score': 4.2109509682516695}, {'label': 'SIMILARITY', 'score': 3.6559267472340986}, {'label': 'SIMILARITY', 'score': 2.537581780809042}, {'label': 'SIMILARITY', 'score': 1.6939611855811272}, {'label': 'SIMILARITY', 'score': 1.450488958231045}, {'label': 'SIMILARITY', 'score': 3.4263966903970497}, {'label': 'SIMILARITY', 'score': 1.913825189573365}, {'label': 'SIMILARITY', 'score': 3.6174109020736145}, {'label': 'SIMILARITY', 'score': 4.229168176485003}, {'label': 'SIMILARITY', 'score': 3.3049256656679984}, {'label': 'SIMILARITY', 'score': 2.692563089895942}, {'label': 'SIMILARITY', 'score': 3.228079871492045}, {'label': 'SIMILARITY', 'score': 2.440754551253095}, {'label': 'SIMILARITY', 'score': 2.1092980653753135}, {'label': 'SIMILARITY', 'score': 2.903265841969788}, {'label': 'SIMILARITY', 'score': 2.4662612133112285}, {'label': 'SIMILARITY', 'score': 2.091977475644338}, {'label': 'SIMILARITY', 'score': 4.092082307836056}, {'label': 'SIMILARITY', 'score': 1.704500017335719}, {'label': 'SIMILARITY', 'score': 3.214508105024464}, {'label': 'SIMILARITY', 'score': 2.8700589757826926}, {'label': 'SIMILARITY', 'score': 2.974992797638109}, {'label': 'SIMILARITY', 'score': 4.198179864945577}, {'label': 'SIMILARITY', 'score': 2.1428625308935483}, {'label': 'SIMILARITY', 'score': 2.2372577963930076}, {'label': 'SIMILARITY', 'score': 1.5118939406010605}, {'label': 'SIMILARITY', 'score': 3.312270953679279}, {'label': 'SIMILARITY', 'score': 3.5276928850977005}, {'label': 'SIMILARITY', 'score': 4.080995599647323}, {'label': 'SIMILARITY', 'score': 1.7417548677908263}, {'label': 'SIMILARITY', 'score': 1.9153259030153231}, {'label': 'SIMILARITY', 'score': 2.213783867836392}, {'label': 'SIMILARITY', 'score': 4.214557923901399}, {'label': 'SIMILARITY', 'score': 2.0441171322987484}, {'label': 'SIMILARITY', 'score': 4.219992152420881}, {'label': 'SIMILARITY', 'score': 2.8858495802738804}, {'label': 'SIMILARITY', 'score': 1.7291024917240958}, {'label': 'SIMILARITY', 'score': 3.164178545977202}, {'label': 'SIMILARITY', 'score': 3.173469976808441}, {'label': 'SIMILARITY', 'score': 1.933746712586543}, {'label': 'SIMILARITY', 'score': 3.0770977178876064}, {'label': 'SIMILARITY', 'score': 2.087687643905302}, {'label': 'SIMILARITY', 'score': 2.83682199578123}, {'label': 'SIMILARITY', 'score': 4.22678663648792}, {'label': 'SIMILARITY', 'score': 4.205782334241574}, {'label': 'SIMILARITY', 'score': 3.2409221830839403}, {'label': 'SIMILARITY', 'score': 2.6564129046941636}, {'label': 'SIMILARITY', 'score': 2.9921580156875924}, {'label': 'SIMILARITY', 'score': 2.800613530251556}, {'label': 'SIMILARITY', 'score': 0.5038581481197284}, {'label': 'SIMILARITY', 'score': 1.7460476574900716}, {'label': 'SIMILARITY', 'score': 3.286596864499533}, {'label': 'SIMILARITY', 'score': 3.0091242296733003}, {'label': 'SIMILARITY', 'score': 2.9190530049314423}, {'label': 'SIMILARITY', 'score': 1.80701024024446}, {'label': 'SIMILARITY', 'score': 3.3373759383931576}, {'label': 'SIMILARITY', 'score': 1.5672632619394746}, {'label': 'SIMILARITY', 'score': 3.0918542063285397}, {'label': 'SIMILARITY', 'score': 1.3979198782971145}, {'label': 'SIMILARITY', 'score': 1.520881304631895}, {'label': 'SIMILARITY', 'score': 2.985693559101881}, {'label': 'SIMILARITY', 'score': 2.566757567487595}, {'label': 'SIMILARITY', 'score': 4.213814770412939}, {'label': 'SIMILARITY', 'score': 3.0034371744112622}, {'label': 'SIMILARITY', 'score': 2.9034315263489696}, {'label': 'SIMILARITY', 'score': 2.459516232270932}, {'label': 'SIMILARITY', 'score': 3.2172275565700432}, {'label': 'SIMILARITY', 'score': 1.532377057163061}, {'label': 'SIMILARITY', 'score': 2.3941109097216797}, {'label': 'SIMILARITY', 'score': 1.7902489290434058}, {'label': 'SIMILARITY', 'score': 2.6381237877163084}, {'label': 'SIMILARITY', 'score': 2.4106165610887986}, {'label': 'SIMILARITY', 'score': 3.6796678547732595}, {'label': 'SIMILARITY', 'score': 2.7801892427792105}, {'label': 'SIMILARITY', 'score': 2.5140150593543593}, {'label': 'SIMILARITY', 'score': 2.0392705110381937}, {'label': 'SIMILARITY', 'score': 1.4291220456604727}, {'label': 'SIMILARITY', 'score': 1.1553854649989794}, {'label': 'SIMILARITY', 'score': 2.30180675519254}, {'label': 'SIMILARITY', 'score': 2.9728510954078793}, {'label': 'SIMILARITY', 'score': 3.1760543203474896}, {'label': 'SIMILARITY', 'score': 1.2759631107723173}, {'label': 'SIMILARITY', 'score': 3.1489042210445066}, {'label': 'SIMILARITY', 'score': 2.5204080878449506}, {'label': 'SIMILARITY', 'score': 2.5560494636174975}, {'label': 'SIMILARITY', 'score': 2.7988337059246016}, {'label': 'SIMILARITY', 'score': 3.0716757423788392}, {'label': 'SIMILARITY', 'score': 3.6975428602103366}, {'label': 'SIMILARITY', 'score': 3.6450970324131324}, {'label': 'SIMILARITY', 'score': 1.443513244027849}, {'label': 'SIMILARITY', 'score': 1.7574139892345304}, {'label': 'SIMILARITY', 'score': 2.6049665744478205}, {'label': 'SIMILARITY', 'score': 2.773317884312862}, {'label': 'SIMILARITY', 'score': 1.7254965152467348}, {'label': 'SIMILARITY', 'score': 2.4598079459790974}, {'label': 'SIMILARITY', 'score': 3.9863905474083907}, {'label': 'SIMILARITY', 'score': 3.2971708579547587}, {'label': 'SIMILARITY', 'score': 2.161590121513415}, {'label': 'SIMILARITY', 'score': 2.4803548545526866}, {'label': 'SIMILARITY', 'score': 3.0236965290412474}, {'label': 'SIMILARITY', 'score': 1.9101483588927066}, {'label': 'SIMILARITY', 'score': 2.9913722710357113}, {'label': 'SIMILARITY', 'score': 1.9437391744941144}, {'label': 'SIMILARITY', 'score': 1.3810110357799548}, {'label': 'SIMILARITY', 'score': 1.4859968147807474}, {'label': 'SIMILARITY', 'score': 3.1202835347002207}, {'label': 'SIMILARITY', 'score': 3.1880690915792447}, {'label': 'SIMILARITY', 'score': 2.5317576064248852}, {'label': 'SIMILARITY', 'score': 1.978577949383262}, {'label': 'SIMILARITY', 'score': 4.126985645635536}, {'label': 'SIMILARITY', 'score': 2.655806244833704}, {'label': 'SIMILARITY', 'score': 3.0836023777948522}, {'label': 'SIMILARITY', 'score': 3.9385748555753715}, {'label': 'SIMILARITY', 'score': 3.7404621818175445}, {'label': 'SIMILARITY', 'score': 3.0963124168881144}, {'label': 'SIMILARITY', 'score': 0.583272814588352}, {'label': 'SIMILARITY', 'score': 2.423776359675736}, {'label': 'SIMILARITY', 'score': 2.992350608317846}, {'label': 'SIMILARITY', 'score': 2.1555848807897977}, {'label': 'SIMILARITY', 'score': 2.788451215110736}, {'label': 'SIMILARITY', 'score': 2.963532387252444}, {'label': 'SIMILARITY', 'score': 2.4938189242146382}, {'label': 'SIMILARITY', 'score': 2.4598342448223276}, {'label': 'SIMILARITY', 'score': 1.53093909790328}, {'label': 'SIMILARITY', 'score': 2.3934880350649075}, {'label': 'SIMILARITY', 'score': 3.071827830147404}, {'label': 'SIMILARITY', 'score': 1.8728389008479969}, {'label': 'SIMILARITY', 'score': 0.27437341759919387}, {'label': 'SIMILARITY', 'score': 2.1803525473680727}, {'label': 'SIMILARITY', 'score': 4.201090319983246}, {'label': 'SIMILARITY', 'score': 1.4732320694862793}, {'label': 'SIMILARITY', 'score': 1.8058085173904337}, {'label': 'SIMILARITY', 'score': 1.885932146710877}, {'label': 'SIMILARITY', 'score': 2.1267004133503695}, {'label': 'SIMILARITY', 'score': 1.3847048671712126}, {'label': 'SIMILARITY', 'score': 3.689000673107928}, {'label': 'SIMILARITY', 'score': 2.8596759600788557}, {'label': 'SIMILARITY', 'score': 3.274991029838873}, {'label': 'SIMILARITY', 'score': 3.0085058066537074}, {'label': 'SIMILARITY', 'score': 2.1163454051533157}, {'label': 'SIMILARITY', 'score': 2.8633013027395955}, {'label': 'SIMILARITY', 'score': 2.8342015882493565}, {'label': 'SIMILARITY', 'score': 3.2237793133772112}, {'label': 'SIMILARITY', 'score': 2.106809191505433}, {'label': 'SIMILARITY', 'score': 1.5022161222540622}, {'label': 'SIMILARITY', 'score': 2.9858264124157996}, {'label': 'SIMILARITY', 'score': 3.5188494449678545}, {'label': 'SIMILARITY', 'score': 0.6860419093768225}, {'label': 'SIMILARITY', 'score': 3.2256476573666353}, {'label': 'SIMILARITY', 'score': 4.228309177178264}, {'label': 'SIMILARITY', 'score': 4.19250951414441}, {'label': 'SIMILARITY', 'score': 3.086681504918212}, {'label': 'SIMILARITY', 'score': 3.0624729264066364}, {'label': 'SIMILARITY', 'score': 0.3571664924157631}, {'label': 'SIMILARITY', 'score': 3.284395819596529}, {'label': 'SIMILARITY', 'score': 2.7638984150841748}, {'label': 'SIMILARITY', 'score': 2.9656139311859335}, {'label': 'SIMILARITY', 'score': 3.7356086738274725}, {'label': 'SIMILARITY', 'score': 4.229214515445745}, {'label': 'SIMILARITY', 'score': 2.8433861025705705}, {'label': 'SIMILARITY', 'score': 4.180329060981676}, {'label': 'SIMILARITY', 'score': 1.9135145024035232}, {'label': 'SIMILARITY', 'score': 4.228347059098615}, {'label': 'SIMILARITY', 'score': 1.5362027413694244}, {'label': 'SIMILARITY', 'score': 1.4132070111942352}, {'label': 'SIMILARITY', 'score': 1.6403581207525495}, {'label': 'SIMILARITY', 'score': 2.4434499729399985}, {'label': 'SIMILARITY', 'score': 4.226429459996051}, {'label': 'SIMILARITY', 'score': 3.1965033247883654}, {'label': 'SIMILARITY', 'score': 2.162742934054114}, {'label': 'SIMILARITY', 'score': 2.9795023446324804}, {'label': 'SIMILARITY', 'score': 2.6476407101603083}, {'label': 'SIMILARITY', 'score': 1.2158042721429376}, {'label': 'SIMILARITY', 'score': 4.221550667780023}, {'label': 'SIMILARITY', 'score': 1.9536475253455343}, {'label': 'SIMILARITY', 'score': 3.4577646814912466}, {'label': 'SIMILARITY', 'score': 2.9828111865291462}, {'label': 'SIMILARITY', 'score': 2.056740698156049}, {'label': 'SIMILARITY', 'score': 3.289117124286104}, {'label': 'SIMILARITY', 'score': 2.824101661700424}, {'label': 'SIMILARITY', 'score': 1.5818898856173353}, {'label': 'SIMILARITY', 'score': 1.867759652932041}, {'label': 'SIMILARITY', 'score': 1.8354581477799998}, {'label': 'SIMILARITY', 'score': 2.7490903077361035}, {'label': 'SIMILARITY', 'score': 4.216133188253521}, {'label': 'SIMILARITY', 'score': 3.1801196652609915}, {'label': 'SIMILARITY', 'score': 3.2899361455810605}, {'label': 'SIMILARITY', 'score': 3.2128303381647205}, {'label': 'SIMILARITY', 'score': 2.7434739654649887}, {'label': 'SIMILARITY', 'score': 3.042655355013823}, {'label': 'SIMILARITY', 'score': 2.4378731808745564}, {'label': 'SIMILARITY', 'score': 4.225383855520518}, {'label': 'SIMILARITY', 'score': 3.7022916328832305}, {'label': 'SIMILARITY', 'score': 1.952100500492617}, {'label': 'SIMILARITY', 'score': 2.8481660918916325}, {'label': 'SIMILARITY', 'score': 3.1521550823489197}, {'label': 'SIMILARITY', 'score': 1.9510179956170803}, {'label': 'SIMILARITY', 'score': 2.253177569281694}, {'label': 'SIMILARITY', 'score': 3.7337666060858856}, {'label': 'SIMILARITY', 'score': 1.7381379538955632}, {'label': 'SIMILARITY', 'score': 2.7724133118946934}, {'label': 'SIMILARITY', 'score': 1.6421578171353095}, {'label': 'SIMILARITY', 'score': 2.734367484029553}, {'label': 'SIMILARITY', 'score': 2.0496670147201166}, {'label': 'SIMILARITY', 'score': 2.388607990629304}, {'label': 'SIMILARITY', 'score': 4.202825764803667}, {'label': 'SIMILARITY', 'score': 2.8712793211582937}, {'label': 'SIMILARITY', 'score': 2.4772023795853952}, {'label': 'SIMILARITY', 'score': 2.1173756932849703}, {'label': 'SIMILARITY', 'score': 1.6187660775273702}, {'label': 'SIMILARITY', 'score': 1.9826419774907291}, {'label': 'SIMILARITY', 'score': 2.807401231581593}, {'label': 'SIMILARITY', 'score': 2.328320354164411}, {'label': 'SIMILARITY', 'score': 2.287342658248627}, {'label': 'SIMILARITY', 'score': 2.656915780266112}, {'label': 'SIMILARITY', 'score': 2.3285199900356384}, {'label': 'SIMILARITY', 'score': 3.2527641002704306}, {'label': 'SIMILARITY', 'score': 2.4196858863217985}, {'label': 'SIMILARITY', 'score': 3.484349247112656}, {'label': 'SIMILARITY', 'score': 2.978443426881}, {'label': 'SIMILARITY', 'score': 1.9126455974829242}, {'label': 'SIMILARITY', 'score': 2.0699265348980918}, {'label': 'SIMILARITY', 'score': 2.1006642817293506}, {'label': 'SIMILARITY', 'score': 2.4510516621728335}, {'label': 'SIMILARITY', 'score': 3.2032054450171583}, {'label': 'SIMILARITY', 'score': 2.589246749384223}, {'label': 'SIMILARITY', 'score': 2.462269411605626}, {'label': 'SIMILARITY', 'score': 2.8100868274151316}, {'label': 'SIMILARITY', 'score': 3.335709642254214}, {'label': 'SIMILARITY', 'score': 4.211327656607019}, {'label': 'SIMILARITY', 'score': 2.4052361875598693}, {'label': 'SIMILARITY', 'score': 2.6787253842410856}, {'label': 'SIMILARITY', 'score': 2.706443055210308}, {'label': 'SIMILARITY', 'score': 2.9367606282751795}, {'label': 'SIMILARITY', 'score': 1.9900430200478845}, {'label': 'SIMILARITY', 'score': 2.833275320569283}, {'label': 'SIMILARITY', 'score': 2.4320381215951206}, {'label': 'SIMILARITY', 'score': 2.8873674069459336}, {'label': 'SIMILARITY', 'score': 0.8420838545702727}, {'label': 'SIMILARITY', 'score': 2.472086966713493}, {'label': 'SIMILARITY', 'score': 3.052586593219088}, {'label': 'SIMILARITY', 'score': 3.003781332823669}, {'label': 'SIMILARITY', 'score': 4.22629922645644}, {'label': 'SIMILARITY', 'score': 3.7530479233772023}, {'label': 'SIMILARITY', 'score': 3.3980126161401203}, {'label': 'SIMILARITY', 'score': 3.4833258861992302}, {'label': 'SIMILARITY', 'score': 3.7597556300336206}, {'label': 'SIMILARITY', 'score': 3.5017078881819867}, {'label': 'SIMILARITY', 'score': 1.8946499698672221}, {'label': 'SIMILARITY', 'score': 3.0773326496446067}, {'label': 'SIMILARITY', 'score': 2.100001186094684}, {'label': 'SIMILARITY', 'score': 1.8214170260301572}, {'label': 'SIMILARITY', 'score': 3.47071815893391}, {'label': 'SIMILARITY', 'score': 2.841641612949123}, {'label': 'SIMILARITY', 'score': 4.229332478576151}, {'label': 'SIMILARITY', 'score': 2.2784131844276683}, {'label': 'SIMILARITY', 'score': 3.3014317840560725}, {'label': 'SIMILARITY', 'score': 3.6569614343483217}, {'label': 'SIMILARITY', 'score': 2.9020149329806117}, {'label': 'SIMILARITY', 'score': 2.9496093666991263}, {'label': 'SIMILARITY', 'score': 2.835827525579301}, {'label': 'SIMILARITY', 'score': 2.5917489897037065}, {'label': 'SIMILARITY', 'score': 1.760787490904456}, {'label': 'SIMILARITY', 'score': 1.6429033260745773}, {'label': 'SIMILARITY', 'score': 1.6843649665593783}, {'label': 'SIMILARITY', 'score': 3.1068107937664733}, {'label': 'SIMILARITY', 'score': 2.3408740957913414}, {'label': 'SIMILARITY', 'score': 0.9801058609500465}, {'label': 'SIMILARITY', 'score': 0.7149070479345434}, {'label': 'SIMILARITY', 'score': 4.2239117320919615}, {'label': 'SIMILARITY', 'score': 2.9963554816748026}, {'label': 'SIMILARITY', 'score': 3.026652624639244}, {'label': 'SIMILARITY', 'score': 1.5732968349391887}, {'label': 'SIMILARITY', 'score': 4.228431246134341}, {'label': 'SIMILARITY', 'score': 4.032336827903548}, {'label': 'SIMILARITY', 'score': 2.1819707841847538}, {'label': 'SIMILARITY', 'score': 2.66022545120832}, {'label': 'SIMILARITY', 'score': 3.397563447673433}, {'label': 'SIMILARITY', 'score': 2.1320678735938956}, {'label': 'SIMILARITY', 'score': 2.6779165783298433}, {'label': 'SIMILARITY', 'score': 3.0281363584297116}, {'label': 'SIMILARITY', 'score': 2.5823284637120016}, {'label': 'SIMILARITY', 'score': 3.3589149370684326}, {'label': 'SIMILARITY', 'score': 2.939661816674804}, {'label': 'SIMILARITY', 'score': 2.1143505819415687}, {'label': 'SIMILARITY', 'score': 0.7585168732431353}, {'label': 'SIMILARITY', 'score': 4.222211555021264}, {'label': 'SIMILARITY', 'score': 3.4048456889775243}, {'label': 'SIMILARITY', 'score': 3.5503053954489685}, {'label': 'SIMILARITY', 'score': 1.4650617076025332}, {'label': 'SIMILARITY', 'score': 2.848699227502611}, {'label': 'SIMILARITY', 'score': 3.1768339237737027}, {'label': 'SIMILARITY', 'score': 4.188695233366358}, {'label': 'SIMILARITY', 'score': 1.3238336768341024}, {'label': 'SIMILARITY', 'score': 2.7135504793899385}, {'label': 'SIMILARITY', 'score': 2.881903828506379}, {'label': 'SIMILARITY', 'score': 1.6690233523164926}, {'label': 'SIMILARITY', 'score': 2.8705110180228957}, {'label': 'SIMILARITY', 'score': 2.945267227683559}, {'label': 'SIMILARITY', 'score': 3.268012793924745}, {'label': 'SIMILARITY', 'score': 3.045040086768937}, {'label': 'SIMILARITY', 'score': 2.0400687330725678}, {'label': 'SIMILARITY', 'score': 4.1089197699232685}, {'label': 'SIMILARITY', 'score': 1.9717390572596238}, {'label': 'SIMILARITY', 'score': 3.199614851911162}, {'label': 'SIMILARITY', 'score': 4.162718862851803}, {'label': 'SIMILARITY', 'score': 1.9350747325455304}, {'label': 'SIMILARITY', 'score': 2.8426698812670965}, {'label': 'SIMILARITY', 'score': 3.2228875991309285}, {'label': 'SIMILARITY', 'score': 2.956521766743539}, {'label': 'SIMILARITY', 'score': 2.697699851453724}, {'label': 'SIMILARITY', 'score': 2.991267547256921}, {'label': 'SIMILARITY', 'score': 2.3414711367135577}, {'label': 'SIMILARITY', 'score': 2.400758669523344}, {'label': 'SIMILARITY', 'score': 4.226404252218907}, {'label': 'SIMILARITY', 'score': 2.932463332209097}, {'label': 'SIMILARITY', 'score': 3.0360376420816206}, {'label': 'SIMILARITY', 'score': 2.7591295427679596}, {'label': 'SIMILARITY', 'score': 3.863877941192224}, {'label': 'SIMILARITY', 'score': 2.2003468570144293}, {'label': 'SIMILARITY', 'score': 2.6983472268514026}, {'label': 'SIMILARITY', 'score': 2.306338619426483}, {'label': 'SIMILARITY', 'score': 1.8585296722542137}, {'label': 'SIMILARITY', 'score': 2.845462858746485}, {'label': 'SIMILARITY', 'score': 3.117027794089612}, {'label': 'SIMILARITY', 'score': 4.2271229158209715}, {'label': 'SIMILARITY', 'score': 1.6256606867739714}, {'label': 'SIMILARITY', 'score': 2.934059664463582}, {'label': 'SIMILARITY', 'score': 3.200983711754559}, {'label': 'SIMILARITY', 'score': 1.7496044303338367}, {'label': 'SIMILARITY', 'score': 1.318372504101822}, {'label': 'SIMILARITY', 'score': 2.7581256559866127}, {'label': 'SIMILARITY', 'score': 0.7920408694421555}, {'label': 'SIMILARITY', 'score': 1.3510702732417834}, {'label': 'SIMILARITY', 'score': 3.0515851370645026}, {'label': 'SIMILARITY', 'score': 1.6404737967030765}, {'label': 'SIMILARITY', 'score': 2.4279448978066327}, {'label': 'SIMILARITY', 'score': 4.22374829266195}, {'label': 'SIMILARITY', 'score': 3.097511265680129}, {'label': 'SIMILARITY', 'score': 3.0438354050842604}, {'label': 'SIMILARITY', 'score': 2.9903974145046677}, {'label': 'SIMILARITY', 'score': 4.225677693278653}, {'label': 'SIMILARITY', 'score': 3.13810459945878}, {'label': 'SIMILARITY', 'score': 2.8442507599796523}, {'label': 'SIMILARITY', 'score': 2.854575857863823}, {'label': 'SIMILARITY', 'score': 2.688924894055085}, {'label': 'SIMILARITY', 'score': 2.7850564531909803}, {'label': 'SIMILARITY', 'score': 2.9045363143866765}, {'label': 'SIMILARITY', 'score': 1.4204986941567583}, {'label': 'SIMILARITY', 'score': 1.8351959612052422}, {'label': 'SIMILARITY', 'score': 2.044181727552023}, {'label': 'SIMILARITY', 'score': 2.91151212536389}, {'label': 'SIMILARITY', 'score': 3.017329443106786}, {'label': 'SIMILARITY', 'score': 3.9057076686338474}, {'label': 'SIMILARITY', 'score': 2.4575558048312836}, {'label': 'SIMILARITY', 'score': 1.8706715443998922}, {'label': 'SIMILARITY', 'score': 1.9190543148483499}, {'label': 'SIMILARITY', 'score': 2.3289893739463348}, {'label': 'SIMILARITY', 'score': 1.9447395509491203}, {'label': 'SIMILARITY', 'score': 2.7316132309543693}, {'label': 'SIMILARITY', 'score': 2.6829561154376695}, {'label': 'SIMILARITY', 'score': 3.345541588891716}, {'label': 'SIMILARITY', 'score': 0.8788336193439932}, {'label': 'SIMILARITY', 'score': 3.2332645021613216}, {'label': 'SIMILARITY', 'score': 2.8652200641485415}, {'label': 'SIMILARITY', 'score': 1.3439022599585424}, {'label': 'SIMILARITY', 'score': 0.9954229912269812}, {'label': 'SIMILARITY', 'score': 2.0842187063009905}, {'label': 'SIMILARITY', 'score': 2.505767693303969}, {'label': 'SIMILARITY', 'score': 4.171735356092364}, {'label': 'SIMILARITY', 'score': 4.1527590715974005}, {'label': 'SIMILARITY', 'score': 2.6928712287908154}, {'label': 'SIMILARITY', 'score': 2.3624362088752213}, {'label': 'SIMILARITY', 'score': 3.006339405901469}, {'label': 'SIMILARITY', 'score': 2.404342326090762}, {'label': 'SIMILARITY', 'score': 1.7020017105875225}, {'label': 'SIMILARITY', 'score': 2.9124505785267885}, {'label': 'SIMILARITY', 'score': 2.8650692938911697}, {'label': 'SIMILARITY', 'score': 3.0404235839553375}, {'label': 'SIMILARITY', 'score': 1.7803740760362319}, {'label': 'SIMILARITY', 'score': 1.625294140606527}, {'label': 'SIMILARITY', 'score': 4.227425661154405}, {'label': 'SIMILARITY', 'score': 2.8495530018333852}, {'label': 'SIMILARITY', 'score': 2.5490801211430067}, {'label': 'SIMILARITY', 'score': 2.947730009738462}, {'label': 'SIMILARITY', 'score': 3.2068796894543086}, {'label': 'SIMILARITY', 'score': 2.9642641239334337}, {'label': 'SIMILARITY', 'score': 1.8952916540332576}, {'label': 'SIMILARITY', 'score': 2.8937411402993285}, {'label': 'SIMILARITY', 'score': 4.222575642441926}, {'label': 'SIMILARITY', 'score': 3.051752444011898}, {'label': 'SIMILARITY', 'score': 3.619134952907555}, {'label': 'SIMILARITY', 'score': 0.8150621956757004}, {'label': 'SIMILARITY', 'score': 1.6133769893961507}, {'label': 'SIMILARITY', 'score': 2.8016635518236543}, {'label': 'SIMILARITY', 'score': 2.9359758015138424}, {'label': 'SIMILARITY', 'score': 2.9442429912836863}, {'label': 'SIMILARITY', 'score': 3.2343887767010036}, {'label': 'SIMILARITY', 'score': 2.54216880752728}, {'label': 'SIMILARITY', 'score': 2.6264700641869023}, {'label': 'SIMILARITY', 'score': 1.0988370505450546}, {'label': 'SIMILARITY', 'score': 2.5326043457005576}, {'label': 'SIMILARITY', 'score': 2.4510655307425053}, {'label': 'SIMILARITY', 'score': 1.7838146318236396}, {'label': 'SIMILARITY', 'score': 2.7455861748316788}, {'label': 'SIMILARITY', 'score': 1.9153429480391804}, {'label': 'SIMILARITY', 'score': 3.0387250485390367}, {'label': 'SIMILARITY', 'score': 2.4813118618224785}, {'label': 'SIMILARITY', 'score': 3.4791970679559454}, {'label': 'SIMILARITY', 'score': 4.144651061548484}, {'label': 'SIMILARITY', 'score': 2.467783432208337}, {'label': 'SIMILARITY', 'score': 3.0348768131162296}, {'label': 'SIMILARITY', 'score': 2.4071068990824163}, {'label': 'SIMILARITY', 'score': 3.0374071402218594}, {'label': 'SIMILARITY', 'score': 2.0340555255577333}, {'label': 'SIMILARITY', 'score': 3.2429274978453013}, {'label': 'SIMILARITY', 'score': 2.9608114504691185}, {'label': 'SIMILARITY', 'score': 3.32864008053628}, {'label': 'SIMILARITY', 'score': 3.3287364390816965}, {'label': 'SIMILARITY', 'score': 3.260742598901819}, {'label': 'SIMILARITY', 'score': 2.9295895024058645}, {'label': 'SIMILARITY', 'score': 3.208131678028741}, {'label': 'SIMILARITY', 'score': 3.2729050145978147}, {'label': 'SIMILARITY', 'score': 2.8356373891711506}, {'label': 'SIMILARITY', 'score': 3.201906765461919}, {'label': 'SIMILARITY', 'score': 1.8802936010479676}, {'label': 'SIMILARITY', 'score': 1.9569359941917523}, {'label': 'SIMILARITY', 'score': 2.8302597259448485}, {'label': 'SIMILARITY', 'score': 3.125979010588841}, {'label': 'SIMILARITY', 'score': 2.6181935477243874}, {'label': 'SIMILARITY', 'score': 3.20976062833578}, {'label': 'SIMILARITY', 'score': 3.150928059364242}, {'label': 'SIMILARITY', 'score': 2.768923481476384}, {'label': 'SIMILARITY', 'score': 3.7056968032453086}, {'label': 'SIMILARITY', 'score': 2.021846248082909}, {'label': 'SIMILARITY', 'score': 4.196668527813787}, {'label': 'SIMILARITY', 'score': 3.553345442029783}, {'label': 'SIMILARITY', 'score': 1.7299517025025237}, {'label': 'SIMILARITY', 'score': 2.5770753505386312}, {'label': 'SIMILARITY', 'score': 2.609718939295725}, {'label': 'SIMILARITY', 'score': 2.479320083746472}, {'label': 'SIMILARITY', 'score': 1.584883431673738}, {'label': 'SIMILARITY', 'score': 3.434142757031424}, {'label': 'SIMILARITY', 'score': 2.0613193747001266}, {'label': 'SIMILARITY', 'score': 1.9204539365656026}, {'label': 'SIMILARITY', 'score': 1.847818275063934}, {'label': 'SIMILARITY', 'score': 3.231714005710603}, {'label': 'SIMILARITY', 'score': 2.535330469565657}, {'label': 'SIMILARITY', 'score': 2.828818319546671}, {'label': 'SIMILARITY', 'score': 2.9482851723217247}, {'label': 'SIMILARITY', 'score': 2.8112994397930446}, {'label': 'SIMILARITY', 'score': 2.9738544222280825}, {'label': 'SIMILARITY', 'score': 1.76210378025411}, {'label': 'SIMILARITY', 'score': 3.0705751427725207}, {'label': 'SIMILARITY', 'score': 4.2066433482568195}, {'label': 'SIMILARITY', 'score': 1.931673574839772}, {'label': 'SIMILARITY', 'score': 1.9572855152658692}, {'label': 'SIMILARITY', 'score': 1.4202705156685276}, {'label': 'SIMILARITY', 'score': 2.3199665547161277}, {'label': 'SIMILARITY', 'score': 2.941670250674881}, {'label': 'SIMILARITY', 'score': 2.901236089450833}, {'label': 'SIMILARITY', 'score': 2.6022640318532786}, {'label': 'SIMILARITY', 'score': 1.7794043923022156}, {'label': 'SIMILARITY', 'score': 2.328259217630623}, {'label': 'SIMILARITY', 'score': 4.228111372013784}, {'label': 'SIMILARITY', 'score': 2.7614491063615154}, {'label': 'SIMILARITY', 'score': 2.891216472865493}, {'label': 'SIMILARITY', 'score': 2.4531313064931064}, {'label': 'SIMILARITY', 'score': 1.218569239243021}, {'label': 'SIMILARITY', 'score': 1.6067044074372747}, {'label': 'SIMILARITY', 'score': 2.9980149719171383}, {'label': 'SIMILARITY', 'score': 2.2433947901213807}, {'label': 'SIMILARITY', 'score': 2.083799599226641}, {'label': 'SIMILARITY', 'score': 3.6033747618612275}, {'label': 'SIMILARITY', 'score': 1.9036180680633412}, {'label': 'SIMILARITY', 'score': 2.9971605693608625}, {'label': 'SIMILARITY', 'score': 2.6411648512905237}, {'label': 'SIMILARITY', 'score': 1.8396962043401504}, {'label': 'SIMILARITY', 'score': 3.075693423098079}, {'label': 'SIMILARITY', 'score': 4.160615926951101}, {'label': 'SIMILARITY', 'score': 2.0948449531058495}, {'label': 'SIMILARITY', 'score': 3.077389267232347}, {'label': 'SIMILARITY', 'score': 2.2749848697238817}, {'label': 'SIMILARITY', 'score': 1.8656111244079292}, {'label': 'SIMILARITY', 'score': 3.242036336560086}, {'label': 'SIMILARITY', 'score': 3.393937050739828}, {'label': 'SIMILARITY', 'score': 2.5248553629883337}, {'label': 'SIMILARITY', 'score': 3.1644513700343624}, {'label': 'SIMILARITY', 'score': 1.7567960917046934}, {'label': 'SIMILARITY', 'score': 4.23086301101293}, {'label': 'SIMILARITY', 'score': 2.4543545003813763}, {'label': 'SIMILARITY', 'score': 2.182417719932124}, {'label': 'SIMILARITY', 'score': 3.295627960949742}, {'label': 'SIMILARITY', 'score': 3.4958949806662263}, {'label': 'SIMILARITY', 'score': 1.8133814740968996}, {'label': 'SIMILARITY', 'score': 2.9066254514977454}, {'label': 'SIMILARITY', 'score': 2.9602130772656627}, {'label': 'SIMILARITY', 'score': 2.837208401801777}, {'label': 'SIMILARITY', 'score': 2.9610508901621553}, {'label': 'SIMILARITY', 'score': 2.4250384039013926}, {'label': 'SIMILARITY', 'score': 2.5680561604701735}, {'label': 'SIMILARITY', 'score': 2.483392509740989}, {'label': 'SIMILARITY', 'score': 4.222454265664663}, {'label': 'SIMILARITY', 'score': 2.987938577356085}, {'label': 'SIMILARITY', 'score': 2.0756512031598358}, {'label': 'SIMILARITY', 'score': 1.6238245237073552}, {'label': 'SIMILARITY', 'score': 2.731756549824859}, {'label': 'SIMILARITY', 'score': 3.016581840050175}, {'label': 'SIMILARITY', 'score': 3.0427074700412273}, {'label': 'SIMILARITY', 'score': 2.180572112868481}, {'label': 'SIMILARITY', 'score': 2.860760469986587}, {'label': 'SIMILARITY', 'score': 2.46447936969561}, {'label': 'SIMILARITY', 'score': 2.4135506083465765}, {'label': 'SIMILARITY', 'score': 2.7788763698297014}, {'label': 'SIMILARITY', 'score': 1.7458101642351165}, {'label': 'SIMILARITY', 'score': 3.243478045668779}, {'label': 'SIMILARITY', 'score': 1.6594528588832609}, {'label': 'SIMILARITY', 'score': 2.8722904308771082}, {'label': 'SIMILARITY', 'score': 2.9595870407061398}, {'label': 'SIMILARITY', 'score': 1.9603146995745615}, {'label': 'SIMILARITY', 'score': 1.7801041964149957}, {'label': 'SIMILARITY', 'score': 4.096114205933234}, {'label': 'SIMILARITY', 'score': 1.805118843562925}, {'label': 'SIMILARITY', 'score': 2.8947475663821227}, {'label': 'SIMILARITY', 'score': 1.4727115042802743}, {'label': 'SIMILARITY', 'score': 2.297759203035799}, {'label': 'SIMILARITY', 'score': 2.020989888435087}, {'label': 'SIMILARITY', 'score': 4.222420784933289}, {'label': 'SIMILARITY', 'score': 1.1749835957685313}, {'label': 'SIMILARITY', 'score': 3.131946847456983}, {'label': 'SIMILARITY', 'score': 1.3724336586352714}, {'label': 'SIMILARITY', 'score': 2.949386247158979}, {'label': 'SIMILARITY', 'score': 4.203487069289574}, {'label': 'SIMILARITY', 'score': 4.068676985291318}, {'label': 'SIMILARITY', 'score': 1.5888338120844998}, {'label': 'SIMILARITY', 'score': 2.9441727351595137}, {'label': 'SIMILARITY', 'score': 1.9846425024728889}, {'label': 'SIMILARITY', 'score': 2.9238098095046348}, {'label': 'SIMILARITY', 'score': 1.9002475292606436}, {'label': 'SIMILARITY', 'score': 3.2854786382103045}, {'label': 'SIMILARITY', 'score': 4.22744248294999}, {'label': 'SIMILARITY', 'score': 2.4583624062024403}, {'label': 'SIMILARITY', 'score': 3.107287816123369}, {'label': 'SIMILARITY', 'score': 1.718624597787437}, {'label': 'SIMILARITY', 'score': 3.039372972575258}, {'label': 'SIMILARITY', 'score': 1.362271883675236}, {'label': 'SIMILARITY', 'score': 1.5558502643454826}, {'label': 'SIMILARITY', 'score': 2.9924816428885346}, {'label': 'SIMILARITY', 'score': 2.1397458097595976}, {'label': 'SIMILARITY', 'score': 3.19094914532495}, {'label': 'SIMILARITY', 'score': 0.5618130186177763}, {'label': 'SIMILARITY', 'score': 3.7025682085940614}, {'label': 'SIMILARITY', 'score': 1.561080085665873}, {'label': 'SIMILARITY', 'score': 2.5920340945228624}, {'label': 'SIMILARITY', 'score': 0.9311149421018886}, {'label': 'SIMILARITY', 'score': 4.222655172915964}, {'label': 'SIMILARITY', 'score': 3.2424217025115647}, {'label': 'SIMILARITY', 'score': 3.8234251086433306}, {'label': 'SIMILARITY', 'score': 2.693988048629551}, {'label': 'SIMILARITY', 'score': 1.9853474459150895}, {'label': 'SIMILARITY', 'score': 3.1189374361637894}, {'label': 'SIMILARITY', 'score': 3.2586036564651204}, {'label': 'SIMILARITY', 'score': 2.87678443966231}, {'label': 'SIMILARITY', 'score': 1.958518365788638}, {'label': 'SIMILARITY', 'score': 1.9550767246874374}, {'label': 'SIMILARITY', 'score': 2.692780886322404}, {'label': 'SIMILARITY', 'score': 3.275094587696003}, {'label': 'SIMILARITY', 'score': 1.2786912750031796}, {'label': 'SIMILARITY', 'score': 3.6833217771467264}, {'label': 'SIMILARITY', 'score': 1.3085240761703183}, {'label': 'SIMILARITY', 'score': 3.1117861170816816}, {'label': 'SIMILARITY', 'score': 2.464802016764592}, {'label': 'SIMILARITY', 'score': 2.844972581768081}, {'label': 'SIMILARITY', 'score': 2.4428024825316883}, {'label': 'SIMILARITY', 'score': 2.8234899560339697}, {'label': 'SIMILARITY', 'score': 1.5213090435035932}, {'label': 'SIMILARITY', 'score': 3.838739788399678}, {'label': 'SIMILARITY', 'score': 2.7417375623057065}, {'label': 'SIMILARITY', 'score': 4.1794415729816405}, {'label': 'SIMILARITY', 'score': 2.699479501318729}, {'label': 'SIMILARITY', 'score': 2.6822268680361407}, {'label': 'SIMILARITY', 'score': 2.782681603083019}, {'label': 'SIMILARITY', 'score': 2.3578295003383234}, {'label': 'SIMILARITY', 'score': 0.15254493586338416}, {'label': 'SIMILARITY', 'score': 3.013997272280212}, {'label': 'SIMILARITY', 'score': 1.7449396946161744}, {'label': 'SIMILARITY', 'score': 1.9896408030544654}, {'label': 'SIMILARITY', 'score': 2.753356573520177}, {'label': 'SIMILARITY', 'score': 2.781241072231405}, {'label': 'SIMILARITY', 'score': 1.6825804542482166}, {'label': 'SIMILARITY', 'score': 3.007459931068033}, {'label': 'SIMILARITY', 'score': 0.8978623432291614}, {'label': 'SIMILARITY', 'score': 3.1208784059423196}, {'label': 'SIMILARITY', 'score': 2.7204463250108555}, {'label': 'SIMILARITY', 'score': 3.3623010687845905}, {'label': 'SIMILARITY', 'score': 2.780273786760196}, {'label': 'SIMILARITY', 'score': 2.585373586040401}, {'label': 'SIMILARITY', 'score': 3.9634122625250794}, {'label': 'SIMILARITY', 'score': 4.018441643275457}, {'label': 'SIMILARITY', 'score': 3.237247205634415}, {'label': 'SIMILARITY', 'score': 3.042518221999745}, {'label': 'SIMILARITY', 'score': 1.3984883200719875}, {'label': 'SIMILARITY', 'score': 3.7658189923777257}, {'label': 'SIMILARITY', 'score': 2.9225479532218883}, {'label': 'SIMILARITY', 'score': 2.9890588783015346}, {'label': 'SIMILARITY', 'score': 2.9545964896664385}, {'label': 'SIMILARITY', 'score': 2.887071781488231}, {'label': 'SIMILARITY', 'score': 3.2046233835054703}, {'label': 'SIMILARITY', 'score': 1.5277225848663267}, {'label': 'SIMILARITY', 'score': 3.267028243184639}, {'label': 'SIMILARITY', 'score': 1.5106674632310002}, {'label': 'SIMILARITY', 'score': 2.142969725411569}, {'label': 'SIMILARITY', 'score': 3.148951068656051}, {'label': 'SIMILARITY', 'score': 4.181333928392094}, {'label': 'SIMILARITY', 'score': 3.2372176987323504}, {'label': 'SIMILARITY', 'score': 2.3893739862130494}, {'label': 'SIMILARITY', 'score': 3.010484649249653}, {'label': 'SIMILARITY', 'score': 3.649153581216433}, {'label': 'SIMILARITY', 'score': 2.661284567656402}, {'label': 'SIMILARITY', 'score': 1.8292658812815163}, {'label': 'SIMILARITY', 'score': 2.4446599977191203}, {'label': 'SIMILARITY', 'score': 2.870877482223721}, {'label': 'SIMILARITY', 'score': 1.4583629065237533}, {'label': 'SIMILARITY', 'score': 2.876839946654002}, {'label': 'SIMILARITY', 'score': 1.6146907888253434}, {'label': 'SIMILARITY', 'score': 1.53975500727484}, {'label': 'SIMILARITY', 'score': 1.8020869526718142}, {'label': 'SIMILARITY', 'score': 3.101973803779282}, {'label': 'SIMILARITY', 'score': 2.9526214523485392}, {'label': 'SIMILARITY', 'score': 4.120937365648803}, {'label': 'SIMILARITY', 'score': 1.635156349089511}, {'label': 'SIMILARITY', 'score': 1.7761661823043313}, {'label': 'SIMILARITY', 'score': 2.945407882871541}, {'label': 'SIMILARITY', 'score': 2.7357611827549024}, {'label': 'SIMILARITY', 'score': 2.6330905593251885}, {'label': 'SIMILARITY', 'score': 2.3991665002366998}, {'label': 'SIMILARITY', 'score': 1.703402645576806}, {'label': 'SIMILARITY', 'score': 1.946498832291517}, {'label': 'SIMILARITY', 'score': 2.5191120066890744}, {'label': 'SIMILARITY', 'score': 1.9498270535236533}, {'label': 'SIMILARITY', 'score': 2.4194205173687067}, {'label': 'SIMILARITY', 'score': 0.2959056968357674}, {'label': 'SIMILARITY', 'score': 3.0049191424059996}, {'label': 'SIMILARITY', 'score': 3.1405297779639483}, {'label': 'SIMILARITY', 'score': 4.229067080536784}, {'label': 'SIMILARITY', 'score': 1.9184418044323541}, {'label': 'SIMILARITY', 'score': 3.1472703489439002}, {'label': 'SIMILARITY', 'score': 1.6783766606717907}, {'label': 'SIMILARITY', 'score': 3.5479598396601673}, {'label': 'SIMILARITY', 'score': 2.741700891545943}, {'label': 'SIMILARITY', 'score': 3.063878569998974}, {'label': 'SIMILARITY', 'score': 3.1917002181943905}, {'label': 'SIMILARITY', 'score': 1.302850038129019}, {'label': 'SIMILARITY', 'score': 2.572313282376279}, {'label': 'SIMILARITY', 'score': 2.16521311559745}, {'label': 'SIMILARITY', 'score': 2.719105109480672}, {'label': 'SIMILARITY', 'score': 3.015189808879737}, {'label': 'SIMILARITY', 'score': 3.2638900873145005}, {'label': 'SIMILARITY', 'score': 2.941797932643801}, {'label': 'SIMILARITY', 'score': 2.400333258872417}, {'label': 'SIMILARITY', 'score': 2.6634624793125456}, {'label': 'SIMILARITY', 'score': 1.9752304055519863}, {'label': 'SIMILARITY', 'score': 2.983701371186723}, {'label': 'SIMILARITY', 'score': 2.874112732062151}, {'label': 'SIMILARITY', 'score': 3.003021679864635}, {'label': 'SIMILARITY', 'score': 3.005079510174601}, {'label': 'SIMILARITY', 'score': 1.4344893348893344}, {'label': 'SIMILARITY', 'score': 1.3904619125321092}, {'label': 'SIMILARITY', 'score': 2.703706657359532}, {'label': 'SIMILARITY', 'score': 4.203696639386409}, {'label': 'SIMILARITY', 'score': 3.0089712540947633}, {'label': 'SIMILARITY', 'score': 1.7173408921834272}, {'label': 'SIMILARITY', 'score': 3.301684078709034}, {'label': 'SIMILARITY', 'score': 2.8638276717059052}, {'label': 'SIMILARITY', 'score': 3.099359660367943}, {'label': 'SIMILARITY', 'score': 3.155920511026692}, {'label': 'SIMILARITY', 'score': 3.2995266946045336}, {'label': 'SIMILARITY', 'score': 3.2703547082601974}, {'label': 'SIMILARITY', 'score': 1.8630676826475279}, {'label': 'SIMILARITY', 'score': 1.735121183063961}, {'label': 'SIMILARITY', 'score': 1.1042625288504382}, {'label': 'SIMILARITY', 'score': 3.1886222346202446}, {'label': 'SIMILARITY', 'score': 1.416903636100036}, {'label': 'SIMILARITY', 'score': 1.390203496385461}, {'label': 'SIMILARITY', 'score': 1.4642284417469005}, {'label': 'SIMILARITY', 'score': 2.5906303992664017}, {'label': 'SIMILARITY', 'score': 2.242487168963967}, {'label': 'SIMILARITY', 'score': 2.238394317104315}, {'label': 'SIMILARITY', 'score': 2.2820638462735303}, {'label': 'SIMILARITY', 'score': 1.9673904138672553}, {'label': 'SIMILARITY', 'score': 3.040617947541788}, {'label': 'SIMILARITY', 'score': 4.142371584692511}, {'label': 'SIMILARITY', 'score': 1.7836863722592164}, {'label': 'SIMILARITY', 'score': 2.7179347615117675}, {'label': 'SIMILARITY', 'score': 2.5659810839422486}, {'label': 'SIMILARITY', 'score': 2.9796266850315014}, {'label': 'SIMILARITY', 'score': 2.1809276813511844}, {'label': 'SIMILARITY', 'score': 1.842482383754187}, {'label': 'SIMILARITY', 'score': 3.607282952984014}, {'label': 'SIMILARITY', 'score': 4.043967493118697}, {'label': 'SIMILARITY', 'score': 3.814424245891948}, {'label': 'SIMILARITY', 'score': 2.2473918398685795}, {'label': 'SIMILARITY', 'score': 2.537037631899722}, {'label': 'SIMILARITY', 'score': 4.225106885272357}, {'label': 'SIMILARITY', 'score': 1.402967261395525}, {'label': 'SIMILARITY', 'score': 2.8597259734098603}, {'label': 'SIMILARITY', 'score': 4.214001546261018}, {'label': 'SIMILARITY', 'score': 4.223094794231234}, {'label': 'SIMILARITY', 'score': 2.8305328160180974}, {'label': 'SIMILARITY', 'score': 3.910012697629907}, {'label': 'SIMILARITY', 'score': 2.5348635594174462}, {'label': 'SIMILARITY', 'score': 2.698154589356843}, {'label': 'SIMILARITY', 'score': 1.2974472136073012}, {'label': 'SIMILARITY', 'score': 2.7359394241941977}, {'label': 'SIMILARITY', 'score': 4.223836295285371}, {'label': 'SIMILARITY', 'score': 1.4201899002051974}, {'label': 'SIMILARITY', 'score': 2.5394364175531363}, {'label': 'SIMILARITY', 'score': 2.648660294808132}, {'label': 'SIMILARITY', 'score': 1.9675709763831828}, {'label': 'SIMILARITY', 'score': 4.20033223703803}, {'label': 'SIMILARITY', 'score': 2.3916943130852344}, {'label': 'SIMILARITY', 'score': 4.196578734299453}, {'label': 'SIMILARITY', 'score': 3.4220305258709}, {'label': 'SIMILARITY', 'score': 2.968707039474865}, {'label': 'SIMILARITY', 'score': 1.8084617568529233}, {'label': 'SIMILARITY', 'score': 3.1063659543284436}, {'label': 'SIMILARITY', 'score': 2.9107692357532837}, {'label': 'SIMILARITY', 'score': 1.6271712009390433}, {'label': 'SIMILARITY', 'score': 3.418058383677112}, {'label': 'SIMILARITY', 'score': 1.6502441875051381}, {'label': 'SIMILARITY', 'score': 3.1890815730859448}, {'label': 'SIMILARITY', 'score': 2.4433267686588827}, {'label': 'SIMILARITY', 'score': 3.0834173356832766}, {'label': 'SIMILARITY', 'score': 2.9890797804758544}, {'label': 'SIMILARITY', 'score': 2.568461704159322}, {'label': 'SIMILARITY', 'score': 1.9907446588639341}, {'label': 'SIMILARITY', 'score': 3.3140227225577448}, {'label': 'SIMILARITY', 'score': 1.3162520522476175}, {'label': 'SIMILARITY', 'score': 1.5420105777781523}, {'label': 'SIMILARITY', 'score': 2.8685362904164746}, {'label': 'SIMILARITY', 'score': 2.7247829061649065}, {'label': 'SIMILARITY', 'score': 1.6359079535671615}, {'label': 'SIMILARITY', 'score': 2.5174315652013823}, {'label': 'SIMILARITY', 'score': 2.8966345082209717}, {'label': 'SIMILARITY', 'score': 3.4156364976410667}, {'label': 'SIMILARITY', 'score': 2.9927332728057396}, {'label': 'SIMILARITY', 'score': 0.7761535014207026}, {'label': 'SIMILARITY', 'score': 2.2287387528024882}, {'label': 'SIMILARITY', 'score': 3.0763168607693916}, {'label': 'SIMILARITY', 'score': 2.4031904714755252}, {'label': 'SIMILARITY', 'score': 3.123832525087535}, {'label': 'SIMILARITY', 'score': 0.7696485243781807}, {'label': 'SIMILARITY', 'score': 4.214694988408066}, {'label': 'SIMILARITY', 'score': 4.229176601595463}, {'label': 'SIMILARITY', 'score': 2.275459531985689}, {'label': 'SIMILARITY', 'score': 3.0684109436661045}, {'label': 'SIMILARITY', 'score': 1.9726350790977258}, {'label': 'SIMILARITY', 'score': 3.1110983670979984}, {'label': 'SIMILARITY', 'score': 2.321016802074719}, {'label': 'SIMILARITY', 'score': 3.0019148985077586}, {'label': 'SIMILARITY', 'score': 4.2213165310312}, {'label': 'SIMILARITY', 'score': 2.871418000798965}, {'label': 'SIMILARITY', 'score': 4.2288986093464445}, {'label': 'SIMILARITY', 'score': 1.2803803446321846}, {'label': 'SIMILARITY', 'score': 3.037367559099622}, {'label': 'SIMILARITY', 'score': 2.9701033645925587}, {'label': 'SIMILARITY', 'score': 2.550179046219783}, {'label': 'SIMILARITY', 'score': 2.285556108879954}, {'label': 'SIMILARITY', 'score': 1.2479305196414519}, {'label': 'SIMILARITY', 'score': 2.3951762218395434}, {'label': 'SIMILARITY', 'score': 2.9607197638474583}, {'label': 'SIMILARITY', 'score': 2.167324023280203}, {'label': 'SIMILARITY', 'score': 4.225833041403794}, {'label': 'SIMILARITY', 'score': 2.9222268697786213}, {'label': 'SIMILARITY', 'score': 0.8443567660616678}, {'label': 'SIMILARITY', 'score': 2.8830088992169887}, {'label': 'SIMILARITY', 'score': 3.4631639016271976}, {'label': 'SIMILARITY', 'score': 3.4682795054679687}, {'label': 'SIMILARITY', 'score': 2.646263386733232}, {'label': 'SIMILARITY', 'score': 3.0610244540541194}, {'label': 'SIMILARITY', 'score': 1.106015704070109}, {'label': 'SIMILARITY', 'score': 3.1087682004556587}, {'label': 'SIMILARITY', 'score': 2.997909616946205}, {'label': 'SIMILARITY', 'score': 3.324359073047229}, {'label': 'SIMILARITY', 'score': 3.1936069443827524}, {'label': 'SIMILARITY', 'score': 3.154046797738795}, {'label': 'SIMILARITY', 'score': 3.1251077856370815}, {'label': 'SIMILARITY', 'score': 4.227261663048868}, {'label': 'SIMILARITY', 'score': 4.227816839007305}, {'label': 'SIMILARITY', 'score': 3.8851493175951592}, {'label': 'SIMILARITY', 'score': 3.059483190656141}, {'label': 'SIMILARITY', 'score': 3.287280033513668}, {'label': 'SIMILARITY', 'score': 2.6171760583526864}, {'label': 'SIMILARITY', 'score': 2.3120112126179735}, {'label': 'SIMILARITY', 'score': 2.9132116710890394}, {'label': 'SIMILARITY', 'score': 4.229463096380935}, {'label': 'SIMILARITY', 'score': 1.7935271474048726}, {'label': 'SIMILARITY', 'score': 2.6925650970471753}, {'label': 'SIMILARITY', 'score': 3.027673576164223}, {'label': 'SIMILARITY', 'score': 1.8458576559828146}, {'label': 'SIMILARITY', 'score': 1.5853411884529516}, {'label': 'SIMILARITY', 'score': 3.2792450770641133}, {'label': 'SIMILARITY', 'score': 3.234186059508279}, {'label': 'SIMILARITY', 'score': 2.472314514153721}, {'label': 'SIMILARITY', 'score': 2.0183383916705635}, {'label': 'SIMILARITY', 'score': 1.3679920324011994}, {'label': 'SIMILARITY', 'score': 1.7792717101203868}, {'label': 'SIMILARITY', 'score': 3.0513694731164085}, {'label': 'SIMILARITY', 'score': 2.4922729853593935}, {'label': 'SIMILARITY', 'score': 2.4614692042619897}, {'label': 'SIMILARITY', 'score': 2.1878887256077846}, {'label': 'SIMILARITY', 'score': 1.9801008437279666}, {'label': 'SIMILARITY', 'score': 2.938728867255567}, {'label': 'SIMILARITY', 'score': 3.210179440358155}, {'label': 'SIMILARITY', 'score': 4.196778739639225}, {'label': 'SIMILARITY', 'score': 3.1912366285838973}, {'label': 'SIMILARITY', 'score': 3.6953579486344883}, {'label': 'SIMILARITY', 'score': 2.2313742954955185}, {'label': 'SIMILARITY', 'score': 3.2169749322911523}, {'label': 'SIMILARITY', 'score': 1.7080155690133052}, {'label': 'SIMILARITY', 'score': 2.653902787224176}, {'label': 'SIMILARITY', 'score': 2.869105002351585}, {'label': 'SIMILARITY', 'score': 3.4940456300933116}, {'label': 'SIMILARITY', 'score': 3.047800578046651}, {'label': 'SIMILARITY', 'score': 3.358434172574894}, {'label': 'SIMILARITY', 'score': 3.017624336341294}, {'label': 'SIMILARITY', 'score': 4.21692380619942}, {'label': 'SIMILARITY', 'score': 2.5702631208537827}, {'label': 'SIMILARITY', 'score': 2.338742928639461}, {'label': 'SIMILARITY', 'score': 1.143535337541218}, {'label': 'SIMILARITY', 'score': 2.020739549761885}, {'label': 'SIMILARITY', 'score': 4.228928089814795}, {'label': 'SIMILARITY', 'score': 2.5209341910171017}, {'label': 'SIMILARITY', 'score': 2.785477791699258}, {'label': 'SIMILARITY', 'score': 1.814929237066062}, {'label': 'SIMILARITY', 'score': 2.1112682887836924}, {'label': 'SIMILARITY', 'score': 2.2009000337821134}, {'label': 'SIMILARITY', 'score': 2.4452508588804984}, {'label': 'SIMILARITY', 'score': 2.1468214269289745}, {'label': 'SIMILARITY', 'score': 2.3165075135077613}, {'label': 'SIMILARITY', 'score': 3.83232896258316}, {'label': 'SIMILARITY', 'score': 2.932659489283412}, {'label': 'SIMILARITY', 'score': 3.2170103283232705}, {'label': 'SIMILARITY', 'score': 2.973431858065478}, {'label': 'SIMILARITY', 'score': 1.8899742870754592}, {'label': 'SIMILARITY', 'score': 2.3717347496480263}, {'label': 'SIMILARITY', 'score': 1.6524786746269269}, {'label': 'SIMILARITY', 'score': 3.012150850613276}, {'label': 'SIMILARITY', 'score': 1.9415641221989584}, {'label': 'SIMILARITY', 'score': 1.1155918388387105}, {'label': 'SIMILARITY', 'score': 3.081651044990994}, {'label': 'SIMILARITY', 'score': 1.9563926604616555}, {'label': 'SIMILARITY', 'score': 3.0203531557415038}, {'label': 'SIMILARITY', 'score': 3.118918323211551}, {'label': 'SIMILARITY', 'score': 2.9893515446958787}, {'label': 'SIMILARITY', 'score': 1.795178900092425}, {'label': 'SIMILARITY', 'score': 2.5466234723786996}, {'label': 'SIMILARITY', 'score': 2.308530424110914}, {'label': 'SIMILARITY', 'score': 2.6463829210127345}, {'label': 'SIMILARITY', 'score': 3.515560038655625}, {'label': 'SIMILARITY', 'score': 2.3425893316412507}, {'label': 'SIMILARITY', 'score': 2.329172902958206}, {'label': 'SIMILARITY', 'score': 2.1196050355111216}, {'label': 'SIMILARITY', 'score': 3.1727839142677303}, {'label': 'SIMILARITY', 'score': 4.213105330907649}, {'label': 'SIMILARITY', 'score': 3.0063778884979304}, {'label': 'SIMILARITY', 'score': 2.0801798975837387}, {'label': 'SIMILARITY', 'score': 3.8965150577026066}, {'label': 'SIMILARITY', 'score': 3.0993755461353185}, {'label': 'SIMILARITY', 'score': 1.5618688246970154}, {'label': 'SIMILARITY', 'score': 2.37163397280361}, {'label': 'SIMILARITY', 'score': 0.2549516948147848}, {'label': 'SIMILARITY', 'score': 4.22487193862348}, {'label': 'SIMILARITY', 'score': 2.5365612702507345}, {'label': 'SIMILARITY', 'score': 2.828321671552348}, {'label': 'SIMILARITY', 'score': 4.209015886661863}, {'label': 'SIMILARITY', 'score': 3.9873668811012446}, {'label': 'SIMILARITY', 'score': 2.963598772757089}, {'label': 'SIMILARITY', 'score': 3.117778032239381}, {'label': 'SIMILARITY', 'score': 2.8296095623957647}, {'label': 'SIMILARITY', 'score': 2.6412886570846785}, {'label': 'SIMILARITY', 'score': 3.3628572547225124}, {'label': 'SIMILARITY', 'score': 3.0978703111900083}, {'label': 'SIMILARITY', 'score': 2.7681961302799247}, {'label': 'SIMILARITY', 'score': 1.9673593994694811}, {'label': 'SIMILARITY', 'score': 1.5967460917088798}, {'label': 'SIMILARITY', 'score': 3.1088220968798654}, {'label': 'SIMILARITY', 'score': 4.225849837199661}, {'label': 'SIMILARITY', 'score': 2.3122685288130196}, {'label': 'SIMILARITY', 'score': 1.3637657104706533}, {'label': 'SIMILARITY', 'score': 2.7660275755060115}, {'label': 'SIMILARITY', 'score': 2.090379964352483}, {'label': 'SIMILARITY', 'score': 0.16636513807583939}, {'label': 'SIMILARITY', 'score': 3.0114973998509047}, {'label': 'SIMILARITY', 'score': 2.0726515095438884}, {'label': 'SIMILARITY', 'score': 3.11417250159288}, {'label': 'SIMILARITY', 'score': 1.8799630154678708}, {'label': 'SIMILARITY', 'score': 3.1578492563807963}, {'label': 'SIMILARITY', 'score': 3.084253120058818}, {'label': 'SIMILARITY', 'score': 2.9071665502318615}, {'label': 'SIMILARITY', 'score': 2.2319761689726927}, {'label': 'SIMILARITY', 'score': 2.9952041208145364}, {'label': 'SIMILARITY', 'score': 3.0547821982225805}, {'label': 'SIMILARITY', 'score': 2.8983464419344696}, {'label': 'SIMILARITY', 'score': 3.1312284464668907}, {'label': 'SIMILARITY', 'score': 4.204300932984268}, {'label': 'SIMILARITY', 'score': 2.7063160843560636}, {'label': 'SIMILARITY', 'score': 2.791096458656399}, {'label': 'SIMILARITY', 'score': 3.0885360030079627}, {'label': 'SIMILARITY', 'score': 1.332945013412914}, {'label': 'SIMILARITY', 'score': 1.847425015373883}, {'label': 'SIMILARITY', 'score': 4.228275505530242}, {'label': 'SIMILARITY', 'score': 1.9247152124888682}, {'label': 'SIMILARITY', 'score': 0.8169431219732758}, {'label': 'SIMILARITY', 'score': 3.2267607969150864}, {'label': 'SIMILARITY', 'score': 2.7174433678837824}, {'label': 'SIMILARITY', 'score': 1.3683937239046093}, {'label': 'SIMILARITY', 'score': 3.508361142145068}, {'label': 'SIMILARITY', 'score': 2.192818030963479}, {'label': 'SIMILARITY', 'score': 3.4354865724665746}, {'label': 'SIMILARITY', 'score': 4.215147846290924}, {'label': 'SIMILARITY', 'score': 2.1255436689938687}, {'label': 'SIMILARITY', 'score': 4.216470166954534}, {'label': 'SIMILARITY', 'score': 3.235440572979473}, {'label': 'SIMILARITY', 'score': 2.1662290367224415}, {'label': 'SIMILARITY', 'score': 2.465251063118764}, {'label': 'SIMILARITY', 'score': 3.59834713247841}, {'label': 'SIMILARITY', 'score': 2.3163171314253423}, {'label': 'SIMILARITY', 'score': 3.0665032449928575}, {'label': 'SIMILARITY', 'score': 2.7989692444223815}, {'label': 'SIMILARITY', 'score': 3.3146389821063296}, {'label': 'SIMILARITY', 'score': 2.3004150449319654}, {'label': 'SIMILARITY', 'score': 4.228380733086852}, {'label': 'SIMILARITY', 'score': 3.8382514699972363}, {'label': 'SIMILARITY', 'score': 4.2255727415959505}, {'label': 'SIMILARITY', 'score': 4.228578590013102}, {'label': 'SIMILARITY', 'score': 3.233052197716509}, {'label': 'SIMILARITY', 'score': 1.8884356642066018}, {'label': 'SIMILARITY', 'score': 2.8605998218832567}, {'label': 'SIMILARITY', 'score': 2.107884865854394}, {'label': 'SIMILARITY', 'score': 1.876746985300691}, {'label': 'SIMILARITY', 'score': 3.384867132482312}, {'label': 'SIMILARITY', 'score': 1.876041046391394}, {'label': 'SIMILARITY', 'score': 3.651616789080623}, {'label': 'SIMILARITY', 'score': 2.5337456582375664}, {'label': 'SIMILARITY', 'score': 2.9162930587472484}, {'label': 'SIMILARITY', 'score': 4.146266798553918}, {'label': 'SIMILARITY', 'score': 2.8751735744603923}, {'label': 'SIMILARITY', 'score': 2.5830903664886526}, {'label': 'SIMILARITY', 'score': 3.1345850383712515}, {'label': 'SIMILARITY', 'score': 2.7288055351918525}, {'label': 'SIMILARITY', 'score': 1.270226435619703}, {'label': 'SIMILARITY', 'score': 3.0136191918709065}, {'label': 'SIMILARITY', 'score': 4.2256860898754205}, {'label': 'SIMILARITY', 'score': 2.8931609681004784}, {'label': 'SIMILARITY', 'score': 2.5114512358905206}, {'label': 'SIMILARITY', 'score': 3.368801761254934}, {'label': 'SIMILARITY', 'score': 1.4774440915366829}, {'label': 'SIMILARITY', 'score': 2.386954516424344}, {'label': 'SIMILARITY', 'score': 3.209878902359878}, {'label': 'SIMILARITY', 'score': 4.1272374735389015}, {'label': 'SIMILARITY', 'score': 1.9616727832753103}, {'label': 'SIMILARITY', 'score': 3.0039680174400964}, {'label': 'SIMILARITY', 'score': 2.982002194607692}, {'label': 'SIMILARITY', 'score': 3.177786325335908}, {'label': 'SIMILARITY', 'score': 2.1046710205349126}, {'label': 'SIMILARITY', 'score': 2.165023972249091}, {'label': 'SIMILARITY', 'score': 3.592700643579415}, {'label': 'SIMILARITY', 'score': 2.521986238429711}, {'label': 'SIMILARITY', 'score': 3.373807512890416}, {'label': 'SIMILARITY', 'score': 2.9049455934442294}, {'label': 'SIMILARITY', 'score': 2.856658354533901}, {'label': 'SIMILARITY', 'score': 1.7426468983048402}, {'label': 'SIMILARITY', 'score': 3.0424236101849016}, {'label': 'SIMILARITY', 'score': 2.9858042690889337}, {'label': 'SIMILARITY', 'score': 0.504013267764325}, {'label': 'SIMILARITY', 'score': 3.2805564793425726}, {'label': 'SIMILARITY', 'score': 2.8312084604391483}, {'label': 'SIMILARITY', 'score': 3.2123207857645797}, {'label': 'SIMILARITY', 'score': 4.22927349532147}, {'label': 'SIMILARITY', 'score': 3.051984780185712}, {'label': 'SIMILARITY', 'score': 3.101996965692566}, {'label': 'SIMILARITY', 'score': 2.018421871204093}, {'label': 'SIMILARITY', 'score': 1.8312015208211498}, {'label': 'SIMILARITY', 'score': 4.185641823576176}, {'label': 'SIMILARITY', 'score': 3.0865187789761155}, {'label': 'SIMILARITY', 'score': 1.6802744314869074}, {'label': 'SIMILARITY', 'score': 3.5221811660185547}, {'label': 'SIMILARITY', 'score': 1.957312447590583}, {'label': 'SIMILARITY', 'score': 1.758290716669835}, {'label': 'SIMILARITY', 'score': 2.96028435586003}, {'label': 'SIMILARITY', 'score': 2.093440917579721}, {'label': 'SIMILARITY', 'score': 2.7580767604480707}, {'label': 'SIMILARITY', 'score': 2.8029755179065954}, {'label': 'SIMILARITY', 'score': 1.6741620790609557}, {'label': 'SIMILARITY', 'score': 1.7252206154817131}, {'label': 'SIMILARITY', 'score': 2.2323160432881695}, {'label': 'SIMILARITY', 'score': 0.6986927759657476}, {'label': 'SIMILARITY', 'score': 3.1619540587927273}, {'label': 'SIMILARITY', 'score': 3.304690060324743}, {'label': 'SIMILARITY', 'score': 1.697535468603868}, {'label': 'SIMILARITY', 'score': 1.281282074834865}, {'label': 'SIMILARITY', 'score': 2.0924303542915452}, {'label': 'SIMILARITY', 'score': 2.9147231990287295}, {'label': 'SIMILARITY', 'score': 3.262528293242628}, {'label': 'SIMILARITY', 'score': 1.8174581388368556}, {'label': 'SIMILARITY', 'score': 4.227783183456517}, {'label': 'SIMILARITY', 'score': 2.765096712429445}, {'label': 'SIMILARITY', 'score': 1.1657263191104097}, {'label': 'SIMILARITY', 'score': 3.336360034884898}, {'label': 'SIMILARITY', 'score': 3.0768232228509373}, {'label': 'SIMILARITY', 'score': 2.6085763695642705}, {'label': 'SIMILARITY', 'score': 2.003049335501599}, {'label': 'SIMILARITY', 'score': 0.7029095483129665}, {'label': 'SIMILARITY', 'score': 1.314963093410187}, {'label': 'SIMILARITY', 'score': 1.0326080828885902}, {'label': 'SIMILARITY', 'score': 2.5121279618519794}, {'label': 'SIMILARITY', 'score': 2.9299164323048856}, {'label': 'SIMILARITY', 'score': 3.163551922751922}, {'label': 'SIMILARITY', 'score': 2.8965768077653453}, {'label': 'SIMILARITY', 'score': 3.210555230058434}, {'label': 'SIMILARITY', 'score': 2.9347734751562946}, {'label': 'SIMILARITY', 'score': 3.3623029099836916}, {'label': 'SIMILARITY', 'score': 2.007123570511957}, {'label': 'SIMILARITY', 'score': 2.6902331536180037}, {'label': 'SIMILARITY', 'score': 3.9015707707134157}, {'label': 'SIMILARITY', 'score': 2.2517055868808957}, {'label': 'SIMILARITY', 'score': 1.6530406985043842}, {'label': 'SIMILARITY', 'score': 1.5026500006063463}, {'label': 'SIMILARITY', 'score': 2.655117334808296}, {'label': 'SIMILARITY', 'score': 3.431202912884334}, {'label': 'SIMILARITY', 'score': 4.224226111619519}, {'label': 'SIMILARITY', 'score': 4.1723251818726075}, {'label': 'SIMILARITY', 'score': 2.9411997065404916}, {'label': 'SIMILARITY', 'score': 1.4937418826928135}, {'label': 'SIMILARITY', 'score': 1.3292516798245482}, {'label': 'SIMILARITY', 'score': 1.2201148445783387}, {'label': 'SIMILARITY', 'score': 1.992869325522529}, {'label': 'SIMILARITY', 'score': 1.6416990265831697}, {'label': 'SIMILARITY', 'score': 2.7466526968497633}, {'label': 'SIMILARITY', 'score': 2.447970327859124}, {'label': 'SIMILARITY', 'score': 1.0743024268548}, {'label': 'SIMILARITY', 'score': 4.225165630311883}, {'label': 'SIMILARITY', 'score': 1.8574109144845843}, {'label': 'SIMILARITY', 'score': 1.3362759307378396}, {'label': 'SIMILARITY', 'score': 2.7948728126108806}, {'label': 'SIMILARITY', 'score': 3.11791609693693}, {'label': 'SIMILARITY', 'score': 2.938298251145741}, {'label': 'SIMILARITY', 'score': 2.2089437536021306}, {'label': 'SIMILARITY', 'score': 2.9906014744115224}, {'label': 'SIMILARITY', 'score': 3.7589064467176363}, {'label': 'SIMILARITY', 'score': 3.2853637941660354}, {'label': 'SIMILARITY', 'score': 1.6474454832356982}, {'label': 'SIMILARITY', 'score': 3.3257942657455835}, {'label': 'SIMILARITY', 'score': 2.8051562877022116}, {'label': 'SIMILARITY', 'score': 2.7987830209081777}, {'label': 'SIMILARITY', 'score': 4.223371223724058}, {'label': 'SIMILARITY', 'score': 2.1665346838834836}, {'label': 'SIMILARITY', 'score': 4.221258005160855}, {'label': 'SIMILARITY', 'score': 2.9202531953772914}, {'label': 'SIMILARITY', 'score': 4.226984187287527}, {'label': 'SIMILARITY', 'score': 3.370555567645415}, {'label': 'SIMILARITY', 'score': 2.940958254583442}, {'label': 'SIMILARITY', 'score': 1.9657620320539009}, {'label': 'SIMILARITY', 'score': 3.1203806944997092}, {'label': 'SIMILARITY', 'score': 2.4817044252866087}, {'label': 'SIMILARITY', 'score': 2.4733872333054485}, {'label': 'SIMILARITY', 'score': 2.5773923040038462}, {'label': 'SIMILARITY', 'score': 3.1584085766825676}, {'label': 'SIMILARITY', 'score': 4.199198203170543}, {'label': 'SIMILARITY', 'score': 3.2313161312320755}, {'label': 'SIMILARITY', 'score': 2.851687395224263}, {'label': 'SIMILARITY', 'score': 1.91543510143894}, {'label': 'SIMILARITY', 'score': 3.8967686362646767}, {'label': 'SIMILARITY', 'score': 4.2209278143608016}, {'label': 'SIMILARITY', 'score': 2.974681981112783}, {'label': 'SIMILARITY', 'score': 1.6554277110102877}, {'label': 'SIMILARITY', 'score': 2.817148053504156}, {'label': 'SIMILARITY', 'score': 2.799027652203503}, {'label': 'SIMILARITY', 'score': 4.222646800997861}, {'label': 'SIMILARITY', 'score': 2.7530157827191672}, {'label': 'SIMILARITY', 'score': 3.3891611788952685}, {'label': 'SIMILARITY', 'score': 2.9702446351492435}, {'label': 'SIMILARITY', 'score': 3.131051521709927}, {'label': 'SIMILARITY', 'score': 3.2831943423826777}, {'label': 'SIMILARITY', 'score': 1.4143304323767074}, {'label': 'SIMILARITY', 'score': 3.047992115297071}, {'label': 'SIMILARITY', 'score': 1.5337461102893883}, {'label': 'SIMILARITY', 'score': 3.4698136989522537}, {'label': 'SIMILARITY', 'score': 3.1681427439383785}, {'label': 'SIMILARITY', 'score': 4.227366787034085}, {'label': 'SIMILARITY', 'score': 3.319521657588833}, {'label': 'SIMILARITY', 'score': 1.8865076668658614}, {'label': 'SIMILARITY', 'score': 2.827326772307038}, {'label': 'SIMILARITY', 'score': 3.091775323579}, {'label': 'SIMILARITY', 'score': 3.1594777234283793}, {'label': 'SIMILARITY', 'score': 3.064416991575085}, {'label': 'SIMILARITY', 'score': 1.1810980721197446}, {'label': 'SIMILARITY', 'score': 1.5517487753558867}, {'label': 'SIMILARITY', 'score': 1.8709704987206877}, {'label': 'SIMILARITY', 'score': 2.009221186979087}, {'label': 'SIMILARITY', 'score': 1.879760655782385}, {'label': 'SIMILARITY', 'score': 1.4216297880866184}, {'label': 'SIMILARITY', 'score': 3.1963138857940763}, {'label': 'SIMILARITY', 'score': 4.224905499148487}, {'label': 'SIMILARITY', 'score': 2.9730094550312827}, {'label': 'SIMILARITY', 'score': 3.0513860611488113}, {'label': 'SIMILARITY', 'score': 2.6755964091396662}, {'label': 'SIMILARITY', 'score': 2.501545951479285}, {'label': 'SIMILARITY', 'score': 1.6785758600970857}, {'label': 'SIMILARITY', 'score': 2.9899946375239836}, {'label': 'SIMILARITY', 'score': 1.7960174707891192}, {'label': 'SIMILARITY', 'score': 2.552483132124955}, {'label': 'SIMILARITY', 'score': 3.2470584937320797}, {'label': 'SIMILARITY', 'score': 2.788003666261623}, {'label': 'SIMILARITY', 'score': 2.9847288974513435}, {'label': 'SIMILARITY', 'score': 3.221959442867943}, {'label': 'SIMILARITY', 'score': 2.7497179375651495}, {'label': 'SIMILARITY', 'score': 2.1251652015502476}, {'label': 'SIMILARITY', 'score': 2.537898732346371}, {'label': 'SIMILARITY', 'score': 2.451260523646507}, {'label': 'SIMILARITY', 'score': 3.1361312905043466}, {'label': 'SIMILARITY', 'score': 4.2270514472724345}, {'label': 'SIMILARITY', 'score': 2.783904289490688}, {'label': 'SIMILARITY', 'score': 2.4103839453618643}, {'label': 'SIMILARITY', 'score': 3.0885760421990276}, {'label': 'SIMILARITY', 'score': 2.7931173491421935}, {'label': 'SIMILARITY', 'score': 2.7556749690977327}, {'label': 'SIMILARITY', 'score': 2.555068862187991}, {'label': 'SIMILARITY', 'score': 2.7269982496406735}, {'label': 'SIMILARITY', 'score': 3.155598118258739}, {'label': 'SIMILARITY', 'score': 2.789934850187707}, {'label': 'SIMILARITY', 'score': 2.7391870490070174}, {'label': 'SIMILARITY', 'score': 1.9464404974427176}, {'label': 'SIMILARITY', 'score': 2.6198147262481055}, {'label': 'SIMILARITY', 'score': 3.8388669620353033}, {'label': 'SIMILARITY', 'score': 2.0039281943168046}, {'label': 'SIMILARITY', 'score': 3.051939138847183}, {'label': 'SIMILARITY', 'score': 2.8867345301599183}, {'label': 'SIMILARITY', 'score': 1.6947026194955437}, {'label': 'SIMILARITY', 'score': 4.22828392333901}, {'label': 'SIMILARITY', 'score': 4.051873700072448}, {'label': 'SIMILARITY', 'score': 2.615022722251908}, {'label': 'SIMILARITY', 'score': 2.610131810930863}, {'label': 'SIMILARITY', 'score': 3.1245386846940146}, {'label': 'SIMILARITY', 'score': 3.3694039608812405}, {'label': 'SIMILARITY', 'score': 3.2203507989647155}, {'label': 'SIMILARITY', 'score': 1.0203347709001205}, {'label': 'SIMILARITY', 'score': 3.2814356193064564}, {'label': 'SIMILARITY', 'score': 3.1175841835994875}, {'label': 'SIMILARITY', 'score': 2.5821943839573063}, {'label': 'SIMILARITY', 'score': 3.2592994356612737}, {'label': 'SIMILARITY', 'score': 3.097257553532507}, {'label': 'SIMILARITY', 'score': 2.9651471926294075}, {'label': 'SIMILARITY', 'score': 3.133768022005759}, {'label': 'SIMILARITY', 'score': 3.4527473135956006}, {'label': 'SIMILARITY', 'score': 4.220388869522037}, {'label': 'SIMILARITY', 'score': 3.123470758288352}, {'label': 'SIMILARITY', 'score': 2.955147495105575}, {'label': 'SIMILARITY', 'score': 2.4887331591657813}, {'label': 'SIMILARITY', 'score': 4.229083929172131}, {'label': 'SIMILARITY', 'score': 1.6165743912916741}, {'label': 'SIMILARITY', 'score': 3.0055448410552557}, {'label': 'SIMILARITY', 'score': 3.239566012666129}, {'label': 'SIMILARITY', 'score': 3.386099506804807}, {'label': 'SIMILARITY', 'score': 2.905237508382747}, {'label': 'SIMILARITY', 'score': 1.4251582076716607}, {'label': 'SIMILARITY', 'score': 2.9778949484665747}, {'label': 'SIMILARITY', 'score': 2.2202683320207677}, {'label': 'SIMILARITY', 'score': 3.6984828100915514}, {'label': 'SIMILARITY', 'score': 3.3210726495244716}, {'label': 'SIMILARITY', 'score': 2.4576788520171418}, {'label': 'SIMILARITY', 'score': 2.9326147922239443}, {'label': 'SIMILARITY', 'score': 1.9219192492009223}, {'label': 'SIMILARITY', 'score': 3.8416571158121053}, {'label': 'SIMILARITY', 'score': 1.5740185473072184}, {'label': 'SIMILARITY', 'score': 1.9831126801158796}, {'label': 'SIMILARITY', 'score': 1.8862647092144855}, {'label': 'SIMILARITY', 'score': 4.188861306871045}, {'label': 'SIMILARITY', 'score': 4.227190184869217}, {'label': 'SIMILARITY', 'score': 2.2512641956901893}, {'label': 'SIMILARITY', 'score': 2.192689348418153}, {'label': 'SIMILARITY', 'score': 3.237609550441211}, {'label': 'SIMILARITY', 'score': 1.7878838783951838}, {'label': 'SIMILARITY', 'score': 1.454804664607477}, {'label': 'SIMILARITY', 'score': 2.7447843127892324}, {'label': 'SIMILARITY', 'score': 3.1528540426932232}, {'label': 'SIMILARITY', 'score': 3.8331766773186704}, {'label': 'SIMILARITY', 'score': 2.615074325414789}, {'label': 'SIMILARITY', 'score': 4.220781561133232}, {'label': 'SIMILARITY', 'score': 3.6735673744264177}, {'label': 'SIMILARITY', 'score': 1.9789175842869253}, {'label': 'SIMILARITY', 'score': 2.812372837093739}, {'label': 'SIMILARITY', 'score': 2.4856716845599833}, {'label': 'SIMILARITY', 'score': 2.573727636426762}, {'label': 'SIMILARITY', 'score': 2.4222854841496675}, {'label': 'SIMILARITY', 'score': 3.5825657287780297}, {'label': 'SIMILARITY', 'score': 2.9359733108820647}, {'label': 'SIMILARITY', 'score': 4.032577080870264}, {'label': 'SIMILARITY', 'score': 1.3551786387910625}, {'label': 'SIMILARITY', 'score': 2.7871461771693262}, {'label': 'SIMILARITY', 'score': 3.240093484150846}, {'label': 'SIMILARITY', 'score': 4.136529230479042}, {'label': 'SIMILARITY', 'score': 3.0900628178378966}, {'label': 'SIMILARITY', 'score': 2.069190509360031}, {'label': 'SIMILARITY', 'score': 2.841282284441624}, {'label': 'SIMILARITY', 'score': 2.814593093500041}, {'label': 'SIMILARITY', 'score': 4.22802300326461}, {'label': 'SIMILARITY', 'score': 2.0421291714384426}, {'label': 'SIMILARITY', 'score': 3.3536219096805397}, {'label': 'SIMILARITY', 'score': 3.2996291637925075}, {'label': 'SIMILARITY', 'score': 1.5004674132073434}, {'label': 'SIMILARITY', 'score': 1.5111773389782026}, {'label': 'SIMILARITY', 'score': 2.521711662774929}, {'label': 'SIMILARITY', 'score': 3.0564487973044177}, {'label': 'SIMILARITY', 'score': 4.2281534550364706}, {'label': 'SIMILARITY', 'score': 2.74439882156908}, {'label': 'SIMILARITY', 'score': 4.225064926581685}, {'label': 'SIMILARITY', 'score': 2.678050348781929}, {'label': 'SIMILARITY', 'score': 3.2073563911089793}, {'label': 'SIMILARITY', 'score': 3.3079197242312617}, {'label': 'SIMILARITY', 'score': 1.5595881227702542}, {'label': 'SIMILARITY', 'score': 2.795136367447385}, {'label': 'SIMILARITY', 'score': 2.712905677236881}, {'label': 'SIMILARITY', 'score': 1.4446230134548612}, {'label': 'SIMILARITY', 'score': 2.7738307960376654}, {'label': 'SIMILARITY', 'score': 2.9327228131918726}, {'label': 'SIMILARITY', 'score': 2.927872221729528}, {'label': 'SIMILARITY', 'score': 3.3199304348456833}, {'label': 'SIMILARITY', 'score': 1.8481913676593917}, {'label': 'SIMILARITY', 'score': 1.0233217339427254}, {'label': 'SIMILARITY', 'score': 2.845468600962301}, {'label': 'SIMILARITY', 'score': 3.066912559696785}, {'label': 'SIMILARITY', 'score': 2.9808410330891397}, {'label': 'SIMILARITY', 'score': 2.8557191880809416}, {'label': 'SIMILARITY', 'score': 2.3592832690287455}, {'label': 'SIMILARITY', 'score': 3.116470220822215}, {'label': 'SIMILARITY', 'score': 3.0910642011416707}, {'label': 'SIMILARITY', 'score': 2.7784055363697258}, {'label': 'SIMILARITY', 'score': 0.7925220736640286}, {'label': 'SIMILARITY', 'score': 2.2099596497707577}, {'label': 'SIMILARITY', 'score': 2.5077087966630107}, {'label': 'SIMILARITY', 'score': 2.9456327169814567}, {'label': 'SIMILARITY', 'score': 3.103881961588625}, {'label': 'SIMILARITY', 'score': 2.617083945434252}, {'label': 'SIMILARITY', 'score': 2.734749591904275}, {'label': 'SIMILARITY', 'score': 2.2552181196624077}, {'label': 'SIMILARITY', 'score': 2.0053821082553145}, {'label': 'SIMILARITY', 'score': 1.6806508596789276}, {'label': 'SIMILARITY', 'score': 1.923165942986546}, {'label': 'SIMILARITY', 'score': 0.8678666368481547}, {'label': 'SIMILARITY', 'score': 2.905357445780855}, {'label': 'SIMILARITY', 'score': 3.217802214559931}, {'label': 'SIMILARITY', 'score': 1.8884132116685588}, {'label': 'SIMILARITY', 'score': 2.750514841021356}, {'label': 'SIMILARITY', 'score': 2.848001481281147}, {'label': 'SIMILARITY', 'score': 1.8596053786898723}, {'label': 'SIMILARITY', 'score': 1.3602368077693165}, {'label': 'SIMILARITY', 'score': 2.0935367093443107}, {'label': 'SIMILARITY', 'score': 1.8347962476781605}, {'label': 'SIMILARITY', 'score': 3.7373490482199263}, {'label': 'SIMILARITY', 'score': 1.78956640528508}, {'label': 'SIMILARITY', 'score': 3.409580684175606}, {'label': 'SIMILARITY', 'score': 1.633440135196017}, {'label': 'SIMILARITY', 'score': 1.8970556223411723}, {'label': 'SIMILARITY', 'score': 3.2386940307101466}, {'label': 'SIMILARITY', 'score': 3.0303772402119087}, {'label': 'SIMILARITY', 'score': 2.8021784300688184}, {'label': 'SIMILARITY', 'score': 3.5982253103784116}, {'label': 'SIMILARITY', 'score': 2.4267101519330296}, {'label': 'SIMILARITY', 'score': 2.592350550816409}, {'label': 'SIMILARITY', 'score': 2.0103187466029655}, {'label': 'SIMILARITY', 'score': 3.0776823099638233}, {'label': 'SIMILARITY', 'score': 1.6488073764728854}, {'label': 'SIMILARITY', 'score': 0.13343882476801083}, {'label': 'SIMILARITY', 'score': 3.550090151490886}, {'label': 'SIMILARITY', 'score': 2.938015009169587}, {'label': 'SIMILARITY', 'score': 0.3417628953317474}, {'label': 'SIMILARITY', 'score': 3.0442253742294425}, {'label': 'SIMILARITY', 'score': 1.8632296487493372}, {'label': 'SIMILARITY', 'score': 1.5399927986906268}, {'label': 'SIMILARITY', 'score': 3.0484414630806107}, {'label': 'SIMILARITY', 'score': 2.019662026442775}, {'label': 'SIMILARITY', 'score': 3.26291096685721}, {'label': 'SIMILARITY', 'score': 1.4783154283778386}, {'label': 'SIMILARITY', 'score': 2.3042720669038097}, {'label': 'SIMILARITY', 'score': 2.7092012933260294}, {'label': 'SIMILARITY', 'score': 1.8408419711799286}, {'label': 'SIMILARITY', 'score': 2.2462484084891825}, {'label': 'SIMILARITY', 'score': 3.103119458348488}, {'label': 'SIMILARITY', 'score': 1.434264944451407}, {'label': 'SIMILARITY', 'score': 1.6578234770401423}, {'label': 'SIMILARITY', 'score': 3.205390351137702}, {'label': 'SIMILARITY', 'score': 1.9412029533831532}, {'label': 'SIMILARITY', 'score': 2.9300043730248917}, {'label': 'SIMILARITY', 'score': 1.4843039469466695}, {'label': 'SIMILARITY', 'score': 0.5160253935872487}, {'label': 'SIMILARITY', 'score': 3.096874213784272}, {'label': 'SIMILARITY', 'score': 3.5277509426230718}, {'label': 'SIMILARITY', 'score': 3.0858567050896704}, {'label': 'SIMILARITY', 'score': 0.6379446981790331}, {'label': 'SIMILARITY', 'score': 1.7902489290434058}, {'label': 'SIMILARITY', 'score': 1.2113153071863008}, {'label': 'SIMILARITY', 'score': 4.227930434613974}, {'label': 'SIMILARITY', 'score': 2.864304067744304}, {'label': 'SIMILARITY', 'score': 3.140841742569009}, {'label': 'SIMILARITY', 'score': 3.8703074385236307}, {'label': 'SIMILARITY', 'score': 1.99227490826603}, {'label': 'SIMILARITY', 'score': 1.6809931514954324}, {'label': 'SIMILARITY', 'score': 2.8703407469332007}, {'label': 'SIMILARITY', 'score': 2.96133879567211}, {'label': 'SIMILARITY', 'score': 4.224918084627374}, {'label': 'SIMILARITY', 'score': 1.4214851714482544}, {'label': 'SIMILARITY', 'score': 2.328818399955627}, {'label': 'SIMILARITY', 'score': 2.666950049308541}, {'label': 'SIMILARITY', 'score': 1.7554415545469173}, {'label': 'SIMILARITY', 'score': 2.0243244296231806}, {'label': 'SIMILARITY', 'score': 2.921156030805957}, {'label': 'SIMILARITY', 'score': 2.105409827886432}, {'label': 'SIMILARITY', 'score': 1.8047724149532816}, {'label': 'SIMILARITY', 'score': 2.5231849019622903}, {'label': 'SIMILARITY', 'score': 2.4082562299205827}, {'label': 'SIMILARITY', 'score': 4.127577156910778}, {'label': 'SIMILARITY', 'score': 2.9422486921696405}, {'label': 'SIMILARITY', 'score': 1.3394031773364805}, {'label': 'SIMILARITY', 'score': 2.9752662851340688}, {'label': 'SIMILARITY', 'score': 2.989761930683661}, {'label': 'SIMILARITY', 'score': 3.0458182677319288}, {'label': 'SIMILARITY', 'score': 4.227623334612204}, {'label': 'SIMILARITY', 'score': 3.3986200549400625}, {'label': 'SIMILARITY', 'score': 3.1478922000110945}, {'label': 'SIMILARITY', 'score': 2.9188616830206193}, {'label': 'SIMILARITY', 'score': 1.926172299634595}, {'label': 'SIMILARITY', 'score': 2.667875899156841}, {'label': 'SIMILARITY', 'score': 3.037891783140517}, {'label': 'SIMILARITY', 'score': 2.8612017886453556}, {'label': 'SIMILARITY', 'score': 3.128706634548026}, {'label': 'SIMILARITY', 'score': 3.029188490347478}, {'label': 'SIMILARITY', 'score': 1.6478030127655028}, {'label': 'SIMILARITY', 'score': 1.181904591164107}, {'label': 'SIMILARITY', 'score': 2.5917103679798683}, {'label': 'SIMILARITY', 'score': 2.9292502903368645}, {'label': 'SIMILARITY', 'score': 2.9702073893452057}, {'label': 'SIMILARITY', 'score': 2.3445346604658486}, {'label': 'SIMILARITY', 'score': 0.0316818031920107}, {'label': 'SIMILARITY', 'score': 1.8057421404884415}, {'label': 'SIMILARITY', 'score': 2.0445529189744605}, {'label': 'SIMILARITY', 'score': 3.086090668256187}, {'label': 'SIMILARITY', 'score': 3.144536605433389}, {'label': 'SIMILARITY', 'score': 2.4741339739464547}, {'label': 'SIMILARITY', 'score': 1.294805006169131}, {'label': 'SIMILARITY', 'score': 2.2665988873637213}, {'label': 'SIMILARITY', 'score': 2.1747431454887676}, {'label': 'SIMILARITY', 'score': 3.6755664341253294}, {'label': 'SIMILARITY', 'score': 3.3192545321985083}, {'label': 'SIMILARITY', 'score': 2.2234580140250317}, {'label': 'SIMILARITY', 'score': 2.904132026272363}, {'label': 'SIMILARITY', 'score': 2.9728794182310683}, {'label': 'SIMILARITY', 'score': 2.9616955964462557}, {'label': 'SIMILARITY', 'score': 2.358399471387357}, {'label': 'SIMILARITY', 'score': 2.026729104938132}, {'label': 'SIMILARITY', 'score': 3.1244455873174513}, {'label': 'SIMILARITY', 'score': 1.7983836037180685}, {'label': 'SIMILARITY', 'score': 1.9011590813750212}, {'label': 'SIMILARITY', 'score': 2.6239088387158387}, {'label': 'SIMILARITY', 'score': 3.0135991558884156}, {'label': 'SIMILARITY', 'score': 2.3482624726324217}, {'label': 'SIMILARITY', 'score': 2.238352560087081}, {'label': 'SIMILARITY', 'score': 2.867475856940139}, {'label': 'SIMILARITY', 'score': 2.4031371789261926}, {'label': 'SIMILARITY', 'score': 3.499846305626015}, {'label': 'SIMILARITY', 'score': 2.107428950532489}, {'label': 'SIMILARITY', 'score': 3.2064398430815526}, {'label': 'SIMILARITY', 'score': 2.8354928159320534}, {'label': 'SIMILARITY', 'score': 2.5519417879576416}, {'label': 'SIMILARITY', 'score': 3.0644141938975316}, {'label': 'SIMILARITY', 'score': 2.2400020054901364}, {'label': 'SIMILARITY', 'score': 2.6400195581187993}, {'label': 'SIMILARITY', 'score': 3.0299338505231552}, {'label': 'SIMILARITY', 'score': 3.1648607344136406}, {'label': 'SIMILARITY', 'score': 1.2229361743354061}, {'label': 'SIMILARITY', 'score': 3.1704107590992407}, {'label': 'SIMILARITY', 'score': 2.951614410658074}, {'label': 'SIMILARITY', 'score': 3.352139935718038}, {'label': 'SIMILARITY', 'score': 1.226877975464907}, {'label': 'SIMILARITY', 'score': 4.221412687896774}, {'label': 'SIMILARITY', 'score': 1.7911842932918305}, {'label': 'SIMILARITY', 'score': 2.8182808441270333}, {'label': 'SIMILARITY', 'score': 4.226223614540295}, {'label': 'SIMILARITY', 'score': 2.876966323902264}, {'label': 'SIMILARITY', 'score': 3.269651769045096}, {'label': 'SIMILARITY', 'score': 2.4795974940468177}, {'label': 'SIMILARITY', 'score': 2.777824570426215}, {'label': 'SIMILARITY', 'score': 1.9713490437426475}, {'label': 'SIMILARITY', 'score': 3.064103695993174}, {'label': 'SIMILARITY', 'score': 2.9625600398163323}, {'label': 'SIMILARITY', 'score': 2.046584605899881}, {'label': 'SIMILARITY', 'score': 3.073990319309617}, {'label': 'SIMILARITY', 'score': 4.226698381359096}, {'label': 'SIMILARITY', 'score': 3.350213876950072}, {'label': 'SIMILARITY', 'score': 2.7876239344158287}, {'label': 'SIMILARITY', 'score': 3.779318210090974}, {'label': 'SIMILARITY', 'score': 2.9923768139896434}, {'label': 'SIMILARITY', 'score': 2.1735825409805685}, {'label': 'SIMILARITY', 'score': 4.227392018387717}, {'label': 'SIMILARITY', 'score': 3.189541105924135}, {'label': 'SIMILARITY', 'score': 2.9619581731806277}, {'label': 'SIMILARITY', 'score': 3.1531892782344992}, {'label': 'SIMILARITY', 'score': 2.6686973192371877}, {'label': 'SIMILARITY', 'score': 2.1973203458007307}, {'label': 'SIMILARITY', 'score': 0.8625304901818189}, {'label': 'SIMILARITY', 'score': 4.215097980622575}, {'label': 'SIMILARITY', 'score': 4.060187598134467}, {'label': 'SIMILARITY', 'score': 2.1010594809092633}, {'label': 'SIMILARITY', 'score': 2.60552849781949}, {'label': 'SIMILARITY', 'score': 2.911726559317776}, {'label': 'SIMILARITY', 'score': 1.9234359982908213}, {'label': 'SIMILARITY', 'score': 2.3127033275236997}, {'label': 'SIMILARITY', 'score': 1.6987287065040573}, {'label': 'SIMILARITY', 'score': 2.978755301091307}, {'label': 'SIMILARITY', 'score': 1.7800887487023}, {'label': 'SIMILARITY', 'score': 2.123717430940097}, {'label': 'SIMILARITY', 'score': 2.602834859433103}, {'label': 'SIMILARITY', 'score': 3.1612813315659296}, {'label': 'SIMILARITY', 'score': 2.719318776185432}, {'label': 'SIMILARITY', 'score': 3.0999056853306928}, {'label': 'SIMILARITY', 'score': 2.812845768118447}, {'label': 'SIMILARITY', 'score': 1.8287763958594616}, {'label': 'SIMILARITY', 'score': 2.599880730711132}, {'label': 'SIMILARITY', 'score': 2.0963373591873786}, {'label': 'SIMILARITY', 'score': 3.837315923809184}, {'label': 'SIMILARITY', 'score': 3.5813231996554387}, {'label': 'SIMILARITY', 'score': 4.1827947415190465}, {'label': 'SIMILARITY', 'score': 3.0039666933246054}, {'label': 'SIMILARITY', 'score': 3.2069785200684513}, {'label': 'SIMILARITY', 'score': 4.22266354490213}, {'label': 'SIMILARITY', 'score': 2.7977753020223037}, {'label': 'SIMILARITY', 'score': 2.2507247780137387}, {'label': 'SIMILARITY', 'score': 3.9805914979505985}, {'label': 'SIMILARITY', 'score': 2.90942841636924}, {'label': 'SIMILARITY', 'score': 2.0393114635748306}, {'label': 'SIMILARITY', 'score': 3.0389491816340417}, {'label': 'SIMILARITY', 'score': 2.7290572919469414}, {'label': 'SIMILARITY', 'score': 4.167941444499178}, {'label': 'SIMILARITY', 'score': 2.557031781389589}, {'label': 'SIMILARITY', 'score': 2.17318421636502}, {'label': 'SIMILARITY', 'score': 0.9934040061687817}, {'label': 'SIMILARITY', 'score': 2.885648390614758}, {'label': 'SIMILARITY', 'score': 2.0192782762221917}, {'label': 'SIMILARITY', 'score': 2.975145013477121}, {'label': 'SIMILARITY', 'score': 4.2053335739898525}, {'label': 'SIMILARITY', 'score': 1.8441060505660978}, {'label': 'SIMILARITY', 'score': 1.9996067410523675}, {'label': 'SIMILARITY', 'score': 1.675173869749569}, {'label': 'SIMILARITY', 'score': 1.6996819978254547}, {'label': 'SIMILARITY', 'score': 2.897027671923171}, {'label': 'SIMILARITY', 'score': 4.163722522592244}, {'label': 'SIMILARITY', 'score': 4.05382684051749}, {'label': 'SIMILARITY', 'score': 2.488922659307119}, {'label': 'SIMILARITY', 'score': 3.4573943001697858}, {'label': 'SIMILARITY', 'score': 2.3303513916601384}, {'label': 'SIMILARITY', 'score': 2.6029964128632623}, {'label': 'SIMILARITY', 'score': 2.729114281647501}, {'label': 'SIMILARITY', 'score': 2.293139440245977}, {'label': 'SIMILARITY', 'score': 2.7661849347364322}, {'label': 'SIMILARITY', 'score': 2.8247463962720447}, {'label': 'SIMILARITY', 'score': 1.5170502553255005}, {'label': 'SIMILARITY', 'score': 2.1945998292469784}, {'label': 'SIMILARITY', 'score': 3.393832753030138}, {'label': 'SIMILARITY', 'score': 2.999861631078586}, {'label': 'SIMILARITY', 'score': 2.794473205030836}, {'label': 'SIMILARITY', 'score': 2.7532475516780686}, {'label': 'SIMILARITY', 'score': 0.960778706397081}, {'label': 'SIMILARITY', 'score': 2.5863589743791118}, {'label': 'SIMILARITY', 'score': 2.968456964803852}, {'label': 'SIMILARITY', 'score': 1.6514872603930506}, {'label': 'SIMILARITY', 'score': 1.4611180780137891}, {'label': 'SIMILARITY', 'score': 2.5430186969213944}, {'label': 'SIMILARITY', 'score': 2.907020937319277}, {'label': 'SIMILARITY', 'score': 2.8316689472697236}, {'label': 'SIMILARITY', 'score': 2.878780878372552}, {'label': 'SIMILARITY', 'score': 2.3935315713554197}, {'label': 'SIMILARITY', 'score': 3.1380881404574628}, {'label': 'SIMILARITY', 'score': 2.6928852827042427}, {'label': 'SIMILARITY', 'score': 1.9376394117376454}, {'label': 'SIMILARITY', 'score': 2.9249559518191566}, {'label': 'SIMILARITY', 'score': 2.231203454768787}, {'label': 'SIMILARITY', 'score': 3.0884287623838467}, {'label': 'SIMILARITY', 'score': 3.299387768908125}, {'label': 'SIMILARITY', 'score': 3.2076131634451754}, {'label': 'SIMILARITY', 'score': 2.8859924588164354}, {'label': 'SIMILARITY', 'score': 2.1708241512187922}, {'label': 'SIMILARITY', 'score': 1.789202917232214}, {'label': 'SIMILARITY', 'score': 2.9269639266669762}, {'label': 'SIMILARITY', 'score': 0.9962036319248612}, {'label': 'SIMILARITY', 'score': 2.96321072916933}, {'label': 'SIMILARITY', 'score': 3.070238990393299}, {'label': 'SIMILARITY', 'score': 1.6068761946503334}, {'label': 'SIMILARITY', 'score': 1.6210063933522243}, {'label': 'SIMILARITY', 'score': 3.0220033856530146}, {'label': 'SIMILARITY', 'score': 1.1435665603222345}, {'label': 'SIMILARITY', 'score': 2.8444480960268166}, {'label': 'SIMILARITY', 'score': 2.759175291806565}, {'label': 'SIMILARITY', 'score': 4.227892568019177}, {'label': 'SIMILARITY', 'score': 2.8810807796743942}, {'label': 'SIMILARITY', 'score': 2.2358435627188142}, {'label': 'SIMILARITY', 'score': 2.9606115324507765}, {'label': 'SIMILARITY', 'score': 1.275598764231552}, {'label': 'SIMILARITY', 'score': 3.4540024510881584}, {'label': 'SIMILARITY', 'score': 2.4499834528366335}, {'label': 'SIMILARITY', 'score': 3.2163589047681787}, {'label': 'SIMILARITY', 'score': 3.4523025558837137}, {'label': 'SIMILARITY', 'score': 4.2239033499516445}, {'label': 'SIMILARITY', 'score': 1.809298987109514}, {'label': 'SIMILARITY', 'score': 2.848532235563948}, {'label': 'SIMILARITY', 'score': 3.119147700710317}, {'label': 'SIMILARITY', 'score': 3.0850139958565737}, {'label': 'SIMILARITY', 'score': 2.944442492708951}, {'label': 'SIMILARITY', 'score': 1.7885388717529371}, {'label': 'SIMILARITY', 'score': 2.7185649576894377}, {'label': 'SIMILARITY', 'score': 4.226345436472109}, {'label': 'SIMILARITY', 'score': 4.224569943110671}, {'label': 'SIMILARITY', 'score': 0.484728008360793}]\n"
     ]
    }
   ],
   "source": [
    "predictions = pipe(prepare(fine_runed_corpus_semantic), add_special_tokens=False)\n",
    "\n",
    "# convert back to scores to the original 0 and 5 interval\n",
    "for prediction in predictions:\n",
    "    prediction['score'] = logit(prediction['score'])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model amb embeddings entrenables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "vectors_1 =[pair[0] for pair in mean_embbeding_corpus_semantic]\n",
    "vectors_2 =[pair[1] for pair in mean_embbeding_corpus_semantic]\n",
    "\n",
    "# Tokenització i creació del vocabulari\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts_1 + texts_2)\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Padding de les seqüències\n",
    "max_length = 10\n",
    "data_1 = pad_sequences(sequences_1, maxlen=max_length)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=max_length)\n",
    "\n",
    "# Paràmetres del model\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 100\n",
    "hidden_size = 64\n",
    "input_length = max_length\n",
    "\n",
    "# Creació d'embeddings aleatoris\n",
    "random_embeddings = np.random.uniform(-1, 1, (vocab_size, embedding_dim))\n",
    "\n",
    "# Creació d'embeddings de Word2Vec\n",
    "texts_combined = [text.split() for text in texts_1 + texts_2]\n",
    "word2vec_model = Word2Vec(texts_combined, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "word2vec_embeddings = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        word2vec_embeddings[i] = word2vec_model.wv[word]\n",
    "\n",
    "# Entrenament del model amb embeddings aleatoris\n",
    "model_random = build_and_compile_model(random_embeddings, input_length=max_length, hidden_size=hidden_size)\n",
    "model_random.fit([data_1, data_2], labels, epochs=10, batch_size=2)\n",
    "\n",
    "# Entrenament del model amb embeddings de Word2Vec\n",
    "model_word2vec = build_and_compile_model(word2vec_embeddings, input_length=max_length, hidden_size=hidden_size)\n",
    "model_word2vec.fit([data_1, data_2], labels, epochs=10, batch_size=2)\n",
    "\n",
    "# Avalua els resultats dels models\n",
    "loss_random = model_random.evaluate([data_1, data_2], labels)\n",
    "loss_word2vec = model_word2vec.evaluate([data_1, data_2], labels)\n",
    "\n",
    "print(f'Random Embeddings - Loss: {loss_random}')\n",
    "print(f'Word2Vec Embeddings - Loss: {loss_word2vec}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Exemple de dades\n",
    "texts_1 = [\"aquest és un text d'exemple\", \"un altre text\"]\n",
    "texts_2 = [\"aquest és un altre text\", \"un text diferent\"]\n",
    "labels = [0.8, 0.4]  # Similitud entre les frases\n",
    "\n",
    "# Tokenització i creació del vocabulari\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts_1 + texts_2)\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Padding de les seqüències\n",
    "max_length = 10\n",
    "data_1 = pad_sequences(sequences_1, maxlen=max_length)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=max_length)\n",
    "\n",
    "# Paràmetres del model\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 100\n",
    "hidden_size = 64\n",
    "input_length = max_length\n",
    "\n",
    "# Creació d'embeddings de Word2Vec\n",
    "texts_combined = [text.split() for text in texts_1 + texts_2]\n",
    "word2vec_model = Word2Vec(texts_combined, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "word2vec_embeddings = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        word2vec_embeddings[i] = word2vec_model.wv[word]\n",
    "\n",
    "def build_and_compile_model(embedding_matrix, input_length: int = 100, hidden_size: int = 64) -> tf.keras.Model:\n",
    "    input_1, input_2 = tf.keras.Input((input_length, ), dtype=tf.int32), tf.keras.Input((input_length, ), dtype=tf.int32)\n",
    "\n",
    "    # Define Layers\n",
    "    embedding = tf.keras.layers.Embedding(\n",
    "        vocab_size, embedding_dim, weights=[embedding_matrix], input_length=input_length, mask_zero=True, trainable=True)\n",
    "\n",
    "    lstm = tf.keras.layers.LSTM(hidden_size)\n",
    "\n",
    "    concatenate = tf.keras.layers.Concatenate(axis=-1)\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "    output = tf.keras.layers.Dense(1)\n",
    "\n",
    "    # Pass through the layers\n",
    "    _embedded_1, _embedded_2 = embedding(input_1), embedding(input_2)\n",
    "    _lstm_1, _lstm_2 = lstm(_embedded_1), lstm(_embedded_2)\n",
    "\n",
    "    _concatenated = concatenate([_lstm_1, _lstm_2])\n",
    "    _hidden_output = hidden(_concatenated)\n",
    "    _output = output(_hidden_output)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=(input_1, input_2), outputs=_output)\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "\n",
    "# Entrenament del model amb embeddings de Word2Vec\n",
    "model_word2vec = build_and_compile_model(word2vec_embeddings, input_length=max_length, hidden_size=hidden_size)\n",
    "model_word2vec.fit([data_1, data_2], labels, epochs=10, batch_size=2)\n",
    "\n",
    "# Avalua els resultats dels models\n",
    "loss_word2vec = model_word2vec.evaluate([data_1, data_2], labels)\n",
    "\n",
    "print(f'Word2Vec Embeddings - Loss: {loss_word2vec}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Defineix funcions per calcular els embeddings de frases\n",
    "def compute_mean_embedding(text, model, embedding_dim):\n",
    "    \"\"\"\n",
    "    Agafa els vectors d'embeddings de cada paraula en una frase o document i \n",
    "    calcula la mitjana dels vectors per obtenir una única representació vectorial \n",
    "    per a la frase o document.\n",
    "    \"\"\"\n",
    "    vectors = [model[word] for word in text if word in model]\n",
    "    if vectors:\n",
    "        mean_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        mean_vector = np.zeros(embedding_dim)\n",
    "    return mean_vector\n",
    "\n",
    "def compute_weighted_mean_embedding(text, model, word2tfidf, embedding_dim):\n",
    "    \"\"\"\n",
    "    Utilitza una ponderació per a cada vector de paraula, com ara la freqüència \n",
    "    inversa del document (TF-IDF), per calcular una mitjana ponderada dels vectors.\n",
    "    \"\"\"\n",
    "    vectors = [model[word] * word2tfidf[word] for word in text if word in model and word in word2tfidf]\n",
    "    if vectors:\n",
    "        weighted_mean_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        weighted_mean_vector = np.zeros(embedding_dim)\n",
    "    return weighted_mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de corpus\n",
    "corpus = [\"Aquest és un text de exemple\", \"Aquí hi ha un altre text\"]\n",
    "\n",
    "# Prepara els vectors TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.7557\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4268\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5486\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4800\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3008\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0543\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2087\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2880\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3351\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[0.10263795]]\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'ús amb embeddings pre-entrenats (Word2Vec)\n",
    "from gensim.models import KeyedVectors\n",
    "import tensorflow as tf\n",
    "\n",
    "# Carrega el model pre-entrenat (substitueix 'path_to_model' amb la ruta real)\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format('path_to_model', binary=True)\n",
    "\n",
    "# Defineix la longitud de les seqüències i la dimensió dels embeddings\n",
    "input_length = 10\n",
    "embedding_dim = model_100MB.vector_size\n",
    "\n",
    "# Prepara les dades d'entrenament\n",
    "X_train1 = np.array([compute_mean_embedding(text.split(), model_100MB.wv, embedding_dim) for text in corpus])\n",
    "X_train2 = np.array([compute_weighted_mean_embedding(text.split(), model_100MB.wv, word2tfidf, embedding_dim) for text in corpus])\n",
    "y_train = np.random.rand(len(corpus), 1)\n",
    "\n",
    "# Defineix el model de Keras (ajusta les dimensions segons la longitud de les seqüències i la dimensió dels embeddings)\n",
    "def build_and_compile_model(input_dim, hidden_size=64):\n",
    "    input_1 = tf.keras.Input(shape=(input_dim,))\n",
    "    input_2 = tf.keras.Input(shape=(input_dim,))\n",
    "    \n",
    "    concatenate = tf.keras.layers.Concatenate(axis=-1)([input_1, input_2])\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu')(concatenate)\n",
    "    output = tf.keras.layers.Dense(1)(hidden)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construir i compilar el model\n",
    "m = build_and_compile_model(input_dim=embedding_dim)\n",
    "\n",
    "# Entrenar el model\n",
    "m.fit([X_train1, X_train2], y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Exemple de predicció\n",
    "input_data1 = compute_mean_embedding(\"Aquest és un text de exemple\".split(), model_100MB.wv, embedding_dim).reshape(1, -1)\n",
    "input_data2 = compute_weighted_mean_embedding(\"Aquí hi ha un altre text\".split(), model_100MB.wv, word2tfidf, embedding_dim).reshape(1, -1)\n",
    "\n",
    "# Predir la similitud\n",
    "y_pred = m.predict([input_data1, input_data2])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24829134],\n",
       "       [0.49559584]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
